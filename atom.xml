<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Tianke Youke</title>
  
  <subtitle>A Base for Secreting and Running at Night</subtitle>
  <link href="https://jyzhu.top/atom.xml" rel="self"/>
  
  <link href="https://jyzhu.top/"/>
  <updated>2023-01-12T09:38:18.916Z</updated>
  <id>https://jyzhu.top/</id>
  
  <author>
    <name>Jiayin Zhu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>NeRF Notebook - Part One</title>
    <link href="https://jyzhu.top/NeRF-Notebook-Part-One/"/>
    <id>https://jyzhu.top/NeRF-Notebook-Part-One/</id>
    <published>2023-01-12T09:33:39.000Z</published>
    <updated>2023-01-12T09:38:18.916Z</updated>
    
    <content type="html"><![CDATA[<h1 id="learning-nerf">Learning NeRF</h1><h2 id="reading-list">Reading List</h2><h3 id="classical">Classical</h3><ul><li><p>Mildenhall <em>et al.</em> introduced NeRF at ECCV 2020 in the now seminal <a href="https://www.matthewtancik.com/nerf">Neural Radiance Field paper</a>.</p><p>This is done by storing the density and radiance in a neural volumetric scene representation using MLPs and then rendering the volume to create new images.</p></li><li><p><a href="https://m-niemeyer.github.io/project-pages/giraffe/index.html">GIRAFFE</a>: Compositional Generative Neural Feature Fields</p></li></ul><h3 id="survey">Survey</h3><ul><li><a href="https://arxiv.org/abs/2004.03805">Apr 2020 - State of the Art on Neural Rendering</a></li></ul><h3 id="cvpr">2021CVPR</h3><p>2021å¹´CVPRè¿˜æœ‰è®¸å¤šç›¸å…³çš„ç²¾å½©å·¥ä½œå‘è¡¨ã€‚ä¾‹å¦‚ï¼Œæå‡ç½‘ç»œçš„æ³›åŒ–æ€§ï¼š</p><ul><li><a href="https://alexyu.net/pixelnerf/">pixelNeRF</a>ï¼šå°†æ¯ä¸ªåƒç´ çš„ç‰¹å¾å‘é‡è€Œéåƒç´ æœ¬èº«ä½œä¸ºè¾“å…¥ï¼Œå…è®¸ç½‘ç»œåœ¨ä¸åŒåœºæ™¯çš„å¤šè§†å›¾å›¾åƒä¸Šè¿›è¡Œè®­ç»ƒï¼Œå­¦ä¹ åœºæ™¯å…ˆéªŒï¼Œç„¶åæµ‹è¯•æ—¶ç›´æ¥æ¥æ”¶ä¸€ä¸ªæˆ–å‡ ä¸ªè§†å›¾ä¸ºè¾“å…¥åˆæˆæ–°è§†å›¾ã€‚</li><li><a href="https://ibrnet.github.io/">IBRNet</a>ï¼šå­¦ä¹ ä¸€ä¸ªé€‚ç”¨äºå¤šç§åœºæ™¯çš„é€šç”¨è§†å›¾æ’å€¼å‡½æ•°ï¼Œä»è€Œä¸ç”¨ä¸ºæ¯ä¸ªæ–°çš„åœºæ™¯éƒ½æ–°å­¦ä¹ ä¸€ä¸ªæ¨¡å‹æ‰èƒ½æ¸²æŸ“ï¼›ä¸”ç½‘ç»œç»“æ„ä¸Šç”¨äº†å¦ä¸€ä¸ªæ—¶é«¦çš„ä¸œè¥¿ Transformerã€‚</li><li><a href="https://apchenstu.github.io/mvsnerf/">MVSNeRF</a>ï¼šè®­ç»ƒä¸€ä¸ªå…·æœ‰æ³›åŒ–æ€§èƒ½çš„å…ˆéªŒç½‘ç»œï¼Œåœ¨æ¨ç†çš„æ—¶å€™åªç”¨3å¼ è¾“å…¥å›¾ç‰‡å°±é‡å»ºä¸€ä¸ªæ–°çš„åœºæ™¯ã€‚</li></ul><p>é’ˆå¯¹åŠ¨æ€åœºæ™¯çš„NeRF:</p><ul><li><a href="https://nerfies.github.io/">Nerfies</a>ï¼šå¤šä½¿ç”¨äº†ä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºæ¥æ‹Ÿåˆå½¢å˜çš„SE(3) fieldï¼Œä»è€Œå»ºæ¨¡å¸§é—´åœºæ™¯å½¢å˜ã€‚Nerfies: Deformable Neural Radiance Fields</li><li><a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a>ï¼šå¤šä½¿ç”¨äº†ä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºæ¥æ‹Ÿåˆåœºæ™¯å½¢å˜çš„displacementã€‚</li><li><a href="https://link.zhihu.com/?target=http%3A//www.cs.cornell.edu/~zl548/NSFF/">Neural Scene Flow Fields</a>ï¼šå¤šæå‡ºäº†ä¸€ä¸ªscene flow fieldsæ¥æè¿°æ—¶åºçš„åœºæ™¯å½¢å˜ã€‚</li></ul><p>å…¶ä»–åˆ›æ–°ç‚¹ï¼š</p><ul><li><a href="https://kai-46.github.io/PhySG-website/">PhySG</a>ï¼šç”¨çƒçŠ¶é«˜æ–¯å‡½æ•°æ¨¡æ‹ŸBRDFï¼ˆé«˜çº§ç€è‰²çš„ä¸Šå¤ç¥å™¨ï¼‰å’Œç¯å¢ƒå…‰ç…§ï¼Œé’ˆå¯¹æ›´å¤æ‚çš„å…‰ç…§ç¯å¢ƒï¼Œèƒ½å¤„ç†éæœ—ä¼¯è¡¨é¢çš„åå°„ã€‚</li><li><a href="https://nex-mpi.github.io/">NeX</a>ï¼šç”¨MPIï¼ˆMulti-Plane Image ï¼‰ä»£æ›¿NeRFçš„RGBÏƒä½œä¸ºç½‘ç»œçš„è¾“å‡ºã€‚</li></ul><h3 id="cvpr-1">2022 CVPR</h3><p><a href="https://ajayj.com/dreamfields">Zero-Shot Text-Guided Object Generation with <strong>Dream Fields</strong></a></p><h2 id="useful-references"><strong>Useful References:</strong></h2><blockquote><p><a href="https://markboss.me/post/nerf_at_eccv22/?continueFlag=55ed0f6189bcd6ca987e08764bcbe945">NeRF at ECCV22 - Mark Boss</a></p><p><a href="https://markboss.me/post/nerf_at_neurips22/">NeRF at NeurIPS 2022 - Mark Boss</a></p><p><a href="https://dellaert.github.io/NeRF22/">NeRF at CVPR 2022 - Frank Dellaert</a></p><p><a href="https://youtu.be/PeRRp1cFuH4">CVPR 2022 Tutorial on Neural Fields in Computer Vision</a></p></blockquote><p>Bigger to learn:</p><ul><li>[ ] Above NeRF: neural rendering</li><li>[ ] Related theories in graphics and computer vision</li><li>[ ] NeRFçš„ä¸€ä½œBen Mildenhallåœ¨SIGGRAPH 2021 Course <a href="https://www.youtube.com/watch%3Fv%3Dotly9jcZ0Jg">Advances in Neural Rendering</a>ä¸­ä»æ¦‚ç‡çš„è§’åº¦æ¨å¯¼äº†NeRFçš„ä½“æ¸²æŸ“å…¬å¼ã€‚</li></ul><h1 id="introduction">1. Introduction</h1><h2 id="what-is-nerf">What is NeRF</h2><blockquote><p>Reference: Original NeRF paper; an online ariticle</p></blockquote><p>åœ¨å·²çŸ¥è§†è§’ä¸‹å¯¹åœºæ™¯è¿›è¡Œä¸€ç³»åˆ—çš„æ•è· (åŒ…æ‹¬æ‹æ‘„åˆ°çš„å›¾åƒï¼Œä»¥åŠæ¯å¼ å›¾åƒå¯¹åº”çš„å†…å¤–å‚)ï¼Œåˆæˆæ–°è§†è§’ä¸‹çš„å›¾åƒã€‚</p><p>NeRF æƒ³åšè¿™æ ·ä¸€ä»¶äº‹ï¼Œä¸éœ€è¦ä¸­é—´ä¸‰ç»´é‡å»ºçš„è¿‡ç¨‹ï¼Œä»…æ ¹æ®ä½å§¿å†…å‚å’Œå›¾åƒï¼Œç›´æ¥åˆæˆæ–°è§†è§’ä¸‹çš„å›¾åƒã€‚ä¸ºæ­¤ NeRF å¼•å…¥äº†è¾å°„åœºçš„æ¦‚å¿µï¼Œè¿™åœ¨å›¾å½¢å­¦ä¸­æ˜¯éå¸¸é‡è¦çš„æ¦‚å¿µï¼Œåœ¨æ­¤æˆ‘ä»¬ç»™å‡ºæ¸²æŸ“æ–¹ç¨‹çš„å®šä¹‰ï¼š</p><p><embed src="https://pic1.zhimg.com/80/v2-1a80de23a422688b739f36828affb8ec_1440w.webp" /></p><p><embed src="https://pic4.zhimg.com/80/v2-c469e4968a3e6cf8ec7a81f816de4f87_1440w.webp" /></p><p>é‚£ä¹ˆè¾å°„å’Œé¢œè‰²æ˜¯ä»€ä¹ˆå…³ç³»å‘¢ï¼Ÿç®€å•è®²å°±æ˜¯ï¼Œå…‰å°±æ˜¯ç”µç£è¾å°„ï¼Œæˆ–è€…è¯´æ˜¯æŒ¯è¡çš„ç”µç£åœºï¼Œå…‰åˆæœ‰æ³¢é•¿å’Œé¢‘ç‡ï¼Œ<span class="math inline">\(æ³¢é•¿\times é¢‘ç‡=å…‰é€Ÿ\)</span>ï¼Œå…‰çš„é¢œè‰²æ˜¯ç”±é¢‘ç‡å†³å®šçš„ï¼Œå¤§å¤šæ•°å…‰æ˜¯ä¸å¯è§çš„ï¼Œäººçœ¼å¯è§çš„å…‰è°±ç§°ä¸ºå¯è§å…‰è°±ï¼Œå¯¹åº”çš„é¢‘ç‡å°±æ˜¯æˆ‘ä»¬è®¤ä¸ºçš„é¢œè‰²ï¼š</p><p><embed src="https://pic1.zhimg.com/80/v2-381aa740f21b7eba1f896fd98dcc1308_1440w.webp" /></p><p><embed src="https://pic1.zhimg.com/80/v2-51bd3710b9f891c4c44fde12545e4fd4_1440w.webp" /></p><h3 id="sdf---signed-distance-function">SDF - Signed Distance Function</h3><p>SDFæ˜¯ä¸€ç§è®¡ç®—å›¾å½¢å­¦ä¸­å®šä¹‰è·ç¦»çš„å‡½æ•°ã€‚SDFå®šä¹‰äº†ç©ºé—´ä¸­çš„ç‚¹åˆ°éšå¼æ›²é¢çš„è·ç¦»ï¼Œè¯¥ç‚¹åœ¨æ›²é¢å†…å¤–å†³å®šäº†å…¶SDFçš„æ­£è´Ÿæ€§ã€‚</p><p>ç›¸è¾ƒäºå…¶ä»–åƒç‚¹äº‘ï¼ˆpoint cloudï¼‰ã€ä½“ç´ ï¼ˆvoxelï¼‰ã€é¢äº‘ï¼ˆmeshï¼‰é‚£æ ·çš„ç»å…¸3Dæ¨¡å‹è¡¨ç¤ºæ–¹æ³•ï¼ŒSDFæœ‰å›ºå®šçš„æ•°å­¦æ–¹ç¨‹ï¼Œæ›´å…³æ³¨ç‰©ä½“çš„è¡¨é¢ä¿¡æ¯ï¼Œå…·æœ‰å¯æ§çš„è®¡ç®—æˆæœ¬ã€‚</p><h2 id="features-of-nerf">Features of NeRF</h2><ul><li>Representation can be discrete or continuous. but the discrete representation will be a big one if you have more dimensions, e.g., 3 dim.<ul><li>Actually the Plenoxels try to use 3D grids to store the fields. Fast, however, too much memory.</li></ul></li><li>Neural Field has advantages:<ol type="1"><li>Compactness ç´§è‡´:</li><li>Regularization: nn itself as inductive bias makes it easy to learn</li><li>Domain Agonostic: cheap to add a dimension</li></ol></li><li>also problems<ul><li>Editability / Manipulability</li><li>Computational Complexity</li><li>Spectral Bias</li></ul></li></ul><h2 id="problem-formulation">Problem Formulation</h2><ul><li>Input: multiview images</li><li>Output: 3D Geometry and appearance</li><li>Objective:</li></ul><p><span class="math display">\[\arg \min_x\|y-F(x)\|+\lambda P(x)\]</span></p><p>y is multiview images, F is forward mapping, x is the desired 3D reconstruction.</p><p>F can be differentiable, then you can supervise this.</p><ul><li>nnæœ¬èº«å°±æ˜¯æŸç§constraintsï¼Œä½ å°±ä¸éœ€è¦åŠ å¤ªå¤šhandicraft constraints</li></ul><h1 id="techniques">2. Techniques</h1><h2 id="network-architecture">2.1. Network Architecture</h2><h3 id="input-encoding">1. Input Encoding</h3><p>Similar as NLP, they use position encodings. Like Sinusoid functions. I also remember an encoding method which takes into consider of the å…‰çº¿çš„æ•£å°„</p><h3 id="activation-functions">2. Activation functions</h3><p>ReLU is not perfect for this task. Because it ä¸èƒ½è§£å†³å¯¹é«˜é˜¶å¯¼æœ‰constraintsçš„å‡½æ•°ã€‚</p><p>SIREN is a replacement.</p><h3 id="symmetry-invariance-equivariance">3. Symmetry, Invariance &amp; Equivariance</h3><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221205193423558.png" alt="image-20221205193423558" /><figcaption>image-20221205193423558</figcaption></figure><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221205193614341.png" alt="image-20221205193614341" /><figcaption>image-20221205193614341</figcaption></figure><h2 id="hybrid-representations">2.2. Hybrid representations</h2><h3 id="tradeoffs-of-choosing-a-proper-representation">Tradeoffs of choosing a proper representation</h3><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221208172055153.png" alt="image-20221208172055153" /><figcaption>image-20221208172055153</figcaption></figure><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221208172209556.png" alt="image-20221208172209556" /><figcaption>image-20221208172209556</figcaption></figure><p>You may choose one proper representation depending on your own application</p><h3 id="grid">1. Grid</h3><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221205195659841.png" alt="image-20221205195659841" /><figcaption>image-20221205195659841</figcaption></figure><p>Input is too huge. Then you need too huge neural network. So, this grid interpolation acts like a &quot;position encoding&quot;, which encodes the low dimensional features into high dims.</p><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221208162026398.png" alt="image-20221208162026398" /><figcaption>image-20221208162026398</figcaption></figure><p>NeRFusion CVPR22: online!</p><h3 id="point-cloud">2. point cloud</h3><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221208162541770.png" alt="image-20221208162541770" /><figcaption>image-20221208162541770</figcaption></figure><p>Cons:</p><ol type="1"><li>To access local points, you need to specifically design the data structure. Otherwise, it is O(n)!</li><li>Choose different kernels to retrieve nearby points' features. Oftentimes you assume it is local kernel.</li></ol><p><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221208163050867.png" alt="image-20221208163050867" style="zoom:50%;" /></p><h3 id="mesh">3. Mesh</h3><p>Unstructed grids. Compared with point clouds, meshes have connectivity info.</p><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221208163526289.png" alt="image-20221208163526289" /><figcaption>image-20221208163526289</figcaption></figure><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221208163746237.png" alt="image-20221208163746237" /><figcaption>image-20221208163746237</figcaption></figure><h3 id="multiplanar-images">4. Multiplanar Images</h3><p>Something like project a 3D grid into an axis to get levels of planes.</p><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221208164038729.png" alt="image-20221208164038729" /><figcaption>image-20221208164038729</figcaption></figure><p>Pros:</p><ol type="1"><li>Compact</li><li>Very efficient because the hardware and software designs are accelerated to these 2D operations, like bi-linear operations.</li></ol><p>Cons:</p><ol type="1"><li>Resolution bias on plane axis: coz it is discrete betweens planes.</li></ol><p>This is not very wise in my opinion. It is just a temporary tradeoff given nowadays' technologies. Coz everything will be 3D in the future.</p><p><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221208165534056.png" alt="image-20221208165534056" />Generate 2D images from different camera views (perhaps). Key point is the tri-plane representation of 3D features.</p><h3 id="multiresolution-grids">5. Multiresolution grids</h3><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221208165714329.png" alt="image-20221208165714329" /><figcaption>image-20221208165714329</figcaption></figure><p>Pros:</p><ol start="2" type="1"><li>Stable coz you indeed need both low and high resolution info</li></ol><h3 id="hash-grids">6. Hash grids</h3><p><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221208170131069.png" alt="image-20221208170131069" /> <span class="math display">\[[x,y,z]\text{ coordinates}\rightarrow \text{Hash function()} \rightarrow \text{Fixed size codebook}\]</span> Pros:</p><ol type="1"><li>No matter how big is the original data, you can use a fixed size codebook as the input feature.</li><li>Can be online!</li></ol><p>Cons:</p><ol type="1"><li>May still need large codebooks</li><li>Features not spatially local. I don't think the hash grid is a good idea if this drawback exists. But isn't there a simple way to generate features with local info remaining?</li></ol><h3 id="codebook-grids">7. Codebook grids</h3><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221208170955887.png" alt="image-20221208170955887" /><figcaption>image-20221208170955887</figcaption></figure><p>Instead of storing features of points in grids, store a (index to a) code in a codebook. The size of the codebook is fixed, so the overall size can be controlled as much smaller.</p><p>cons:</p><ol type="1"><li>To make the indexing operation differentiable, the computing complexity rises here.</li><li>Using hash is to get rid of the complex data structure, but the indices bring it back.</li></ol><h3 id="bounding-volume-hierarchies">8. Bounding Volume Hierarchies</h3><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221208171806113.png" alt="image-20221208171806113" /><figcaption>image-20221208171806113</figcaption></figure><p>Commonly used method in computer graphics</p><h3 id="others-voxel">9. Others (voxel)</h3><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221208173124734.png" alt="image-20221208173124734" /><figcaption>image-20221208173124734</figcaption></figure><ul><li>For dynamic nerfs, is there any better hybrid representation? Sure.</li><li>Is there any explicit bias of these hybird representations that we can discover and then design regularization? Sure.</li></ul><h2 id="differentiable-forward-maps">2.3. Differentiable Forward Maps</h2><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221208175453557.png" alt="image-20221208175453557" /><figcaption>image-20221208175453557</figcaption></figure><h3 id="differentiable-rendering">Differentiable rendering</h3><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221208181457315.png" alt="image-20221208181457315" /><figcaption>image-20221208181457315</figcaption></figure><p>Volume rendering can render fogs. Sphere rendering only render the solid surface, and needs ground truth supervision.? Neural renderer combines the two.</p><h3 id="differentiability-of-the-rendering-function-itself">Differentiability of the rendering function itself</h3><ul><li>BRDF Shading? details later.</li></ul><h3 id="differentiation-itself">Differentiation itself</h3><p>Design a neural network with higher order derivatives constraints and therefore directly use its derivative.</p><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221208182302568-0494983.png" alt="image-20221208182302568" /><figcaption>image-20221208182302568</figcaption></figure><p>For example the Eikonal equation forces the neural network has a derivative as 1. Adding the eikonal loss then promises the neural network valid.</p><p>Generally, this kind of problems are: the solutions are constrained by its partial derivatives.</p><h3 id="special-identity-operator">Special: Identity Operator</h3><p><span class="math display">\[\text{Reconstruction} \rightarrow \hat 1()\rightarrow \text{Sensor domain}\\\text{Reconstruction} == \text{Sensor domain}\]</span></p><p>Q&amp;A:</p><ul><li>Can we obtain a neural network in just one forward, without optimization?</li><li>Can we design special forward maps for specific downstream tasks, eg., classification? Absolutely yes. We can design it to represent a compact representation as the sensor domain. The key idea is to get a differentiable function to map your specific recon and sensor domain.</li></ul><h2 id="prior-based-reconstruction-of-neural-fields">2.4. Prior-based reconstruction of neural fields</h2><p>Sounds like a one-shot task: instead of fitting and optimizing a neural field each for one scene; let's learn a prior distribution of neural field. Then, given a specific scene, it adjusts the neural field in just one forward.</p><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221211234430727.png" alt="image-20221211234430727" /><figcaption>image-20221211234430727</figcaption></figure><h3 id="how-does-the-latent-code-look-like">How does the latent code look like?</h3><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221211234923290.png" alt="image-20221211234923290" /><figcaption>image-20221211234923290</figcaption></figure><ul><li>Global: not local. A small latent code represents a neural field<ul><li>main limitation: can only represent very simple (single) object. coz if you have multiple objects in a scene, the degree of freedom grows non-linearly.</li><li><strong>How about giving the natural language descriptions as conditions???</strong></li></ul></li><li>Local: you get different latent codes considering the locality where you are. So, you have a prior 3D data structure to store the latent codes.<ul><li>3D point clouds -&gt; grids -&gt; triplanes interpolation</li></ul></li></ul><blockquote><p>Convolutional Occupancy Networks</p></blockquote><h3 id="autodecoder-instead-of-encoder-decoder">Autodecoder instead of Encoder-decoder</h3><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221212005012783.png" alt="image-20221212005012783" /><figcaption>image-20221212005012783</figcaption></figure><ul><li><p>Encoder is a 2D CNN structure.</p></li><li><p>But while using autodecoder, the backpropogate through the forward map (i.e., the neural renderer) will give the 3D structural information to the latent codes directly. <span class="math display">\[\text{latent code }\hat z=\arg \min_z \|\text{Render(}\Phi)-g.t.\|\]</span> <img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221212004946040.png" alt="image-20221212004946040" /></p></li></ul><p><strong>Instead of trying to build the encoder, sometimes just use the backpropogation through the forward map is helpful.</strong></p><h3 id="light-field-networks----dont-need-to-render-anymore">Light field networks -- Don't need to render anymore</h3><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221212005908926.png" alt="image-20221212005908926" /><figcaption>image-20221212005908926</figcaption></figure><p>Instead of learning a NeRF that you use a neural renderer to generate all points along a ray; you can learn a network to directly give you a color along a ray. So you do not use a 3d coordinate as the query, instead, use a ray.</p><p>But this do not work in complicated task yet.</p><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221212010316991.png" alt="image-20221212010316991" /><figcaption>image-20221212010316991</figcaption></figure><h3 id="outlook">Outlook</h3><ul><li>You don't need to use 600 images of a scene to reconstruct it. Synthesis images?</li><li>Open minds: other ways to skip the expensive forward map? (e.g., the light field)</li><li>Understanding the scene like humans do: disentangle different objects</li><li>Local conditioning methods? Regular grids are easy to tackle with, but it's harder for point clouds / factorized representations</li><li>Transformers: seems like local conditioning</li></ul><h2 id="manipulate-neural-fields">2.5. Manipulate Neural Fields</h2><p>Neural fields is ready to be a prime representation, similar as point clouds or meshes, that is able to be manipulated.</p><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221212211525928.png" alt="image-20221212211525928" /><figcaption>image-20221212211525928</figcaption></figure><p>You can either edit the input coordinates, or edit the parameters <span class="math inline">\(\theta\)</span>.</p><p>On the other axis, you can edit through an explicit geometry, or an implicit neural fields.</p><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221212213802209.png" alt="image-20221212213802209" /><figcaption>image-20221212213802209</figcaption></figure><p>The following examples è½åœ¨ä¸åŒçš„è±¡é™ã€‚</p><h3 id="editing-the-input-via-explicit-geometry-left-up">Editing the input via Explicit geometry (left-up)</h3><ul><li><p>You can represent each object using a separated neural field (local frame), and then compose them together in different ways.</p></li><li><p>If you want to manipulate not only spatially, but also <strong>temporaly</strong>, it is also possible. You can add a time coordinate as the input of the neural field network, and transform the time input.</p></li><li><p>You can also manipulate (especially human body) via <strong>skeleton</strong>.</p><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221212212838893.png" alt="image-20221212212838893" /><figcaption>image-20221212212838893</figcaption></figure><ul><li><p><strong>Beyond human</strong>, we can also first estimate different moving parts of an object, to form some skeleton structure, and then do the same.</p><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221212213151594.png" alt="Noguchi etal, CVPR22" /><figcaption>Noguchi etal, CVPR22</figcaption></figure></li></ul></li><li><p>Beyond rigid, we can also manipulate via <strong>mesh</strong>. coz we have plenty of manipulation tools on mesh. The deformation on mesh can be re-mapped as the deformation on the input coordinate</p><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20221212213601773.png" alt="image-20221212213601773" /><figcaption>image-20221212213601773</figcaption></figure></li></ul><h3 id="editing-the-input-via-neural-flow-fields-left-down">Editing the input via Neural Flow Fields (left-down)</h3><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20230104183222294.png" alt="image-20230104183222294" /><figcaption>image-20230104183222294</figcaption></figure><p>We use the <span class="math inline">\(f_{i\rightarrow j}\)</span> to edit the <span class="math inline">\(r_{i\rightarrow j}\)</span> to represent one ray into another one.</p><p>We need to define the consistency here, so that the network can learn through forward and backward:</p><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20230104183453487.png" alt="image-20230104183453487" /><figcaption>image-20230104183453487</figcaption></figure><h3 id="editing-network-parameters-via-explicit-geometry-right-up">Editing network parameters via Explicit geometry (right-up)</h3><p>The knowledge is already in the network. So instead of editing the inputs, we can directly edit the network parameters for generating new things.</p><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20230104185014312.png" alt="image-20230104185014312" /><figcaption>image-20230104185014312</figcaption></figure><ul><li>This proposed solution makes use of an encoder. The encoder learns to represent the rotated input as a high-dimensional latent code Z, with the same rotation R, in 3-dim space. The the following network use the latent code to generate the <span class="math inline">\(f_\theta\)</span></li></ul><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20230104185544623.png" alt="image-20230104185544623" /><figcaption>image-20230104185544623</figcaption></figure><ul><li>In this work, the key idea is to map the high-resolutional object and the similar but lower resolutional object into the same latent space. Then, you can easily manipulate the lower resolutional object, and it should also affect the higher resolutional one. Then, the shared latent space are put into the following neural field network, which outputs high resolutional results.</li></ul><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20230104202425695.png" alt="image-20230104202425695" /><figcaption>image-20230104202425695</figcaption></figure><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20230104202625346.png" alt="image-20230104202625346" /><figcaption>image-20230104202625346</figcaption></figure><ul><li>This work (Yang et al. NeurlPS'21) about shape editing is &quot;super important&quot; but the speaker does not have enough time... Basically it shows that the tools that we use to manipulate a mesh can also be used on a neural field, where we can keep some of the network parameters to make sure the basic shape of the object the same, and then the magical thing is the &quot;curvature manipulation&quot; item. Given the neural field is differentiable, this can be achieved.</li></ul><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20230104203311551.png" alt="image-20230104203311551" /><figcaption>image-20230104203311551</figcaption></figure><ul><li>Obeying the points (a.k.a generalization). It makes sure the manipulation done on the input points are reconstructed.</li></ul><h3 id="editing-network-parameters-via-neural-fields-right-down">Editing network parameters via Neural Fields (right-down)</h3><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20230104204330741.png" alt="image-20230104204330741" /><figcaption>image-20230104204330741</figcaption></figure><ul><li>This work constructs a reasonable latent space of the object, then do interpolation of different objects.</li><li>Beyond geometry, we can also manipulate <strong>color</strong></li></ul><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20230104204738067.png" alt="image-20230104204738067" /><figcaption>image-20230104204738067</figcaption></figure><p>It decomposes the network into shape and color networks, and we can edit each independently.</p><figure><img src="/Users/jiayinzhu/Documents/ç¬”è®°/æ”¾å›¾/image-20230104204937204.png" alt="image-20230104204937204" /><figcaption>image-20230104204937204</figcaption></figure><ul><li>This is the stylization work. It mainly depends on a different loss function, which does not search for the exact feature of the vgg, but somehow the nearest neighbor.</li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;learning-nerf&quot;&gt;Learning NeRF&lt;/h1&gt;
&lt;h2 id=&quot;reading-list&quot;&gt;Reading List&lt;/h2&gt;
&lt;h3 id=&quot;classical&quot;&gt;Classical&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Mildenhall &lt;em&gt;et al.&lt;/em&gt; introduced NeRF at ECCV 2020 in the now seminal &lt;a href=&quot;https://www.matthewtancik.com/nerf&quot;&gt;Neural Radiance Field paper&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is done by storing the density and radiance in a neural volumetric scene representation using MLPs and then rendering the volume to create new images.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://m-niemeyer.github.io/project-pages/giraffe/index.html&quot;&gt;GIRAFFE&lt;/a&gt;: Compositional Generative Neural Feature Fields&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Computer Notes" scheme="https://jyzhu.top/categories/Computer-Notes/"/>
    
    
    <category term="Computer Vision" scheme="https://jyzhu.top/tags/Computer-Vision/"/>
    
    <category term="NeRF" scheme="https://jyzhu.top/tags/NeRF/"/>
    
  </entry>
  
  <entry>
    <title>The difference between RNN&#39;s output and h_n</title>
    <link href="https://jyzhu.top/The-difference-between-RNN-s-output-and-h-n/"/>
    <id>https://jyzhu.top/The-difference-between-RNN-s-output-and-h-n/</id>
    <published>2022-10-22T08:56:44.000Z</published>
    <updated>2022-10-22T09:12:01.123Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Reference: <a href="https://stackoverflow.com/questions/48302810/whats-the-difference-between-hidden-and-output-in-pytorch-lstm" class="uri">https://stackoverflow.com/questions/48302810/whats-the-difference-between-hidden-and-output-in-pytorch-lstm</a></p></blockquote><p>I was so confused when doing a homework on implementing the Luong Attention, because it tells that the decoder is a RNN, which takes <span class="math inline">\(y_{t-1}\)</span> and <span class="math inline">\(s_{t-1}\)</span> as input, and outputs <span class="math inline">\(s_t\)</span>, i.e., <span class="math inline">\(s_t = RNN(y_{t-1}, s_{t-1})\)</span>.</p><p>But the pytorch implementation of RNN is: <span class="math inline">\(outputs, hidden\_last = RNN(inputs, hidden\_init)\)</span>, which takes in a sequence of elements, computes in serials, and outputs a sequence also.</p><p>I was confused about what is the <span class="math inline">\(s_t\)</span>. Is it the <span class="math inline">\(outputs\)</span>, or the <span class="math inline">\(hidden\_states\)</span>?</p><p>This is the very helpful picture:</p><p><img src="https://i.stack.imgur.com/SjnTl.png" /></p><p>The <span class="math inline">\(output\)</span> here is the <span class="math inline">\(hidden\_states\)</span> of the last layer among all elements in the sequence (time steps), while the <span class="math inline">\(h_n,c_n = hidden\_last\)</span> is the <span class="math inline">\(hidden\_states\)</span> of the last time step among all layers.</p><p>The former is the <span class="math inline">\(H\)</span>, hidden state collection, which can be used in subsequent calculations, like attentions or scores; and the latter is the hidden state that can be directly used in the next iteration.</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Reference: &lt;a href=&quot;https://stackoverflow.com/questions/48302810/whats-the-difference-between-hidden-and-output-in-pytorch-lstm&quot; class=&quot;uri&quot;&gt;https://stackoverflow.com/questions/48302810/whats-the-difference-between-hidden-and-output-in-pytorch-lstm&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I was so confused when doing a homework on implementing the Luong Attention, because it tells that the decoder is a RNN, which takes &lt;span class=&quot;math inline&quot;&gt;\(y_{t-1}\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(s_{t-1}\)&lt;/span&gt; as input, and outputs &lt;span class=&quot;math inline&quot;&gt;\(s_t\)&lt;/span&gt;, i.e., &lt;span class=&quot;math inline&quot;&gt;\(s_t = RNN(y_{t-1}, s_{t-1})\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;But the pytorch implementation of RNN is: &lt;span class=&quot;math inline&quot;&gt;\(outputs, hidden\_last = RNN(inputs, hidden\_init)\)&lt;/span&gt;, which takes in a sequence of elements, computes in serials, and outputs a sequence also.&lt;/p&gt;
&lt;p&gt;I was confused about what is the &lt;span class=&quot;math inline&quot;&gt;\(s_t\)&lt;/span&gt;. Is it the &lt;span class=&quot;math inline&quot;&gt;\(outputs\)&lt;/span&gt;, or the &lt;span class=&quot;math inline&quot;&gt;\(hidden\_states\)&lt;/span&gt;?&lt;/p&gt;</summary>
    
    
    
    <category term="Computer Notes" scheme="https://jyzhu.top/categories/Computer-Notes/"/>
    
    
    <category term="Deep Learning" scheme="https://jyzhu.top/tags/Deep-Learning/"/>
    
    <category term="Neural Network" scheme="https://jyzhu.top/tags/Neural-Network/"/>
    
  </entry>
  
  <entry>
    <title>Reading 3D Photography using Context-aware Layered Depth Inpainting</title>
    <link href="https://jyzhu.top/Reading-3D-Photography-using-Context-aware-Layered-Depth-Inpainting/"/>
    <id>https://jyzhu.top/Reading-3D-Photography-using-Context-aware-Layered-Depth-Inpainting/</id>
    <published>2022-10-07T00:35:43.000Z</published>
    <updated>2022-10-22T09:15:26.167Z</updated>
    
    <content type="html"><![CDATA[<p>è®ºæ–‡åœ°å€ï¼š<a href="https://shihmengli.github.io/3D-Photo-Inpainting" class="uri">https://shihmengli.github.io/3D-Photo-Inpainting</a></p><p>ä½œè€…ï¼š<a href="https://shihmengli.github.io/">Meng-Li Shih</a>, <a href="https://lemonatsu.github.io/">Shih-Yang Su</a>, <a href="https://johanneskopf.de/">Johannes Kopf</a>, <a href="https://filebox.ece.vt.edu/~jbhuang/">Jia-Bin Huang</a></p><p>å‘è¡¨ï¼š CVPR2020</p><p>é“¾æ¥ï¼š <a href="https://github.com/vt-vl-lab/3d-photo-inpainting" class="uri">https://github.com/vt-vl-lab/3d-photo-inpainting</a></p><hr /><h2 id="why">Whyï¼š</h2><p>ä¹‹å‰çš„ç…§ç‰‡3DåŒ–çš„æ–¹æ³•ï¼Œä¼šåœ¨è§†è§’å˜åŠ¨åå‡ºç°çš„æ–°åƒç´ åŒºåŸŸ å¡«å……å¾ˆæ¨¡ç³Šçš„èƒŒæ™¯ï¼›è¿™ä¸ªæ–¹æ³•ä¸»è¦æ˜¯ç”¨inpaintingçš„æ–¹æ³•æé«˜æ–°èƒŒæ™¯ç”Ÿæˆçš„æ•ˆæœ</p><figure><img src="https://s2.loli.net/2022/10/22/dfjuy9vNrBak1oP.png" alt="image-20221007084129382" /><figcaption>image-20221007084129382</figcaption></figure><h2 id="what">Whatï¼š</h2><ol type="1"><li>ä»»åŠ¡æ˜¯3D photographyï¼Œå›¾åƒ3DåŒ–ï¼ŒæŠŠä¸€å¼ 2D+æ·±åº¦ä¿¡æ¯çš„RGB-Då›¾åƒè½¬åŒ–æˆ3Dé£æ ¼çš„å›¾åƒã€‚</li><li>ç°åœ¨çš„å¤šé•œå¤´æ™ºèƒ½æ‰‹æœºæ‹çš„ç…§ç‰‡éƒ½èƒ½æä¾›æ·±åº¦ä¿¡æ¯ã€‚æ²¡æœ‰çš„è¯ï¼Œä¹Ÿèƒ½ç”¨å…¶ä»–æ¨¡å‹é¢„æµ‹æ·±åº¦ã€‚</li><li>ç”¨åˆ†å±‚æ·±åº¦å›¾åƒï¼ˆLayered Depth Imageï¼‰æ¥è¡¨ç¤ºå›¾åƒï¼šèƒ½æ˜¾å¼åœ°è¡¨ç¤ºåƒç´ ç‚¹ä¹‹é—´çš„è¿é€šæ€§ã€‚å’Œæ™®é€šçš„2Då›¾åƒç›¸æ¯”ï¼Œå¯ä»¥æŠŠåƒç´ ç‚¹åˆ†æˆå¤šå±‚æ¥è¡¨ç¤ºï¼ŒåŒä¸€ä¸ªåæ ‡å¤„å¯ä»¥æœ‰é‡åˆçš„ä¸åŒå±‚æ¬¡çš„åƒç´ ç‚¹ã€‚</li><li>æå‡ºä¸€ä¸ªåŸºäºå­¦ä¹ çš„ inpainting æ–¹æ³•å¡«å……é‡å åŒºåŸŸçš„åƒç´ ï¼Œè®©3Då›¾åƒè§†è§’å˜åŒ–çš„æ—¶å€™å‡ºç°çš„æ–°èƒŒæ™¯æ•ˆæœå¾ˆå¥½ã€‚</li></ol><h2 id="how">Howï¼š</h2><p>æ˜¯ä¸€ä¸ªå¾ˆæ¸…æ™°çš„æµç¨‹ï¼š</p><ol type="1"><li><p>è¾“å…¥ä¸ºå•å¼ RGB-Då›¾åƒã€‚Dä¸ºdepthï¼Œä¸€èˆ¬å¤šé•œå¤´æ™ºèƒ½æ‰‹æœºæ‹æ‘„çš„ç…§ç‰‡éƒ½èƒ½æä¾›æ·±åº¦ä¿¡æ¯ï¼›æ²¡æœ‰çš„è¯å°±ç”¨å…¶ä»–æ¨¡å‹é¢„æµ‹æ·±åº¦ï¼Œæ¯”å¦‚MegaDepth, MiDas, and Kinect depth sensor</p></li><li><p>å°†è¾“å…¥å›¾åƒè½¬åŒ–æˆåˆ†å±‚æ·±åº¦å›¾åƒï¼ˆLayered Depth Imageï¼‰ã€‚LDIä¸­çš„æ¯ä¸ªåƒç´ ç‚¹ä¿å­˜é¢œè‰²å’Œæ·±åº¦ä¿¡æ¯ï¼Œä»¥åŠä¸Šä¸‹å·¦å³å››ä¸ªæ–¹å‘çš„é‚»å±…åƒç´ ç‚¹ã€‚åŒä¸€ä¸ªåæ ‡å¤„å¯ä»¥æœ‰é‡åˆçš„ä¸åŒæ·±åº¦çš„åƒç´ ç‚¹ã€‚</p></li><li><p>å›¾åƒé¢„å¤„ç†ï¼šæ£€æµ‹æ·±åº¦ä¸è¿è´¯çš„è¾¹ç¼˜</p><figure><img src="https://s2.loli.net/2022/10/22/6tjCgUHTpVyIAFN.png" alt="image-20221007090910332" /><figcaption>image-20221007090910332</figcaption></figure><p>ç”¨filteræŠŠæ·±åº¦è¾¹ç¼˜è¿‡æ»¤å¾—æ›´é”åˆ©ï¼Œç„¶åæ¸…ç†ä¸€äº›ä¸è¿è´¯çš„è¾¹ç¼˜ï¼Œæœ€åæ ¹æ®è¿é€šæ€§åˆ’åˆ†ä¸åŒçš„æ·±åº¦è¾¹ï¼ˆå¦‚å›¾2 ï¼ˆfï¼‰ä¸­ï¼Œä¸åŒé¢œè‰²è¡¨ç¤ºä¸åŒæ·±åº¦è¾¹ï¼‰ã€‚</p></li><li><p>å¯¹äºæ¯ä¸€ä¸ªæ·±åº¦è¾¹ï¼ŒæŠŠLDIå›¾ä¸­çš„åƒç´ ç‚¹åˆ‡å‰²å¼€ï¼Œå¹¶åœ¨èƒŒæ™¯å±‚æ‰©å±•ä¸€äº›åƒç´ ç‚¹ï¼Œå¯¹æ‰©å±•åŒºåŸŸè¿›è¡Œç”Ÿæˆ</p><figure><img src="https://s2.loli.net/2022/10/22/Ap62PxdYEDKzBkJ.png" alt="image-20221007091217942" /><figcaption>image-20221007091217942</figcaption></figure><ol type="1"><li><p>æ‰¾åˆ°ä¸€ä¸ªæ·±åº¦è¾¹ï¼ŒæŠŠä¸¤å±‚çš„åƒç´ ç‚¹åˆ‡å‰²å¼€</p></li><li><p>å¯¹äºèƒŒæ™¯å±‚ï¼Œç”¨flood-fill likeç®—æ³•è¿­ä»£åœ°é€‰å–ä¸€å®šçš„å·²çŸ¥åŒºåŸŸä½œä¸ºcontext regionï¼Œä»¥åŠæ‰©å±•ä¸€å®šçš„æœªçŸ¥åŒºåŸŸä½œä¸ºsynthesis region</p></li><li><p>åˆ©ç”¨å·²çŸ¥context region ç”ŸæˆæœªçŸ¥synthesis region çš„æ·±åº¦å’Œé¢œè‰²ï¼šé‡‡ç”¨åŸºäºå­¦ä¹ çš„inpaintingæ–¹æ³•</p><figure><img src="https://s2.loli.net/2022/10/22/h8uGZm4XAEcL5SP.png" alt="image-20221007091716266" /><figcaption>image-20221007091716266</figcaption></figure><p>è¿™ä¸ªæ–¹æ³•ä¸­ï¼Œæœ€å…³é”®çš„å°±æ˜¯åœ¨é¢„æµ‹colorå’Œdepthä¹‹å‰ï¼Œå…ˆé¢„æµ‹äº†ä¸€ä¸‹depth edgesï¼Œç„¶åæŠŠè¿™ä¸ªedgesä¿¡æ¯åŠ è¿›å»ï¼Œå¯ä»¥æ›´å¥½åœ°é¢„æµ‹colorå’Œdepthã€‚</p></li><li><p>å°†ç”Ÿæˆå®Œæ¯•çš„åƒç´ èåˆå›LDIå›¾åƒ</p></li></ol></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;è®ºæ–‡åœ°å€ï¼š&lt;a href=&quot;https://shihmengli.github.io/3D-Photo-Inpainting&quot; class=&quot;uri&quot;&gt;https://shihmengli.github.io/3D-Photo-Inpainting&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ä½œè€…ï¼š&lt;a href=&quot;https://shihmengli.github.io/&quot;&gt;Meng-Li Shih&lt;/a&gt;, &lt;a href=&quot;https://lemonatsu.github.io/&quot;&gt;Shih-Yang Su&lt;/a&gt;, &lt;a href=&quot;https://johanneskopf.de/&quot;&gt;Johannes Kopf&lt;/a&gt;, &lt;a href=&quot;https://filebox.ece.vt.edu/~jbhuang/&quot;&gt;Jia-Bin Huang&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;å‘è¡¨ï¼š CVPR2020&lt;/p&gt;
&lt;p&gt;é“¾æ¥ï¼š &lt;a href=&quot;https://github.com/vt-vl-lab/3d-photo-inpainting&quot; class=&quot;uri&quot;&gt;https://github.com/vt-vl-lab/3d-photo-inpainting&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Computer Notes" scheme="https://jyzhu.top/categories/Computer-Notes/"/>
    
    
    <category term="Computer Vision" scheme="https://jyzhu.top/tags/Computer-Vision/"/>
    
    <category term="3DCV" scheme="https://jyzhu.top/tags/3DCV/"/>
    
  </entry>
  
  <entry>
    <title>Reading SmoothNet: A Plug-and-Play Network for Refining Human Poses in Videos</title>
    <link href="https://jyzhu.top/Reading-SmoothNet-A-Plug-and-Play-Network-for-Refining-Human-Poses-in-Videos/"/>
    <id>https://jyzhu.top/Reading-SmoothNet-A-Plug-and-Play-Network-for-Refining-Human-Poses-in-Videos/</id>
    <published>2022-09-09T06:25:03.000Z</published>
    <updated>2022-10-22T09:16:13.032Z</updated>
    
    <content type="html"><![CDATA[<p>è®ºæ–‡åœ°å€ï¼šhttps://arxiv.org/abs/2112.13715</p><p>ä½œè€…ï¼š<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng%2C+A">Ailing Zeng</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang%2C+L">Lei Yang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ju%2C+X">Xuan Ju</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+J">Jiefeng Li</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+J">Jianyi Wang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+Q">Qiang Xu</a></p><p>å‘è¡¨ï¼š ECCV 2022</p><p>é“¾æ¥ï¼š <a href="https://github.com/cure-lab/SmoothNet" class="uri">https://github.com/cure-lab/SmoothNet</a></p><hr /><blockquote><p>å¦‚æœä½ å»åšè¿™ä¸ªä»»åŠ¡ï¼Œä¼šæ€ä¹ˆåšï¼Ÿä½œè€…åšçš„æ–¹æ³•å’Œä½ æƒ³çš„æœ‰ä»€ä¹ˆå·®å¼‚ï¼Ÿ</p></blockquote><h2 id="why">Whyï¼š</h2><ol type="1"><li>ä»è§†é¢‘ä¼°è®¡äººä½“å§¿åŠ¿æ—¶ï¼ŒæŠ–åŠ¨æ˜¯ä¸ªé—®é¢˜</li><li>é™¤äº†è½»å¾®æŠ–åŠ¨ä»¥å¤–ï¼Œæœ‰ä¸€äº›long- termæŠ–åŠ¨ï¼Œè¿˜æœ‰å› ä¸ºé‡å ã€å§¿åŠ¿å°‘è§ç­‰åŸå› é€ æˆçš„ä¼°æµ‹å›°éš¾</li></ol><h2 id="what">Whatï¼š</h2><figure><img src="https://s2.loli.net/2022/10/22/fRIB2t9hw8na6my.png" alt="image-20220909143919787" /><figcaption>image-20220909143919787</figcaption></figure><ol type="1"><li>ä¸€ä¸ªä»…åŸºäºæ—¶åºçš„ç²¾ç‚¼ç½‘ç»œï¼Œä»¥å…¶ä»–ç½‘ç»œçš„å§¿åŠ¿ä¼°è®¡ç»“æœä½œä¸ºè¾“å…¥ã€‚</li><li>æœ‰ç›‘ç£çš„</li><li>é‡‡ç”¨æ»‘åŠ¨çª—å£ï¼ŒåŸºäºTCN</li><li>å¹¶ä¸æ˜¯å¸¸è§çš„é‚£ç§åŸºäºå­¦ä¹ çš„æ–¹æ³•ï¼Œå³é‡‡ç”¨æ—¶é—´-ç©ºé—´æ¨¡å‹æ¥åŒæ—¶ä¼˜åŒ–é€å¸§çš„å‡†ç¡®ç‡å’Œæ—¶åºçš„å¹³æ»‘æ€§ã€‚è¿™ä¸ªæ–¹æ³•é€šè¿‡å­¦ä¹ æ¯ä¸€ä¸ªå…³èŠ‚åœ¨é•¿æ—¶é—´èŒƒå›´çš„è¿åŠ¨ç‰¹å¾ï¼ˆè€Œä¸æ˜¯å…³èŠ‚ä¹‹é—´çš„å…³ç³»ï¼‰ï¼Œæ¥è‡ªç„¶åœ°å»ºæ¨¡èº«ä½“è¿åŠ¨ä¸­çš„å¹³æ»‘ç‰¹å¾ã€‚</li><li>ç”±äºå®ƒä»…ä»…éœ€è¦æ—¶åºä¿¡æ¯ï¼Œæ‰€ä»¥å¯ä»¥æ³›åŒ–åˆ°å¾ˆå¤šç§ä»»åŠ¡ä¸Šï¼ŒåŒ…æ‹¬2Då’Œ3Dçš„å§¿åŠ¿ä¼°è®¡ã€body recoveryç­‰</li></ol><h2 id="how">Howï¼š</h2><ol type="1"><li><p>æ ¹æ®æŒç»­æ—¶é•¿ï¼Œå°†æŠ–åŠ¨å½’ç±»ä¸ºsudden jitterå’Œlong- term jitterä¸¤ç§ã€‚ä¸ºäº†è§£å†³long- termçš„æŠ–åŠ¨é—®é¢˜ï¼Œç°æœ‰é‚£äº›æ–¹æ³•éƒ½ä¸å¤§è¡Œã€‚</p><p>æ ¹æ®ç¨‹åº¦ï¼Œåˆå¯ä»¥å°†æŠ–åŠ¨åˆ†ä¸ºå°æŠ–åŠ¨å’Œå¤§æŠ–åŠ¨ã€‚å°æŠ–åŠ¨ä¸€èˆ¬ç”±äºä¸å¯é¿å…çš„è¯¯å·®ï¼Œæˆ–è€…æ ‡æ³¨ä¸Šçš„è¯¯å·®ï¼›å¤§æŠ–åŠ¨åˆ™æ˜¯ç”±äºå›¾åƒè´¨é‡å·®ã€å§¿åŠ¿å°‘ã€é‡å ä¸¥é‡ç­‰ã€‚</p><figure><img src="https://s2.loli.net/2022/10/22/pNa7bcVqzi9lGZw.png" alt="image-20220909143902334" /><figcaption>image-20220909143902334</figcaption></figure></li><li><p>å°†è¯¯å·®å½’ç±»ä¸ºç›¸é‚»å¸§ä¹‹é—´çš„æŠ–åŠ¨é€ æˆçš„è¯¯å·®ï¼ˆjitter errorï¼‰å’Œæ¨¡å‹ä¼°è®¡ç»“æœä¸çœŸå®ç»“æœä¹‹é—´çš„åå·®ï¼ˆbias errorï¼‰è¿™ä¸¤ç§ã€‚ç°æœ‰é‚£äº›æ–¹æ³•å¹¶æ²¡æœ‰å°†è¿™ä¸¤ç±»è¯¯å·®è§£è€¦</p></li><li><p>æå‡ºäº†basic smoothnetå’Œæ­£ç»smoothnetã€‚</p><ol type="1"><li><figure><img src="https://s2.loli.net/2022/10/22/Zf6lpahbHrRG7kF.png" alt="image-20220909154626864" /><figcaption>image-20220909154626864</figcaption></figure><p>Basic smoothnetï¼ŒFCNæ˜¯backboneã€‚é€šè¿‡é•¿åº¦ä¸ºTçš„æ»‘çª—ï¼Œæ¯æ¬¡ä¼ å…¥Tå¸§å›¾åƒï¼ŒåŒ…å«Cä¸ªchannelsã€‚</p><figure><img src="https://s2.loli.net/2022/10/22/hRcX2MCx8SnHZfz.png" alt="image-20220909155504588" /><figcaption>image-20220909155504588</figcaption></figure><p>æƒé‡<span class="math inline">\(w_t^l\)</span>å’Œåå·®<span class="math inline">\(b^l\)</span>æ˜¯ç¬¬<span class="math inline">\(t_{th}\)</span>å¸§çš„ï¼Œå¹¶ä¸”åœ¨ä¸åŒçš„channelä¹‹é—´æ˜¯å…±äº«çš„ã€‚</p></li><li><figure><img src="https://s2.loli.net/2022/10/22/uCJgF8M6tG5S1PB.png" alt="image-20220909155701901" /><figcaption>image-20220909155701901</figcaption></figure><p>å®Œæ•´çš„motion- aware smoothnetå°±æ˜¯åŠ ä¸Šäº†é€Ÿåº¦å’ŒåŠ é€Ÿåº¦ä¸¤ä¸ªæ¨¡å—ã€‚</p><p>å› ä¸ºjitterçš„ä¸€ä¸ªè¡¡é‡æ–¹å¼å°±æ˜¯åŠ é€Ÿåº¦ï¼Œæ‰€ä»¥æŠŠåŠ é€Ÿåº¦ç›´è§‚åœ°æ˜¾ç¤ºåœ¨æ¨¡å‹ä¸­æ˜¯ä¸€ä¸ªå¾ˆæ˜¾ç„¶çš„æ–¹å¼ã€‚ç»™å®šé¢„æµ‹å‡ºçš„å§¿åŠ¿<span class="math inline">\(\hat Y\)</span>ï¼Œé€Ÿåº¦å°±æ˜¯ä¸¤å¸§ä¹‹é—´ç›¸å‡ï¼Œå¾—åˆ° <span class="math display">\[\hat V_{i,t} = \hat Y_{i,t} âˆ’ \hat Y_{i,tâˆ’1}\]</span> åŠ é€Ÿåº¦å°±æ˜¯é€Ÿåº¦ä¹‹é—´çš„å·®ï¼š <span class="math display">\[\hat A_{i,t} = \hat V_{i,t} âˆ’ \hat V_{i,tâˆ’1}\]</span></p></li></ol></li><li><p>losså°±æ˜¯ä¸¤ä¸ªï¼š</p><ol type="1"><li><p>ground truth poseå’Œä¼°è®¡poseä¹‹é—´çš„è¯¯å·®ï¼š <span class="math display">\[L_{pose} = \frac{1}{T\times C} \sum_{t=0}^T \sum_{i=0}^C |\hat G_{i,t} âˆ’ Y_{i,t}|,\]</span></p></li><li><p>ground truth åŠ é€Ÿåº¦å’Œä¼°è®¡åŠ é€Ÿåº¦ä¹‹é—´çš„è¯¯å·®ï¼š <span class="math display">\[L_{acc} = \frac{1}{(T-2)\times C} \sum_{t=0}^T \sum_{i=0}^C |\hat G&#39;&#39;_{i,t} âˆ’ A_{i,t}|,\]</span></p></li></ol></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;è®ºæ–‡åœ°å€ï¼šhttps://arxiv.org/abs/2112.13715&lt;/p&gt;
&lt;p&gt;ä½œè€…ï¼š&lt;a href=&quot;https://arxiv.org/search/cs?searchtype=author&amp;amp;query=Zeng%2C+A&quot;&gt;Ailing Zeng&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/search/cs?searchtype=author&amp;amp;query=Yang%2C+L&quot;&gt;Lei Yang&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/search/cs?searchtype=author&amp;amp;query=Ju%2C+X&quot;&gt;Xuan Ju&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/search/cs?searchtype=author&amp;amp;query=Li%2C+J&quot;&gt;Jiefeng Li&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/search/cs?searchtype=author&amp;amp;query=Wang%2C+J&quot;&gt;Jianyi Wang&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/search/cs?searchtype=author&amp;amp;query=Xu%2C+Q&quot;&gt;Qiang Xu&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;å‘è¡¨ï¼š ECCV 2022&lt;/p&gt;
&lt;p&gt;é“¾æ¥ï¼š &lt;a href=&quot;https://github.com/cure-lab/SmoothNet&quot; class=&quot;uri&quot;&gt;https://github.com/cure-lab/SmoothNet&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Computer Notes" scheme="https://jyzhu.top/categories/Computer-Notes/"/>
    
    
    <category term="Computer Vision" scheme="https://jyzhu.top/tags/Computer-Vision/"/>
    
  </entry>
  
  <entry>
    <title>Reading NeuMan: Neural Human Radiance Field from a Single Video</title>
    <link href="https://jyzhu.top/Reading-NeuMan-Neural-Human-Radiance-Field-from-a-Single-Video/"/>
    <id>https://jyzhu.top/Reading-NeuMan-Neural-Human-Radiance-Field-from-a-Single-Video/</id>
    <published>2022-08-24T04:25:25.000Z</published>
    <updated>2022-09-01T04:57:08.650Z</updated>
    
    <content type="html"><![CDATA[<p>è®ºæ–‡åœ°å€ï¼šhttps://arxiv.org/abs/2203.12575</p><p>ä½œè€…ï¼šJiang, Wei and Yi, Kwang Moo and Samei, Golnoosh and Tuzel, Oncel and Ranjan, Anurag</p><p>å‘è¡¨ï¼š ECCV22</p><p>å¼€æºä»£ç ï¼š https://github.com/apple/ml-neuman</p><h2 id="why">Whyï¼š</h2><ol type="1"><li><p>äººä½“çš„æ¸²æŸ“å’Œæ–°å§¿åŠ¿ç”Ÿæˆåœ¨å¢å¼ºç°å®çš„åº”ç”¨ä¸­å¾ˆé‡è¦</p></li><li><p>NeRFçš„å‡ºç°è®©æ–°è§†è§’ç”Ÿæˆä»»åŠ¡å–å¾—å¾ˆå¤§è¿›æ­¥</p></li><li><p>ä½†æ˜¯ç°æœ‰å·¥ä½œéƒ½æ²¡æœ‰å®ç°ï¼šæ ¹æ®å•æ®µwildè§†é¢‘ï¼Œç”Ÿæˆæ–°çš„äººç‰©å’Œæ–°çš„åœºæ™¯</p><figure><img src="https://s2.loli.net/2022/08/24/NdDrEhojmBLCJz9.png" alt="image-20220824123146868" /><figcaption>image-20220824123146868</figcaption></figure></li></ol><h2 id="what">Whatï¼š</h2><p>è¯»å‰ç–‘é—®ï¼š</p><ol type="1"><li>NeRFå’Œäººä½“SMPLæ¨¡å‹æ˜¯æ€ä¹ˆæœ‰æœºç»Ÿä¸€çš„ğŸ¤”</li></ol><h2 id="how">Howï¼š</h2><ol type="1"><li><p>è¾“å…¥æ˜¯ä¸€æ®µwildè§†é¢‘ï¼Œmoving cameraçš„ã€‚ç”¨ç°å­˜æ–¹æ³•ä¼°è®¡äººä½“å§¿åŠ¿ã€äººä½“å½¢çŠ¶ã€äººä½“maskï¼ˆMask-RCNNï¼‰ã€ç›¸æœºposeã€sparse scene modelã€depth maps</p></li><li><p>ç„¶åè®­ç»ƒä¸¤ä¸ª NeRF æ¨¡å‹ï¼Œä¸€ä¸ªç”¨äºäººä½“ï¼Œä¸€ä¸ªç”¨äºç”± Mask-RCNN ä¼°è®¡çš„åˆ†å‰²maskå¼•å¯¼çš„èƒŒæ™¯ã€‚ æ­¤å¤–ï¼Œé€šè¿‡å°†æ¥è‡ªå¤šè§†å›¾é‡å»ºå’Œå•ç›®æ·±åº¦å›å½’çš„æ·±åº¦ä¼°è®¡èåˆåœ¨ä¸€èµ·æ¥è§„èŒƒåœºæ™¯ NeRF æ¨¡å‹</p></li><li><p>å…³äºNeRFï¼š(å‚è€ƒï¼š<a href="https://zhuanlan.zhihu.com/p/360365941">zhihu</a>ï¼‰</p><ol type="1"><li><p>NeRFæ˜¯ç”¨ç¥ç»è¾å°„åœºå»ºæ¨¡ä¸€ä¸ªåœºæ™¯ï¼Œå¥½å¤„æ˜¯å¯ä»¥ç”Ÿæˆæ–°è§†è§’çš„å›¾åƒã€‚é’ˆå¯¹ä¸€ä¸ªé™æ€åœºæ™¯ï¼Œéœ€è¦æä¾›å¤§é‡ç›¸æœºå‚æ•°å·²çŸ¥çš„å›¾ç‰‡ã€‚åŸºäºè¿™äº›å›¾ç‰‡è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œï¼Œå³å¯ä»¥ä»ä»»æ„è§’åº¦æ¸²æŸ“å‡ºå›¾ç‰‡ç»“æœäº†ã€‚</p></li><li><p>å®ƒç”¨MLPï¼ŒæŠŠä¸€ä¸ª3dåœºæ™¯éšå¼åœ°ç¼–ç è¿›ç¥ç»ç½‘ç»œé‡Œã€‚è¾“å…¥ä¸º3dç©ºé—´ä¸­ä¸€ä¸ªç‚¹çš„åæ ‡<span class="math inline">\(\bold x = (x,y,z)\)</span>å’Œç›¸æœºè§†è§’ <span class="math inline">\(\bold d = (\theta, \phi)\)</span>ï¼Œè¾“å‡ºä¸ºè¯¥ç‚¹å¯¹åº”çš„ä½“ç´ çš„å¯†åº¦opacityï¼Œä»¥åŠé¢œè‰²<span class="math inline">\(\bold c = (r,g,b)\)</span>ã€‚å…¬å¼å°±æ˜¯ <span class="math display">\[f(\bold{x},\bold{v})=(\bold c, \sigma)\]</span></p></li><li><p>åœ¨å…·ä½“çš„å®ç°ä¸­ï¼Œ x é¦–å…ˆè¾“å…¥åˆ°MLPç½‘ç»œä¸­ï¼Œå¹¶è¾“å‡º Ïƒ å’Œä¸­é—´ç‰¹å¾ï¼Œä¸­é—´ç‰¹å¾å’Œ d å†è¾“å…¥åˆ°é¢å¤–çš„å…¨è¿æ¥å±‚ä¸­å¹¶é¢„æµ‹é¢œè‰²ã€‚å› æ­¤ï¼Œä½“ç´ å¯†åº¦åªå’Œç©ºé—´ä½ç½®æœ‰å…³ï¼Œè€Œé¢œè‰²åˆ™ä¸ç©ºé—´ä½ç½®ä»¥åŠè§‚å¯Ÿçš„è§†è§’éƒ½æœ‰å…³ç³»ã€‚åŸºäºview dependent çš„é¢œè‰²é¢„æµ‹ï¼Œèƒ½å¤Ÿå¾—åˆ°ä¸åŒè§†è§’ä¸‹ä¸åŒçš„å…‰ç…§æ•ˆæœã€‚</p></li><li><p>NeRF å‡½æ•°å¾—åˆ°çš„æ˜¯ä¸€ä¸ª3Dç©ºé—´ç‚¹çš„é¢œè‰²å’Œå¯†åº¦ä¿¡æ¯ï¼Œä½†å½“ç”¨ä¸€ä¸ªç›¸æœºå»å¯¹è¿™ä¸ªåœºæ™¯æˆåƒæ—¶ï¼Œæ‰€å¾—åˆ°çš„2D å›¾åƒä¸Šçš„ä¸€ä¸ªåƒç´ å®é™…ä¸Šå¯¹åº”äº†ä¸€æ¡ä»ç›¸æœºå‡ºå‘çš„å°„çº¿ä¸Šçš„æ‰€æœ‰è¿ç»­ç©ºé—´ç‚¹ã€‚åç»­å°±æœ‰å„ç§å„æ ·é«˜æ•ˆçš„æ–¹å¼æ¥è¿›è¡Œå¯å¾®æ¸²æŸ“äº†ï¼Œæœ¬è´¨ä¸Šéƒ½æ˜¯ä»è¿™æ¡å°„çº¿ä¸Šé‡‡æ ·ï¼Œè·å¾—å¹³å‡çš„é¢œè‰²ä¿¡æ¯ã€‚</p></li></ol></li></ol><h3 id="äººä½“æ¨¡å‹nerfsmpl">äººä½“æ¨¡å‹ï¼šNeRF+SMPL</h3><p>æˆ‘ä¸»è¦å…³æ³¨çš„å°±æ˜¯äººä½“æ¨¡å‹è¿™éƒ¨åˆ†äº†ã€‚æ€»ä½“æ¥è¯´ï¼Œåšæ³•å°±æ˜¯ï¼š</p><p>é¦–å…ˆç”Ÿæˆäººä½“NeRFæ¨¡å‹ï¼Œç„¶åç”¨ROMPç”Ÿæˆé€å¸§çš„äººä½“SMPLæ¨¡å‹ï¼Œç„¶åå®šä¹‰ä¸€ä¸ªcanonicalçš„äººä½“æ¨¡å‹ï¼ˆä¸»è¦æ˜¯å»æ‰å§¿åŠ¿è¿™ä¸ªå˜é‡ï¼Œå˜æˆå¤§å­—å‹äººä½“ï¼‰ï¼Œæ ¹æ®åƒç´ ç‚¹åœ¨SMPLæ¨¡å‹ä¸Šå¯¹åº”çš„ä½ç½®ï¼Œå†å¯¹åº”åˆ°canonicalæ¨¡å‹ä¸Šï¼Œå­¦åˆ°äººä½“çš„å¤–è²Œã€‚ï¼ˆå…¶å®è®­ç»ƒä¸­NeRFå’ŒSMPLæ¨¡å‹æ˜¯ä¸€èµ·å­¦çš„ï¼Œæ²¡æœ‰åˆ†å¾—é‚£ä¹ˆå¼€çš„å…ˆåé¡ºåºã€‚ï¼‰</p><figure><img src="https://s2.loli.net/2022/08/24/JSycDH34UlMBsEW.png" alt="image-20220824180150642" /><figcaption>image-20220824180150642</figcaption></figure><p>å…·ä½“æ¥è¯´ï¼š</p><ol type="1"><li><p>å¯¹äºæŸä¸€å¸§å›¾åƒï¼Œç”¨ROMPä¼°è®¡äººä½“çš„SMPLæ¨¡å‹ï¼Œä½†é‡‡å–äº†ä¸€äº›æ”¹è‰¯ï¼š</p><ol type="1"><li>åˆ©ç”¨denseposeä¼°è®¡äººä½“çš„silhouetteï¼Œä»¥åŠMMPoseä¼°è®¡äººä½“çš„2D jointsï¼›æ ¹æ®è¿™äº›ç»“æœä¼˜åŒ–SMPLå‚æ•°</li></ol></li><li><p>æŠŠåˆšåˆšå¾—åˆ°çš„SMPLæ¨¡å‹warpæˆä¸€ä¸ªcanonicalçš„å¤§å­—å‹äººä½“æ¨¡å‹ï¼Œè¿™ä¸ªwarpå˜æ¢ç§°ä¸º<span class="math inline">\(\mathcal T\)</span></p></li><li><p>æ€ä¹ˆæŠŠå›¾åƒä¸­çš„åƒç´ ç‚¹å¯¹åº”åˆ°canonicalçš„å¤§å­—å‹äººä½“æ¨¡å‹ä¸Šå‘¢ï¼Ÿ</p><ol type="1"><li><p>é¦–å…ˆç”Ÿæˆäººä½“NeRFæ¨¡å‹</p></li><li><p>å¯¹äºç©ºé—´ä¸­çš„æ¯ä¸ªç‚¹<span class="math inline">\(\bold x_f=\bold r_f(t)\)</span> ï¼ˆè¿™é‡Œçš„fæ˜¯ç¬¬få¸§å›¾åƒï¼‰ï¼Œå®ƒéƒ½å¯ä»¥ç”±ä¸€æ¡å°„çº¿<span class="math inline">\(\bold r\)</span>ä¸Šå¯¹åº”çš„åƒç´ ç‚¹æ¸²æŸ“è€Œæ¥ï¼›é‚£ä¹ˆå¯¹è¿™ä¸ªç‚¹ç›´æ¥åº”ç”¨å‰é¢çš„å˜æ¢<span class="math inline">\(\mathcal{T}\)</span>ï¼Œå°±å¾—åˆ°å®ƒåœ¨canonicalç©ºé—´ä¸­å¯¹åº”çš„ç‚¹äº†ï¼Œ<span class="math inline">\(\bold x&#39;_f = \mathcal{T}_{\theta_f}(\bold x_f)\)</span></p></li><li><p>ä½†æ˜¯å› ä¸ºSMPLçš„ä¼°è®¡ä¸æ˜¯å¾ˆå‡†ç¡®ï¼Œè¿™ä¸ªå˜æ¢<span class="math inline">\(\mathcal{T}\)</span>ä¹Ÿä¸æ˜¯å¾ˆå‡†ç¡®ï¼Œæ‰€ä»¥è¿™é‡Œæå‡ºæ¥ï¼Œé€šè¿‡åœ¨è®­ç»ƒä¸­åŒæ—¶ä¼˜åŒ–SMPLæ¨¡å‹ <span class="math inline">\(\theta_f\)</span>å’Œäººä½“NeRFæ¨¡å‹çš„æ–¹å¼ï¼Œå¯ä»¥æå‡æ•ˆæœã€‚</p></li><li><p>è¿˜æœ‰ï¼Œè¿˜åŠ äº†ä¸€ä¸ªMLPæ”¹é”™ç½‘ç»œ<span class="math inline">\(\mathcal{E}\)</span>æ”¹æ­£warpingçš„è¯¯å·®ã€‚æœ€ç»ˆç»“æœå°±æ˜¯ï¼š <span class="math display">\[\bold {\tilde x&#39;_f} = \mathcal{T}_{\theta_f}(\bold x_f) + \mathcal{E}(\bold x_f, f)\]</span></p></li><li><p>æ­¤æ—¶ç›¸æœºè§†è§’ä¹Ÿéœ€è¦æ ¡æ­£ï¼šå¯¹äºå°„çº¿rayä¸Šçš„ç¬¬iä¸ªæ ·æœ¬ç‚¹ï¼Œ <span class="math display">\[\bold d(t_i)&#39;_f = \bold {\hat x}&#39;_f(t_i) - \bold {\hat x}&#39;_f(t_{i-1})\]</span></p></li></ol></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;è®ºæ–‡åœ°å€ï¼šhttps://arxiv.org/abs/2203.12575&lt;/p&gt;
&lt;p&gt;ä½œè€…ï¼šJiang, Wei and Yi, Kwang Moo and Samei, Golnoosh and Tuzel, Oncel and Ranjan, Anurag&lt;/p&gt;
&lt;p&gt;å‘è¡¨ï¼š ECCV22&lt;/p&gt;
&lt;p&gt;å¼€æºä»£ç ï¼š https://github.com/apple/ml-neuman&lt;/p&gt;</summary>
    
    
    
    <category term="Computer Notes" scheme="https://jyzhu.top/categories/Computer-Notes/"/>
    
    
    <category term="Computer Vision" scheme="https://jyzhu.top/tags/Computer-Vision/"/>
    
    <category term="3D Generation" scheme="https://jyzhu.top/tags/3D-Generation/"/>
    
  </entry>
  
  <entry>
    <title>It seems impossible to access USB devices in Docker on MacOS</title>
    <link href="https://jyzhu.top/It-seems-impossible-to-access-USB-devices-in-Docker-on-MacOS/"/>
    <id>https://jyzhu.top/It-seems-impossible-to-access-USB-devices-in-Docker-on-MacOS/</id>
    <published>2022-05-16T11:59:12.000Z</published>
    <updated>2022-09-01T04:57:56.460Z</updated>
    
    <content type="html"><![CDATA[<p>According to <a href="https://dev.to/rubberduck/using-usb-with-docker-for-mac-3fdd" class="uri">https://dev.to/rubberduck/using-usb-with-docker-for-mac-3fdd</a>, it seems impossible to forward USB to a Docker container on MacOS, coz the Docker is running in a virtual environment via <a href="https://github.com/docker/for-mac/issues/900">hyperkit</a>.</p><p>First of all, ports of the host (i.e., MacOS) cannot be directly accessed by any virtual environment (i.e., Docker) on it. So, &quot;you first have to expose it to the virtual machine where Docker is running&quot;. However, Docker is running on hyperkit, which doesn't support usb forwarding.</p><p>The author provided another way to do it, that is to use<code>docker-machine</code>, which uses a Virtualbox VM to host the <code>dockerd</code> daemon, to replace the original docker. Then... why bother still using Docker, instead of just using Virtualbox to run the seperated environment?</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;According to &lt;a href=&quot;https://dev.to/rubberduck/using-usb-with-docker-for-mac-3fdd&quot; class=&quot;uri&quot;&gt;https://dev.to/rubberduck/using-usb-with-</summary>
      
    
    
    
    <category term="Computer Notes" scheme="https://jyzhu.top/categories/Computer-Notes/"/>
    
    
    <category term="Docker" scheme="https://jyzhu.top/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Reading Video-to-Video Synthesis</title>
    <link href="https://jyzhu.top/Reading-Video-to-Video-Synthesis/"/>
    <id>https://jyzhu.top/Reading-Video-to-Video-Synthesis/</id>
    <published>2022-05-13T09:36:36.000Z</published>
    <updated>2022-09-01T04:59:24.160Z</updated>
    
    <content type="html"><![CDATA[<p>è®ºæ–‡åœ°å€ï¼šhttps://tcwang0509.github.io/vid2vid/paper_vid2vid.pdf</p><p>ä½œè€…ï¼š<a href="https://tcwang0509.github.io/">Ting-Chun Wang</a>, <a href="http://mingyuliu.net/">Ming-Yu Liu</a>, <a href="http://www.cs.cmu.edu/~junyanz/">Jun-Yan Zhu</a>, <a href="https://liuguilin1225.github.io/">Guilin Liu</a>, Andrew Tao, <a href="http://jankautz.com/">Jan Kautz</a>, <a href="http://catanzaro.name/">Bryan Catanzaro</a></p><p>å‘è¡¨ï¼š NeurIPS 2018</p><p>Projectï¼šhttps://tcwang0509.github.io/vid2vid/</p><p>Githubï¼šhttps://github.com/NVIDIA/vid2vid</p><hr /><blockquote><p><strong>å¦‚æœä½ å»åšè¿™ä¸ªä»»åŠ¡ï¼Œä¼šæ€ä¹ˆåšï¼Ÿä½œè€…åšçš„æ–¹æ³•å’Œä½ æƒ³çš„æœ‰ä»€ä¹ˆå·®å¼‚ï¼Ÿ</strong></p><p>è¿™ç¯‡è®ºæ–‡çš„èƒŒæ™¯æ˜¯å½“æ—¶å·²ç»æœ‰æ¯”è¾ƒå¥½çš„pic2picç”Ÿæˆæ¨¡å‹äº†ã€‚è¦è®©vid2vidä¹Ÿworkçš„è¯ï¼Œæœ€é‡è¦çš„åº”è¯¥å°±æ˜¯å¸§ä¸å¸§ä¹‹é—´consistencyçš„é—®é¢˜ã€‚æ‰€ä»¥æˆ‘ä¼šæƒ³åœ¨å°†pic2picç”Ÿæˆæ¨¡å‹åº”ç”¨åœ¨videoçš„åŸºç¡€ä¸Šï¼Œå¯¹å¸§ä¹‹é—´åŠ ä¸Šconsistency lossã€‚ä½†ç›´æ¥è¿™æ ·è‚¯å®šæ•ˆç‡å¾ˆä½ï¼Œå› ä¸ºä¸€ä¸ªè§†é¢‘ä¸­å¸§ä¸å¸§ä¹‹é—´è‚¯å®šä¼šåŒ…å«å¤§é‡å†—ä½™ä¿¡æ¯å˜›ï¼Œåº”è¯¥è¿˜éœ€è¦æƒ³åŠæ³•è®©å¸§ä¹‹é—´ä¿¡æ¯å…±äº«ï¼Œè¿™æ ·æ¨¡å‹åªéœ€è¦é¢„æµ‹åä¸€å¸§ä¸å‰ä¸€å¸§ä¸åŒçš„åœ°æ–¹ï¼Œå‡å°‘è¿ç®—ã€‚ä¾‹å¦‚ï¼Œç”¨ä¸€ä¸ªå°ç½‘ç»œé¢„æµ‹å›¾åƒä¸­é™æ€ä¸åŠ¨æ€çš„éƒ¨åˆ†ï¼Œä¸çŸ¥é“å¯ä¸å¯è¡Œã€‚</p><p><strong>çœ‹å®Œæ–‡ç« å</strong>ï¼šæˆ‘æ„Ÿè§‰æˆ‘åœ¨å¤§ä½“æ€è·¯ä¸ŠæŠŠæ¡å‡†äº†ï¼Œä¸»è¦çŸ›ç›¾ç¡®å®å¦‚æ­¤ã€‚ä½†</p><ol type="1"><li>ä½œè€…æ²¡æœ‰ç”¨consistency lossï¼Œè€Œæ˜¯ç”¨gançš„æ€è·¯ï¼Œè®¾è®¡äº†ä¸€ä¸ªæ¡ä»¶è§†é¢‘é‰´åˆ«å™¨ <span class="math inline">\(D_V\)</span>ï¼Œé‰´åˆ«è§†é¢‘åœ¨æ—¶åºä¸Šçš„åŠ¨æ€æ˜¯å¦çœŸå®è‡ªç„¶ã€‚</li><li>æˆ‘æ²¡æœ‰optical flowï¼Œå…‰æµï¼Œè¿™æ–¹é¢çš„çŸ¥è¯†å‚¨å¤‡ï¼›ä½œè€…åˆ©ç”¨ä¸€ä¸ªç½‘ç»œé¢„æµ‹optical flowï¼Œå°±å¯ä»¥ç›´æ¥æ ¹æ®å‰ä¸€å¸§å›¾åƒå¾—åˆ°åä¸€å¸§å›¾åƒä¸­å¯¹åº”çš„åƒç´ ç‚¹äº†ï¼Œè€Œä¸”è¿™æ ·çš„ç»“æœèƒ½å¤Ÿå¾ˆconsistentã€‚å¯¹äºå‰ä¸€å¸§å›¾åƒä¸­æ²¡æœ‰å¯¹åº”çš„åƒç´ ï¼Œå†ç”¨ä¸€ä¸ªè¡¥æ´ç½‘ç»œè¡¥æ´ã€‚è¿™æ ·å°±è§£å†³äº†æ•ˆç‡é—®é¢˜ã€‚</li><li>ä½œè€…è¿˜åˆ©ç”¨äº†ç‰¹å¾åµŒå…¥æ–¹æ³•ï¼Œå®ç°äº†å¤šæ¨¡æ€è§†é¢‘çš„ç”Ÿæˆï¼Œè¿™æ˜¯æˆ‘ç¬¬ä¸€æ¬¡äº†è§£åˆ°çš„æ–¹æ³•ï¼Œæ„Ÿè§‰å¾ˆæœ‰è¶£ã€‚</li></ol></blockquote><h2 id="why">Whyï¼š</h2><ol type="1"><li>å›¾åƒæ°´å¹³ä¸Šçš„ç”Ÿæˆè¢«ç ”ç©¶å¾—å¾ˆå¥½ï¼Œä½†æ˜¯è§†é¢‘ä¸Šçš„æ­¤å‰å´æ¯”è¾ƒå°‘ï¼›å›¾åƒç”Ÿæˆçš„æˆæœå¦‚æœç›´æ¥æ”¾åœ¨è§†é¢‘ä¸Šçš„è¯ï¼Œæ•ˆæœä¸å¤ªå¦™ï¼Œå› ä¸ºå¸§ä¸å¸§ä¹‹é—´ç¼ºä¹è¿è´¯æ€§ã€‚æ‰€ä»¥æ˜¯éœ€è¦ä¸€äº›temporalä¸Šçš„æ”¹è¿›çš„</li></ol><h2 id="what">Whatï¼š</h2><ol type="1"><li>åˆ©ç”¨GANå’Œä¸€äº›æ—¶é—´-ç©ºé—´å¯¹æŠ—ç›®æ ‡ï¼ˆspatio-temporal adverbial objectiveï¼‰ï¼Œæ¥å®ç°video to videoçš„ç”Ÿæˆã€‚</li><li>ç”¨ä¸åŒç±»å‹çš„è¾“å…¥æ¥ç”Ÿæˆæ–°çš„ç…§ç‰‡å†™å®é£æ ¼çš„è§†é¢‘ï¼Œæ•ˆæœå¾ˆå¥½ã€‚</li><li>æ˜¯ä¸€ä¸ªå…¨æ–°å®šä¹‰çš„vid2vidä»»åŠ¡ï¼Œä¸»è¦æ–°ç‚¹åœ¨äºï¼šè¾“å…¥çš„vidå¹¶ä¸æ˜¯å®Œæ•´çš„è§†é¢‘å¸§ï¼Œè€Œæ˜¯ä¸€äº›å¯ä»¥æ“æ§çš„è¯­ä¹‰ä¿¡æ¯ï¼Œä¾‹å¦‚segmentation masks, sketches, and poses</li></ol><p>è¯»å‰ç–‘é—®ï¼š</p><ol type="1"><li>åœ¨æ­¤ä¹‹å‰æ²¡æœ‰æ¯”è¾ƒå¥½çš„vid2vidï¼Œè¿™ç¯‡è®ºæ–‡æ˜¯åœ¨ä»€ä¹ˆæ¡ä»¶ä¸‹å®ç°äº†å¾ˆå¥½çš„vid2vidæ•ˆæœå‘¢ï¼Œæ¯”å¦‚å…¶ä»–æ–¹é¢çš„æŠ€æœ¯é©æ–°ï¼Ÿæˆ‘è§‰å¾—ä¸»è¦æ˜¯åˆ©ç”¨äº†ganï¼Œä¸€ä¸ªå›¾åƒé‰´åˆ«å™¨+ä¸€ä¸ªè§†é¢‘é‰´åˆ«å™¨ç›¸é…åˆï¼Œå–å¾—å¾ˆå¥½çš„ç”Ÿæˆæ•ˆæœã€‚é™¤æ­¤ä¹‹å¤–æˆ‘è§‰å¾—optical flowç”¨åœ¨è¿™é‡Œä¹Ÿå¾ˆå¥½ï¼Œæ•ˆç‡é«˜è€Œä¸”ç”Ÿæˆæ•ˆæœè¿è´¯ï¼ˆä½†æ˜¯ä¸çŸ¥é“æ–°ä¸æ–°ï¼‰ï¼›å¦å¤–ç‰¹å¾åµŒå…¥æ–¹æ³•ç”¨åœ¨è¿™é‡Œä¹Ÿå¾ˆå¥½ï¼Œå®ç°äº†æ ¹æ®è¯­ä¹‰ä¿¡æ¯æ¥ç”Ÿæˆæ–°è§†é¢‘ï¼Œè€Œä¸”å¯ä»¥æ˜¯å¤šæ¨¡æ€çš„è§†é¢‘</li><li>æ‘˜è¦é‡Œå¼ºè°ƒçš„æ—¶é—´-ç©ºé—´å¯¹æŠ—ç›®æ ‡ï¼ˆspatio-temporal adverbial objectiveï¼‰åˆ°åº•æ˜¯ä»€ä¹ˆï¼Ÿæˆ‘æ„Ÿè§‰æ­£æ–‡é‡Œå¥½åƒæ²¡æœ‰å†ç‰¹åˆ«å¼ºè°ƒæ—¶é—´-ç©ºé—´è¿™ä¸€å¯¹ç›®æ ‡äº†â€¦â€¦æ ¹æ®æˆ‘è‡ªå·±çš„ç†è§£çš„è¯ï¼Œä¸»è¦å°±æ˜¯é‚£ä¸€å¯¹é‰´åˆ«å™¨ï¼šæ—¶é—´ä¸Š--è§†é¢‘é‰´åˆ«å™¨é‰´åˆ«åœ¨æ—¶åºä¸Šçš„åŠ¨æ€æ˜¯å¦çœŸå®è‡ªç„¶ï¼Œç©ºé—´ä¸Š--å›¾åƒé‰´åˆ«å™¨é‰´åˆ«ä¸€å¼ å›¾åƒåœ¨ç©ºé—´ä¸Šæ˜¯å¦çœŸå®è‡ªç„¶ã€‚</li></ol><h2 id="how">Howï¼š</h2><h3 id="å®šä¹‰vid2vidä»»åŠ¡">å®šä¹‰vid2vidä»»åŠ¡</h3><ol type="1"><li><p>å®šä¹‰è¾“å…¥çš„è¯­ä¹‰ä¿¡æ¯åºåˆ—ä¸º<span class="math inline">\(s\)</span>ï¼Œå¯¹åº”çš„çœŸå®è§†é¢‘åºåˆ—ä¸º<span class="math inline">\(x\)</span>ï¼Œæ¨¡å‹ç”Ÿæˆçš„è§†é¢‘åºåˆ—ä¸º<span class="math inline">\(\tilde x\)</span>ï¼Œåˆ™æ¨¡å‹çš„ç›®æ ‡æ˜¯åœ¨ç»™å®š<span class="math inline">\(s\)</span>çš„æ¡ä»¶ä¸‹ï¼Œè®©<span class="math inline">\(\tilde x\)</span>çš„æ¡ä»¶åˆ†å¸ƒæ‹Ÿåˆ<span class="math inline">\(x\)</span>çš„æ¡ä»¶åˆ†å¸ƒ</p></li><li><figure><img src="https://s2.loli.net/2022/09/01/VfJE42QpgUB5zxt.png" alt="image-20220524143313609" /><figcaption>image-20220524143313609</figcaption></figure><p>Dæ˜¯discriminatorï¼ŒGæ˜¯generatorã€‚æ•´ä¸ªä»»åŠ¡å°±å˜æˆäº†ä¸€ä¸ªæœ€å¤§æœ€å°ä¼˜åŒ–é—®é¢˜ï¼Œè®ºæ–‡ä¸»è¦é€šè¿‡è®¾è®¡ç½‘ç»œå’Œæ—¶ç©ºä¼˜åŒ–ç›®æ ‡æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚</p></li><li><p>ä¸ºäº†ç®€åŒ–é—®é¢˜ï¼Œåšäº†ä¸€ä¸ªMarkovå‡è®¾ï¼šå½“å‰ç¬¬tå¸§ç”Ÿæˆçš„è§†é¢‘<span class="math inline">\(\tilde x_t\)</span>ï¼Œç”±ä¸”ä»…ç”±ç¬¬tå¸§è¾“å…¥<span class="math inline">\(s_t\)</span> + å‰Lå¸§è¾“å…¥<span class="math inline">\(s_{t-L}^{t-1}\)</span> + å‰Lå¸§ç”Ÿæˆçš„è§†é¢‘<span class="math inline">\(\tilde x_{t-L}^{t-1}\)</span>è¿™ä¸‰ä¸ªå› ç´ å†³å®šã€‚<img src="https://s2.loli.net/2022/09/01/Q9MPRD5otda3mAq.png" alt="image-20220524144030781" /></p><p>å®éªŒé‡Œï¼ŒLå–äº†ä¸ªä¸å¤§ä¸å°çš„2.å»ºç«‹äº†ä¸€ä¸ªç¥ç»ç½‘ç»œFï¼Œé€’å½’åœ°é€å¸§ç”Ÿæˆè§†é¢‘ã€‚</p></li></ol><h3 id="ç½‘ç»œæ¶æ„">ç½‘ç»œæ¶æ„</h3><ol type="1"><li><p>ç½‘ç»œFå®šä¹‰å¦‚ä¸‹ï¼š</p><figure><img src="https://s2.loli.net/2022/09/01/5OA4ptSUjI9Mn7J.png" alt="image-20220524144722968" /><figcaption>image-20220524144722968</figcaption></figure><p>ç»™å®š<span class="math inline">\((\tilde x_{t-L}^{t-1}, s_{t}^{t-1})\)</span>ä½œä¸ºè¾“å…¥ã€‚å¯¹äºä¸ä¸Šä¸€å¸§å›¾åƒæœ‰å…³è”çš„åƒç´ ç‚¹ï¼Œç½‘ç»œä¼šåˆ©ç”¨optical flowæ¥warpï¼ˆæ‰­æ›²ï¼Ÿï¼‰ä¸Šä¸€å¸§åƒç´ ç‚¹ï¼Œå¾—åˆ°è¿™ä¸€å¸§æ–°çš„åƒç´ ç‚¹ã€‚å¯¹åº”ç­‰å¼çš„å‰åŠéƒ¨åˆ†ã€‚è¿˜æœ‰ä¸€äº›åƒç´ æ˜¯ä¸Šä¸€å¸§å›¾åƒé‡Œæ²¡æœ‰çš„ï¼Œè¿™æ—¶å€™å°±éœ€è¦ç”Ÿæˆæ¥å¡«å……ã€‚å¯¹åº”ç­‰å¼çš„ååŠéƒ¨åˆ†ã€‚å…·ä½“æ¥è¯´ï¼š</p><ul><li>ç”¨ä¸€ä¸ªoptical flowé¢„æµ‹ç½‘ç»œWæ¥ä¼°è®¡ä»ä¸Šä¸€å¸§åˆ°è¿™ä¸€å¸§çš„optical flow <span class="math inline">\(\tilde w_{t-1}\)</span>.</li><li>ç”¨ä¸€ä¸ªç”Ÿæˆå™¨Hæ¥ç”Ÿæˆéœ€è¦å¡«å……çš„åƒç´ <span class="math inline">\(\tilde h_t\)</span>.</li><li>ç”¨ä¸€ä¸ªmaské¢„æµ‹ç½‘ç»œMæ¥ç”Ÿæˆmask <span class="math inline">\(\tilde m_t\)</span>. è¿™ä¸ªmaskä¸æ˜¯é0å³1çš„ï¼Œè€Œæ˜¯åŒ…å«äº†0-1ä¹‹é—´çš„è¿ç»­å€¼ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†æ›´å¥½åœ°èåˆWå’ŒHç”Ÿæˆçš„ç»“æœã€‚æ¯”å¦‚è¯´ï¼Œåœ¨ zoom in çš„æƒ…å†µä¸‹ï¼Œä¸€ä¸ªç‰©ä½“é€æ¸é è¿‘ï¼Œé‚£ä¹ˆå®ƒä¼šé€å¸§æ”¾å¤§ã€‚å¦‚æœä»…ä»…åˆ©ç”¨optical flowçš„æ‰­æ›²ç»“æœï¼Œé‚£ä¹ˆè¿™ä¸ªç‰©ä½“å°±ä¼šå˜å¾—æ¨¡ç³Šã€‚å› æ­¤ï¼Œè¿˜éœ€è¦ç”Ÿæˆå™¨æ¥å¡«å……ä¸€äº›ç»†èŠ‚ã€‚æœ‰äº†soft maskï¼Œwarpçš„åƒç´ å’Œç”Ÿæˆçš„åƒç´ å°±å¯ä»¥èåˆã€‚</li></ul></li><li><p>ç”¨äº†coarse-to-fineçš„æ–¹æ³•æ¥ç”Ÿæˆé«˜åˆ†è¾¨ç‡çš„è§†é¢‘</p></li><li><p>ç”¨äº†2ä¸ªä¸åŒçš„discriminatoræ¥å‡è½»ganè®­ç»ƒä¸­çš„mode collapseé—®é¢˜ï¼ˆæ¨¡å¼å€’å¡Œï¼Œå³ç”Ÿæˆçš„ç»“æœæ˜¯å¾ˆé€¼çœŸï¼Œä½†æ˜¯å¤šæ ·æ€§ä¸è¶³ï¼‰ã€‚</p><ol type="1"><li>æ¡ä»¶å›¾åƒé‰´åˆ«å™¨ <span class="math inline">\(D_I\)</span>ï¼Œé¡¾åæ€ä¹‰ï¼Œé‰´åˆ«æ¯ä¸€å¸§å›¾åƒæ˜¯å¦çœŸå®çš„</li><li>æ¡ä»¶è§†é¢‘é‰´åˆ«å™¨ <span class="math inline">\(D_V\)</span>ï¼Œé‰´åˆ«è§†é¢‘åœ¨æ—¶åºä¸Šçš„åŠ¨æ€æ˜¯å¦çœŸå®è‡ªç„¶ã€‚ç»™å®šoptical flowï¼Œé‰´åˆ«Kä¸ªè¿ç»­çš„å¸§</li></ol></li></ol><h3 id="losses">losses</h3><p><span class="math display">\[\mathop{min}\limits_{F} ( \mathop{max}\limits_{D_I}\mathcal{L}_I (F, D_I ) + \mathop{max}\limits_{D_V}  \mathcal{L}_V (F, D_V )) + Î»_W L_W (F ),\]</span></p><ol type="1"><li><span class="math inline">\(\mathcal{L}_I\)</span> æ˜¯æ¡ä»¶å›¾åƒé‰´åˆ«å™¨ <span class="math inline">\(D_I\)</span>çš„gan lossï¼š<img src="https://s2.loli.net/2022/09/01/J1mVkCnzWYZiaR9.png" alt="image-20220530194307049" />ï¼Œå…¶ä¸­ï¼Œ<span class="math inline">\(\phi_I\)</span> å°±æ˜¯ä»ç¬¬1ï½Tå¸§ä¸­éšæœºå–1å¸§çš„æ“ä½œ</li><li><span class="math inline">\(\mathcal{L}_V\)</span>æ˜¯æ¡ä»¶è§†é¢‘é‰´åˆ«å™¨ <span class="math inline">\(D_V\)</span>çš„ gan lossï¼š<img src="https://s2.loli.net/2022/09/01/rq6yiaRSHUnEYzg.png" alt="image-20220530194419594" />ï¼Œå’Œå›¾åƒçš„å¦‚å‡ºä¸€è¾™ï¼Œ<span class="math inline">\(\phi_V\)</span> å°±æ˜¯ä»ç¬¬1ï½Tå¸§ä¸­éšæœºå–è¿ç»­Kå¸§çš„æ“ä½œ</li><li><span class="math inline">\(L_W\)</span> æ˜¯flow estimation lossï¼š<img src="https://s2.loli.net/2022/09/01/AuZf1zlcihE3KsU.png" alt="image-20220530194534485" />ï¼ŒåŒ…æ‹¬ä¸¤éƒ¨åˆ†ï¼Œ1. çœŸå®flowå’Œä¼°è®¡flowçš„ç«¯ç‚¹è¯¯å·® 2. æŠŠå‰ä¸€å¸§æ‰­æ›²åˆ°åä¸€å¸§çš„warp loss</li></ol><h3 id="å‰æ™¯-èƒŒæ™¯å…ˆéªŒ">å‰æ™¯-èƒŒæ™¯å…ˆéªŒ</h3><p>é€šè¿‡è¯­ä¹‰åˆ†å‰²ï¼Œç»™æ¨¡å‹æä¾›äº†ä¸€ä¸ªå‰æ™¯ã€èƒŒæ™¯çš„å…ˆéªŒä¿¡æ¯ï¼ŒåŒæ—¶æŠŠè¡¥æ´ç½‘ç»œæ‹†åˆ†æˆäº†ä¸¤ä¸ªï¼š</p><ol type="1"><li>èƒŒæ™¯è¡¥æ´ç½‘ç»œï¼šè¿™ä¸ªå¾ˆå®¹æ˜“ï¼Œå› ä¸ºæ•´ä¸ªå¤§èƒŒæ™¯å…¶å®å¯ä»¥ç”±optical flowå¾ˆå‡†ç¡®åœ°é¢„æµ‹å‡ºæ¥ï¼Œè¡¥æ´ç½‘ç»œåªéœ€è¦è¡¥ä¸€ç‚¹ç‚¹ä»ç”»é¢å¤–é¢åˆšè¿›æ¥çš„éƒ¨åˆ†</li><li>å‰æ™¯è¡¥æ´ç½‘ç»œï¼šè¿™ä¸ªæ¯”è¾ƒéš¾ï¼Œå› ä¸ºå‰æ™¯ç‰©å“å¾€å¾€å æ¯”ä¸å¤§ï¼Œä½†æ˜¯åˆåŠ¨ä½œå¹…åº¦å¾ˆå¤§ï¼Œå‰æ™¯è¡¥æ´ç½‘ç»œéœ€è¦ä»é›¶å¼€å§‹ç”Ÿæˆå¾ˆå¤šä¸œè¥¿</li></ol><p>é€šè¿‡ç”¨æˆ·å®éªŒï¼Œè¯æ˜å¤§éƒ¨åˆ†äººè§‰å¾—æœ‰è¿™ä¸ªå‰æ™¯-èƒŒæ™¯å…ˆéªŒä¹‹åï¼Œæ•ˆæœæ›´å¥½ã€‚</p><h3 id="å¤šæ¨¡æ€ç”Ÿæˆ">å¤šæ¨¡æ€ç”Ÿæˆ</h3><p>ç½‘ç»œFæ˜¯ä¸€ä¸ªå•æ¨¡æ€æ˜ å°„å‡½æ•°ï¼Œè¿™æ„å‘³ç€è¾“å…¥ä¸€ä¸ªè§†é¢‘ï¼Œå®ƒä¹Ÿåªèƒ½ç”Ÿæˆä¸€ä¸ªè§†é¢‘ã€‚é‚£æ€æ ·è®©å®ƒæ ¹æ®åŒä¸€ä¸ªè¾“å…¥è§†é¢‘ï¼Œè¾“å‡ºå¤šä¸ªä¸åŒçš„è§†é¢‘å‘¢ï¼Ÿè¿™é‡Œé‡‡ç”¨äº†ç‰¹å¾åµŒå…¥æ–¹æ³•ï¼ˆfeature embedding schemeï¼‰ã€‚</p><ol type="1"><li>è¾“å…¥æºè§†é¢‘çš„åŒæ—¶ï¼Œä¹Ÿè¾“å…¥instanceçº§åˆ«çš„è¯­ä¹‰åˆ†å‰²mask <span class="math inline">\(s_t\)</span></li><li>è®­ç»ƒä¸€ä¸ªå›¾åƒç¼–ç å™¨Eï¼Œå®ƒæŠŠæ¯ä¸€å¸§çœŸå®å›¾åƒ<span class="math inline">\(x_t\)</span>ç¼–ç æˆdç»´çš„ç‰¹å¾mapï¼ˆè®ºæ–‡ä¸­då–3ï¼‰ã€‚ç„¶åç”¨ä¸€ä¸ªinstance-wiseçš„å¹³å‡æ± åŒ–ï¼Œæ¥è®©åŒä¸€ä¸ªç‰©ä½“çš„æ‰€æœ‰åƒç´ åˆ†äº«å…±åŒçš„ç‰¹å¾å‘é‡ã€‚å¾—åˆ°çš„è¿™ä¸ªinstance-wiseå¹³å‡æ± åŒ–åçš„å›¾åƒç‰¹å¾mapç§°ä¸º<span class="math inline">\(z_t\)</span></li><li>è¿™ä¸ª<span class="math inline">\(z_t\)</span>ï¼ŒåŠ ä¸Šmask <span class="math inline">\(s_t\)</span>ï¼Œå†è¢«è¾“å…¥åˆ°ç½‘ç»œF</li><li>ä»¥ä¸Šæ˜¯è®­ç»ƒçš„è¿‡ç¨‹ã€‚è®­ç»ƒç»“æŸåï¼Œå¯¹æ¯ä¸ªç±»å‹çš„å¯¹è±¡çš„ç‰¹å¾å‘é‡çš„é«˜æ–¯åˆ†å¸ƒæ‹Ÿåˆä¸€ä¸ªæ··åˆé«˜æ–¯åˆ†å¸ƒã€‚</li><li>æµ‹è¯•çš„æ—¶å€™ï¼Œåˆ©ç”¨æ¯ä¸ªç‰©ä½“æ‰€å¯¹åº”çš„ç±»å‹çš„åˆ†å¸ƒï¼Œå¯ä»¥sampleç‰¹å¾å‘é‡ï¼Œè¿›è€Œç”Ÿæˆæ–°è§†é¢‘äº†ã€‚ç»™å‡ºä¸åŒçš„ç‰¹å¾å‘é‡ï¼ŒFå°±èƒ½ç”Ÿæˆä¸åŒçš„è§†é¢‘äº†</li></ol><figure><img src="https://tcwang0509.github.io/vid2vid/paper_gifs/cityscapes_change_styles.gif" alt="img" /><figcaption>img</figcaption></figure><h3 id="å®ç°çš„ç»†èŠ‚">å®ç°çš„ç»†èŠ‚</h3><ol type="1"><li>coarse-to-fineçš„è®­ç»ƒï¼š512 Ã— 256, 1024 Ã— 512, and 2048 Ã— 1024 resolutionsï¼Œè¿™ä¸‰ç§åˆ†è¾¨ç‡ï¼Œå…ˆä»ä½çš„å¼€å§‹è®­ç»ƒèµ·ï¼Œé€æ¸å¢åŠ åˆ°é«˜çš„ã€‚</li><li>maské¢„æµ‹ç½‘ç»œMå’Œflowé¢„æµ‹ç½‘ç»œWå…±äº«æƒé‡ï¼Œåªæœ‰è¾“å‡ºå±‚ä¸ä¸€æ ·ã€‚</li><li>å›¾åƒé‰´åˆ«å™¨æ˜¯ä¸€ä¸ªå¤šå°ºåº¦PatchGAN</li><li>é™¤äº†ç©ºé—´ä¸Šçš„å¤šå°ºåº¦ï¼Œè§†é¢‘é‰´åˆ«å™¨è¿˜ä¼šè€ƒè™‘å¤šä¸ªå¸§ç‡ï¼Œå³æ—¶é—´ä¸Šçš„å¤šå°ºåº¦ï¼Œç¡®ä¿çŸ­æœŸå’Œé•¿æœŸéƒ½èƒ½consistent</li><li>2kåˆ†è¾¨ç‡ï¼Œ8ä¸ªv100 gpusï¼Œè®­ç»ƒ10å¤©â€¦â€¦</li><li>datasetsï¼š<ol type="1"><li>Cityscapesï¼šè®­ç»ƒDeepLabV3ç½‘ç»œæ¥è·å¾—æ‰€æœ‰çš„è¯­ä¹‰åˆ†å‰²maskï¼Œç”¨FlowNet2çš„ç»“æœä½œä¸ºoptical flowçš„ground truthï¼Œç”¨Mask R- CNNçš„ç»“æœä½œä¸ºinstance- level è¯­ä¹‰maskçš„gt</li><li>Apolloscape</li><li>Face video datasetï¼šFaceForensics dataseté‡Œçš„çœŸå®è§†é¢‘</li><li>Dance video datasetï¼šä»YouTubeä¸‹è½½çš„è·³èˆè§†é¢‘ğŸ’ƒ</li></ol></li></ol><h3 id="ç»“æœ">ç»“æœ</h3><p>å›¾åƒç”Ÿæˆæ¨¡å‹pix2pixHDå’Œè§†é¢‘é£æ ¼è¿ç§»æ¨¡å‹COVSTä½œä¸ºbaselineã€‚FIDï¼ˆè®ºæ–‡å®šä¹‰çš„è§†é¢‘å˜ç§ï¼‰è·Ÿbaselineæ¯”ç•¥å¥½ï¼Œä½†human preference scoreï¼ˆè®ºæ–‡å®šä¹‰çš„ç”±äººæ¥æ‰“åˆ†ï¼Œè¯„ä¼°å“ªä¸ªè§†é¢‘æ›´çœŸå®ï¼‰é«˜å¾ˆå¤šã€‚</p><p>é€šè¿‡æ›´æ”¹è¯­ä¹‰maskï¼Œå¯ä»¥æ§åˆ¶ç”Ÿæˆè§†é¢‘ä¸­çš„ç‰©ä½“ç§ç±»ï¼›é€šè¿‡æ›´æ”¹ç‰¹å¾å‘é‡ï¼Œå¯ä»¥æ§åˆ¶ç”Ÿæˆè§†é¢‘ä¸­çš„ç‰©ä½“å¤–è§‚ï¼›åœ¨æœªæ¥è§†é¢‘é¢„æµ‹ä¸Šä¹Ÿæœ‰å¾ˆå¥½çš„æ€§èƒ½ã€‚</p><h3 id="å±€é™æ€§">å±€é™æ€§</h3><ol type="1"><li>ç¼ºå°‘ä¸€ä¸ªç‰©ä½“å†…éƒ¨çš„å…·ä½“ä¿¡æ¯ï¼Œç”Ÿæˆè½¬å¼¯çš„è½¦çš„æ—¶å€™æ•ˆæœæ¯”è¾ƒå·®ã€‚è®ºæ–‡æå‡ºæˆ–è®¸å¯ä»¥é€šè¿‡å¢åŠ 3Dä¿¡æ¯ä½œä¸ºè¾“å…¥æ¥è§£å†³</li><li>åœ¨æ•´ä¸ªè§†é¢‘ä¸­ï¼Œä¸€ä¸ªç‰©ä½“çš„å¤–è§‚æœ‰æ—¶å€™è¿˜æ˜¯å‰åä¸ä¸€è‡´</li><li>å¶ç„¶æƒ…å†µä¸‹ï¼Œä¸€è¾†è½¦çš„é¢œè‰²å¯èƒ½ä¼šé€æ¸å‘ç”Ÿå˜åŒ–</li><li>å½“é€šè¿‡æ›´æ”¹è¯­ä¹‰ä¿¡æ¯æ¥æ“çºµè§†é¢‘ç”Ÿæˆçš„æ—¶å€™ï¼Œä¾‹å¦‚æŠŠæ ‘æ”¹æˆæˆ¿å­ï¼Œå¶ç„¶ä¼šå‡ºç°ä¸€éƒ¨åˆ†å˜æˆæˆ¿å­ï¼Œå¦ä¸€éƒ¨åˆ†æ ‘å˜äº†å½¢çš„æƒ…å†µï¼ˆï¼Ÿæ˜¯è¿™ä¸ªæ„æ€å—ï¼‰ã€‚è¿™æˆ–è®¸å¯ä»¥é€šè¿‡é‡‡ç”¨æ›´ç²—ç³™çš„è¯­ä¹‰æ ‡ç­¾çš„æ–¹å¼è§£å†³ï¼Œå› ä¸ºè¿™æ ·æ¨¡å‹å°±ä¸ä¼šå¯¹æ ‡ç­¾å½¢çŠ¶è¿‡äºæ•æ„Ÿ</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;è®ºæ–‡åœ°å€ï¼šhttps://tcwang0509.github.io/vid2vid/paper_vid2vid.pdf&lt;/p&gt;
&lt;p&gt;ä½œè€…ï¼š&lt;a href=&quot;https://tcwang0509.github.io/&quot;&gt;Ting-Chun Wang&lt;/a&gt;, &lt;a href=&quot;http://mingyuliu.net/&quot;&gt;Ming-Yu Liu&lt;/a&gt;, &lt;a href=&quot;http://www.cs.cmu.edu/~junyanz/&quot;&gt;Jun-Yan Zhu&lt;/a&gt;, &lt;a href=&quot;https://liuguilin1225.github.io/&quot;&gt;Guilin Liu&lt;/a&gt;, Andrew Tao, &lt;a href=&quot;http://jankautz.com/&quot;&gt;Jan Kautz&lt;/a&gt;, &lt;a href=&quot;http://catanzaro.name/&quot;&gt;Bryan Catanzaro&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;å‘è¡¨ï¼š NeurIPS 2018&lt;/p&gt;
&lt;p&gt;Projectï¼šhttps://tcwang0509.github.io/vid2vid/&lt;/p&gt;</summary>
    
    
    
    <category term="Computer Notes" scheme="https://jyzhu.top/categories/Computer-Notes/"/>
    
    
    <category term="Computer Vision" scheme="https://jyzhu.top/tags/Computer-Vision/"/>
    
    <category term="Video Generation" scheme="https://jyzhu.top/tags/Video-Generation/"/>
    
  </entry>
  
  <entry>
    <title>Reading Few-shot Video-to-Video Synthesis</title>
    <link href="https://jyzhu.top/Reading-Few-shot-Video-to-Video-Synthesis/"/>
    <id>https://jyzhu.top/Reading-Few-shot-Video-to-Video-Synthesis/</id>
    <published>2022-05-13T08:49:57.000Z</published>
    <updated>2022-09-01T05:00:11.103Z</updated>
    
    <content type="html"><![CDATA[<p>è®ºæ–‡åœ°å€ï¼šhttp://arxiv.org/abs/1910.12713</p><p>ä½œè€…ï¼š<a href="https://tcwang0509.github.io/">Ting-Chun Wang</a>, <a href="http://mingyuliu.net/">Ming-Yu Liu</a>, Andrew Tao, <a href="https://liuguilin1225.github.io/">Guilin Liu</a>, <a href="http://jankautz.com/">Jan Kautz</a>, <a href="http://catanzaro.name/">Bryan Catanzaro</a></p><p>å‘è¡¨ï¼š NeurIPS 2019</p><p>Projectï¼š https://nvlabs.github.io/few-shot-vid2vid</p><p>Githubï¼šhttps://github.com/NVLabs/few-shot-vid2vid</p><hr /><blockquote><p>å¦‚æœä½ å»åšè¿™ä¸ªä»»åŠ¡ï¼Œä¼šæ€ä¹ˆåšï¼Ÿä½œè€…åšçš„æ–¹æ³•å’Œä½ æƒ³çš„æœ‰ä»€ä¹ˆå·®å¼‚ï¼Ÿ</p><p>é¦–å…ˆè¿™ä¸ªä»»åŠ¡é€‰é¢˜å¯¹æˆ‘æ¥è¯´å¾ˆæ–°ï¼Œæˆ‘ä¹‹å‰éƒ½æ²¡æœ‰æ„è¯†åˆ°è¿‡è¿™æ–¹é¢çš„é—®é¢˜ã€‚å¦‚æœå‘Šè¯‰æˆ‘æœ‰è¿™æ ·çš„é—®é¢˜ï¼Œéœ€è¦å»è§£å†³çš„è¯ï¼Œæˆ‘çš„ç›´è§‚çš„æƒ³æ³•ä¼šå—åˆ°è¿™ç¯‡è®ºæ–‡ä½œè€…çš„ä¸Šä¸€ç¯‡ä¸­æåˆ°çš„ ç‰¹å¾åµŒå…¥æ–¹æ³• æ‰€å½±å“ï¼šä¼šæƒ³ä¹Ÿé€šè¿‡å°†ä¸€ç±»ç‰©ä½“çš„ç‰¹å¾ç¼–ç èµ·æ¥ï¼Œç„¶åé€šè¿‡å­¦ä¹ ä¸åŒä¸ªä½“çš„ç‰¹å¾ç¼–ç ï¼Œæ¥å®ç°ä¸åŒé£æ ¼çš„è§†é¢‘ç”Ÿæˆã€‚</p></blockquote><h2 id="why">Whyï¼š</h2><p>å½“ä»Švid2vidæ–¹æ³•çš„ä¸¤ä¸ªå±€é™æ€§ï¼š</p><ol type="1"><li>éœ€è¦å¤§é‡æ•°æ®ï¼Œå°¤å…¶æ˜¯éœ€è¦ç”Ÿæˆçš„è¿™ä¸ªäººçš„è§†é¢‘æ•°æ®</li><li>æ³›åŒ–èƒ½åŠ›æœ‰é™ï¼Œæ¯”å¦‚è¯´åªèƒ½åœ¨è®­ç»ƒé›†ä¸­åŒ…å«çš„äººä¸Šç”Ÿæˆæ–°çš„pose-to-humanè§†é¢‘ï¼Œä¸èƒ½æ³›åŒ–åˆ°è®­ç»ƒé›†ä¸­ä¸å­˜åœ¨çš„äººä¸Š</li></ol><p>æ‰€ä»¥è¿™ç¯‡è®ºæ–‡å°±æ˜¯æƒ³è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ã€‚</p><h2 id="what">Whatï¼š</h2><ol type="1"><li><p>ä»»åŠ¡æ˜¯Video-to-video synthesisï¼Œå³åˆ©ç”¨è¾“å…¥çš„è¯­ä¹‰è§†é¢‘ï¼ˆä¾‹å¦‚äººçš„å§¿åŠ¿ã€è¡—æ™¯ï¼‰ï¼Œç”Ÿæˆå†™å®çš„è§†é¢‘ã€‚ä¾‹å¦‚è¯´ï¼Œäººä½“å§¿åŠ¿ç”Ÿæˆçš„ä»»åŠ¡ï¼Œå°±æ˜¯é¦–å…ˆæ”¶é›†ä¸€ä¸ªäººåšå¤§é‡ä¸åŒåŠ¨ä½œçš„è§†é¢‘ï¼Œä½œä¸ºè®­ç»ƒé›†ï¼›ç„¶åå‘æ¨¡å‹ä¸­è¾“å…¥åŠ¨ä½œåºåˆ—ï¼Œè®©æ¨¡å‹ç”Ÿæˆè¯¥äººåšè¯¥åŠ¨ä½œçš„è§†é¢‘ã€‚å†æ¯”å¦‚è¡—æ™¯ç”Ÿæˆï¼Œä¹Ÿæ˜¯ä»¥å¤§é‡è¡—æ™¯è§†é¢‘ä½œä¸ºè®­ç»ƒé›†ï¼Œç„¶åå‘æ¨¡å‹ä¸­è¾“å…¥è¯­ä¹‰maskåºåˆ—ï¼Œè®©å®ƒç”Ÿæˆé£æ ¼ç±»ä¼¼çš„å…¨æ–°è¡—æ™¯ã€‚</p></li><li><p>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç½‘ç»œï¼Œå…¶ä¸­åŒ…æ‹¬ä¸€ä¸ªç½‘ç»œæƒé‡ç”Ÿæˆæ¨¡å—ï¼ˆnovel network weight generation moduleï¼‰å’Œattentionæœºåˆ¶</p></li><li><p>è¿™ä¸ªæ–¹æ³•çš„åˆ›æ–°ç‚¹åœ¨äºï¼Œåªéœ€è¦åœ¨æµ‹è¯•æ—¶ï¼Œå‘æ¨¡å‹æä¾›å°‘é‡çš„åœ¨è®­ç»ƒé›†ä¸­æ²¡å‡ºç°è¿‡çš„æ–°çš„äººç‰©çš„å›¾åƒï¼Œå®ƒå°±èƒ½ç”Ÿæˆè¿™ä¸ªæ–°çš„äººçš„è§†é¢‘ã€‚</p><figure><img src="https://s2.loli.net/2022/08/10/IUKDziV4AtOwsxu.png" alt="image-20220513171420180" /><figcaption>image-20220513171420180</figcaption></figure><p>ä¸Šå›¾ä¸­ï¼Œå·¦è¾¹æ˜¯ç°å­˜æ–¹æ³•ï¼Œå®ƒä»¬åŸºæœ¬ä¸Šå¯¹äºæ¯ä¸ªäººï¼Œéƒ½éœ€è¦åœ¨å•ç‹¬çš„è®­ç»ƒé›†ä¸Šè®­ç»ƒã€‚å³è¾¹æ˜¯è¿™ç¯‡è®ºæ–‡æå‡ºçš„æ–¹æ³•ï¼Œåªéœ€è¦è®­ç»ƒä¸€æ¬¡ï¼Œç„¶åè¾“å…¥ä¸€äº›ç¤ºèŒƒå›¾åƒï¼Œå°±å¯ä»¥æ³›åŒ–åˆ°æ–°çš„äººä¸Šã€‚</p></li></ol><p>è¯»å‰ç–‘é—®ï¼š</p><ol type="1"><li>è¯´æ˜¯åˆ©ç”¨å°‘é‡çš„æ–°çš„äººç‰©çš„ç¤ºèŒƒå›¾åƒï¼Œç”Ÿæˆç½‘ç»œæƒé‡ã€‚æ„æ€æ˜¯ä»¥åŸæœ¬çš„vid2vidç½‘ç»œçš„æƒé‡ä½œä¸ºè¾“å‡ºï¼Ÿä¸ºä»€ä¹ˆï¼Ÿæˆ‘çš„æ›´ç›´è§‚çš„æƒ³æ³•æ˜¯ï¼Œç›´æ¥ç”¨ä¸€ä¸ªæ–°ç½‘ç»œï¼Œå­¦ä¹ æ–°äººç‰©çš„å›¾åƒï¼Œç„¶åæŠŠoutputç»™concatæˆ–è€…åŠ è¿›æ—§ç½‘ç»œçš„outputä¸­â€¦â€¦å¦å¤–ï¼Œç›´æ¥ä½œç”¨äºç½‘ç»œæƒé‡ä¸Šï¼Œåœ¨æˆ‘çš„ç²—æµ…ç†è§£ä¸­ï¼Œä¼šä¸ä¼šé€ æˆä¿¡æ¯çš„æŸå¤±å‘¢ï¼Ÿè¿˜æ˜¯è¯´æœ¬è´¨ä¸Šæ²¡å·®ï¼Ÿ related worké‡Œæåˆ°è¿™ç±»ç½‘ç»œå±äºadaptive networkï¼Œè·Ÿå¸¸è§„ç½‘ç»œç›¸æ¯”æœ‰ä¸åŒçš„inductive biasï¼ˆæƒ³æƒ³ä¹Ÿæ˜¯ï¼‰ï¼Œæœ‰å¯¹åº”çš„åº”ç”¨ä»»åŠ¡ã€‚æˆ–è®¸æˆ‘ä¹‹åå†äº†è§£ä¸€ä¸‹è¿™å—ã€‚</li><li>æ ‡é¢˜ä¸­çš„few-shotæ˜¯ä»€ä¹ˆæ„æ€ï¼Œå°±æ˜¯æŒ‡æ›´å°‘çš„dataã€æ›´é«˜çš„æ³›åŒ–æ€§å—ï¼Ÿè¿™æ˜¯ä¸€ç±»ä»»åŠ¡å§ï¼Œä»å°‘é‡æ ‡æ³¨çš„æ ·æœ¬ä¸­å­¦ä¹ çš„æ„æ€ã€‚è¿™ä¸ªç¡®å®å°±æ˜¯å•Šï¼Œåªéœ€è¦ä¸€ç‚¹ç‚¹ç¤ºèŒƒå›¾åƒï¼Œå°±å¯ä»¥ç”Ÿæˆå›¾ä¸­è¿™ä¸ªäºº/ç‰©çš„æ–°videoã€‚</li><li>ä½œè€…çš„ä¸Šç¯‡è®ºæ–‡æ˜¯åˆ©ç”¨ganï¼Œè¿™ç¯‡åˆç”¨ä¸Šäº†attentionï¼Œä¸ºä»€ä¹ˆä½œå‡ºè¿™æ ·æœ¬è´¨çš„æ”¹å˜å‘¢ï¼Ÿ</li></ol><h2 id="how">Howï¼š</h2><ol type="1"><li>è§†é¢‘ç”Ÿæˆä»»åŠ¡å¯ä»¥åˆ†æˆ3ç±»ï¼š<ol type="1"><li>unconditional synthesisï¼šéšæœºç”Ÿæˆè§†é¢‘ç‰‡æ®µ</li><li>future video prediction</li><li>vid2vidï¼šæŠŠè¯­ä¹‰è¾“å…¥è½¬å˜æˆç°å®é£çš„è§†é¢‘ã€‚è¿™ç¯‡è®ºæ–‡å°±æ˜¯å±äºè¿™ä¸ªä»»åŠ¡ï¼Œä¸è¿‡å®ƒèšç„¦çš„ç‚¹åœ¨äºfew shotï¼Œå³é€šè¿‡åœ¨æµ‹è¯•çš„æ—¶å€™è¾“å…¥å°‘é‡å›¾åƒï¼Œè®©ç”Ÿæˆçš„è§†é¢‘å¯ä»¥æ³›åŒ–åˆ°æ²¡è§è¿‡çš„domainä¸Š</li></ol></li><li><p>vid2vidæ˜¯å‰ä¸€ç¯‡å·¥ä½œçš„å†…å®¹å•¦ã€‚referenceï¼š<a href="jyzhu.top/reading-video-to-video-synthesis"><em>Reading vid2vid</em></a></p></li><li><p>few-shotæœ¬è´¨ä¸Šå°±æ˜¯å¤šåŠ äº†ä¸ªç½‘ç»œEï¼Œç”¨æ¥ç”ŸæˆåŸè¡¥æ´ç½‘ç»œHçš„æƒé‡ã€‚è‡³äºåŸæœ¬è¿˜æœ‰ä¸¤ä¸ªç½‘ç»œWå’ŒMï¼Œä»–ä»¬éƒ½ä¸éœ€è¦æ”¹åŠ¨ï¼Œå› ä¸ºä»–ä»¬éƒ½æ˜¯åŸºäºä¸Šä¸€å¸§ç”Ÿæˆçš„å›¾åƒè¿›è¡Œå˜å½¢çš„ï¼Œä»£è¡¨ä¸€ç§è¿åŠ¨ï¼Œè€Œå’Œè§†é¢‘æœ¬è´¨çš„å†…å®¹æ²¡æœ‰å…³ç³»ã€‚</p></li><li><p>ç²¾é«“ä¸€å›¾ï¼š</p><figure><img src="https://s2.loli.net/2022/08/10/T6is35cjyHlvaNe.png" alt="image-20220810193845710" /><figcaption>image-20220810193845710</figcaption></figure></li><li><p>ç”¨æœ€æ–°çš„SOTAè¯­ä¹‰å›¾åƒç”Ÿæˆæ¨¡å‹SPADEä»£æ›¿äº†ä¸Šä¸€ç¯‡è®ºæ–‡ä¸­çš„ç½‘ç»œHã€‚SPADEåŒ…å«several spatial modulation branches and a main image synthesis branchã€‚ä¸è¿‡ç½‘ç»œEåªæ›´æ–°SPADEæ¨¡å‹ä¸­çš„spatial modulation branchesçš„æƒé‡ï¼Œå› ä¸º1è¿™æ ·é‡æ¯”è¾ƒå°ï¼Œ2è¿™æ ·å¯ä»¥é¿å…ä¸€ä¸ªç›´æ¥ä»input imageåˆ°output imageçš„çŸ­è·¯ï¼ˆæˆ‘å°šæ²¡æœ‰æ·±ç©¶åŸå› ï¼‰ã€‚</p></li><li><p>æƒé‡ç”Ÿæˆæ¨¡å—Eã€‚</p></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;è®ºæ–‡åœ°å€ï¼šhttp://arxiv.org/abs/1910.12713&lt;/p&gt;
&lt;p&gt;ä½œè€…ï¼š&lt;a href=&quot;https://tcwang0509.github.io/&quot;&gt;Ting-Chun Wang&lt;/a&gt;, &lt;a href=&quot;http://mingyuliu.net/&quot;&gt;Ming-Yu Liu&lt;/a&gt;, Andrew Tao, &lt;a href=&quot;https://liuguilin1225.github.io/&quot;&gt;Guilin Liu&lt;/a&gt;, &lt;a href=&quot;http://jankautz.com/&quot;&gt;Jan Kautz&lt;/a&gt;, &lt;a href=&quot;http://catanzaro.name/&quot;&gt;Bryan Catanzaro&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;å‘è¡¨ï¼š NeurIPS 2019&lt;/p&gt;
&lt;p&gt;Projectï¼š https://nvlabs.github.io/few-shot-vid2vid&lt;/p&gt;</summary>
    
    
    
    <category term="Computer Notes" scheme="https://jyzhu.top/categories/Computer-Notes/"/>
    
    
    <category term="Computer Vision" scheme="https://jyzhu.top/tags/Computer-Vision/"/>
    
    <category term="Video" scheme="https://jyzhu.top/tags/Video/"/>
    
  </entry>
  
  <entry>
    <title>Live demo of CodeTyping via Pythonanywhere</title>
    <link href="https://jyzhu.top/live-demo-of-code-typing-via-pythonanywhere/"/>
    <id>https://jyzhu.top/live-demo-of-code-typing-via-pythonanywhere/</id>
    <published>2022-04-07T15:24:15.000Z</published>
    <updated>2022-04-07T15:34:41.597Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://user-images.githubusercontent.com/39082096/149967763-a9bb56c5-6411-4d86-90d3-f1e22845e2a8.png" alt="image" /><figcaption>image</figcaption></figure><p><a href="http://jyzhu.pythonanywhere.com/">Code Typing Practice</a> (or source code on Github: <a href="https://github.com/viridityzhu/code-typing">here</a>) is a tiny web page that I wrote for fun last semester, which is for me myself to practice code typing. It is a naive Django web app (with bugsğŸ¤ª). BUT! I find a service to deploy it lively today. That's what is worth noting down now.</p><span id="more"></span><h2 id="note">Note</h2><p>Initially I tried to deploy this demo on Vercel.com. But it was too troublesome coz it does not support Django by default. Thankfully, I found <a href="https://www.pythonanywhere.com/">pythonanywhere</a>, on which each user can deploy one web app without payment. What's the best is that it is really easy to deploy: it provides access to Bash console.</p><p>Two things to be noted:</p><ol type="1"><li>Every 3 months, I have to login into the pythonanywhere to extend my web app, otherwise it will be killed.</li><li>The bug cost most of my time is that in the <code>view.py</code> I had used relative path to the static code files. However, I should use absolute path, with adding <code>BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))</code> ahead.</li></ol><h2 id="todo">TODO</h2><p>Actually, after learned the MERN frame this semester, I am now aware of how naive this project is. However, I love Python, so it doesn't matter if i still regard Django as a hobbyğŸ¤¨. Who knows... I haven't even spent my time on that course project...</p><p>Now that the live demo is achieved, I might think of polishing this little project a bit.</p><ul><li>[ ] Fix bugs. Though i've already forgotten what those bugs are...</li><li>[ ] Replace the stupid code snippets...</li><li>[ ] Add the feature to compute time cost and typing speed. Also, save typing records.</li><li>[ ] Explicitly support other kinds of typing materials, and also support uploading customize materials.</li></ul>]]></content>
    
    
    <summary type="html">&lt;figure&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/39082096/149967763-a9bb56c5-6411-4d86-90d3-f1e22845e2a8.png&quot; alt=&quot;image&quot; /&gt;&lt;figcaption&gt;image&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;a href=&quot;http://jyzhu.pythonanywhere.com/&quot;&gt;Code Typing Practice&lt;/a&gt; (or source code on Github: &lt;a href=&quot;https://github.com/viridityzhu/code-typing&quot;&gt;here&lt;/a&gt;) is a tiny web page that I wrote for fun last semester, which is for me myself to practice code typing. It is a naive Django web app (with bugsğŸ¤ª). BUT! I find a service to deploy it lively today. That&#39;s what is worth noting down now.&lt;/p&gt;</summary>
    
    
    
    <category term="Computer Notes" scheme="https://jyzhu.top/categories/Computer-Notes/"/>
    
    
    <category term="Django" scheme="https://jyzhu.top/tags/Django/"/>
    
    <category term="Python" scheme="https://jyzhu.top/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>ä¸‰æœˆçš„äººç”Ÿä¸»é¢˜æ˜¯å¤æ‚æ€§</title>
    <link href="https://jyzhu.top/complexity-again/"/>
    <id>https://jyzhu.top/complexity-again/</id>
    <published>2022-03-14T07:26:36.000Z</published>
    <updated>2022-03-14T07:48:22.442Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>æˆ‘æ”¾å¼ƒç†è§£å¾ˆå¤šä¸œè¥¿</p><p>æˆ‘å¼€å§‹æ‹¥æŠ±</p><p>æƒŠäººçš„å¤æ‚æ€§</p></blockquote><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="450" src="//music.163.com/outchain/player?type=0&amp;id=7326559292&amp;auto=1&amp;height=430"></iframe><p>è¿™ä¸¤å¤©åˆ—äº†ä¸€ä¸ªåå«ã€Œç²¾ç¥çŠ¶å†µã€çš„æ­Œå•ï¼Œé¡¾åæ€ä¹‰ï¼Œé´é€‰äº†å¤§æŠµæ˜¯æœ€èƒ½æœ‰æ•ˆè¡¨è¾¾æˆ‘è¿‘æ¥ç²¾ç¥çŠ¶å†µçš„9é¦–æ­Œï¼ˆä¸å‡ºæ‰€æ–™ä»¥æ‘‡æ»šä¸ºä¸»ï¼‰ã€‚å¥‡å¦™çš„æ˜¯ï¼Œä¸€æ–¹é¢æˆ‘è‡ªè¯©å¬æ­Œæ—¶å¯¹æ­Œè¯ç”šæ˜¯é‡è§†ï¼Œå¦ä¸€æ–¹é¢æœ€çˆ±çš„æ­Œç«Ÿç„¶æ­Œè¯å«é‡ä¸è¶³50%ã€‚æƒ³æƒ³ç°å®ï¼Œæˆ–è®¸æ˜¯æˆ‘æ”¾å¼ƒç†è§£å¾ˆå¤šä¸œè¥¿ï¼ˆç”¨ç†æ€§ï¼‰ï¼Œå¼€å§‹æ‹¥æŠ±å¤æ‚æ€§äº†å§ï¼ˆç”¨æ„Ÿæ€§ï¼Ÿï¼‰ã€‚</p><p><img src="https://s2.loli.net/2022/03/14/W5bxdr9w3egqRGF.jpg" style="zoom: 33%;" /></p><hr /><h3 id="æœ€è¿‘éšæƒ³">æœ€è¿‘éšæƒ³ï¼š</h3><ul><li>ã€Œæ´»ç€å¾ˆç´¯ï¼Œåœ¨æ¼«é•¿çš„ç”Ÿå‘½ä¸­ï¼Œç§¯ç´¯çš„ç—›è‹¦ä¸æŠ˜ç£¨ä¼šå˜å¾—ç»µé•¿ã€‚ã€æ‰€ä»¥äººé•¿å¤§äº†å¼€å§‹å–é…’ï¼Œä¸€ééå–é…’ï¼Œåªæ˜¯å› ä¸ºç§¯å‹çš„ç—›è‹¦æ— æ³•æ¶ˆè§£å§ã€‚ä¸è¿‡è¿™æ ·çš„å¥½å¤„å°±æ˜¯ä¼šæœ‰ä¸€å¤©ä¸å†åƒå¹´è½»æ—¶å€™é‚£æ ·æ€•æ­»äº†</li><li>æˆ‘å¾ˆæ‚²æˆšï¼Œè¿™ä¸ªä¸–ç•Œçš„æ‚²æˆšåº•è‰²è¿‘å¹´ä¹Ÿé€æ¸æ˜¾éœ²ï¼Œçœ‹å¾—æµ…çš„äººä¹Ÿèƒ½ä¸¾ç›®å°±çœ‹è§ç°é»‘è‰²äº†ã€‚å¾ˆæ— æœ›ï¼Œå¹´å¤ä¸€å¹´åŸ‹å¤´æ´»ç€ï¼Œä¸€æŠ¬å¤´å°±æä¸æ¸…æ¥šåœ¨ç›¼ä»€ä¹ˆã€‚æƒ³åˆ°çˆ¶æ¯æ¸è€ï¼Œå¤§å°æ¯›ç—…æ¥è¿ä¸æ–­ï¼›å°±è¿æˆ‘è‡ªå·±éƒ½å¼€å§‹æ˜¾éœ²ä¸€äº›èº«ä½“ä¸å¥½çš„è¿¹è±¡ï¼Œå°±å®åœ¨æ˜¯éš¾è¿‡ã€‚æƒ³åˆ°æˆ‘çš„ç”Ÿæ´»ï¼Œæµ·å¤–ç•™å­¦ï¼Œä¸“ä¸šå­¦æœ¯ï¼Œä¸çˆ¶æ¯çš„ç”Ÿæ´»ï¼ŒæŸ´ç±³æ²¹ç›ï¼Œå®¶é•¿é‡ŒçŸ­ï¼Œæˆ‘ä»¬çš„ä¸–ç•Œæ˜¯å‰²è£‚çš„ï¼Œæˆ‘æ•´ä¸ªäººä¹Ÿæ„Ÿåˆ°ä¸€ç§å‰²è£‚ï¼Œå¾…åœ¨çˆ¶æ¯èº«è¾¹æˆ–è€…è¿œæ–¹ï¼Œéƒ½å¾ˆæ‚²å“€ã€‚è¿™ç§æ‚²å“€ç”šè‡³åªæ˜¯ç¨çºµå³é€çš„ï¼Œå®ƒå“ªæ€•èƒ½é•¿å­˜ä¸€äº›ï¼Œæˆ‘ä¹Ÿèƒ½å¯¹ç”Ÿæ´»ç¨å¤šäº›æŠŠæ¡ã€‚åªæ˜¯æ—¶é—´æ€»ä¼šè¿‡å¾—å¾ˆå¿«ï¼Œå¯é¢„è§çš„æœªæ¥è¿˜ä¼šé¢ä¸´å˜æ›´ï¼Œä¼´éšæ›´æ·±ã€æ›´æ— åŠ›çš„æ‚²å“€ï¼Œä¾‹å¦‚ä½œä¸ºä¸€ä¸ªæˆå¹´äººéœ€æ‰¿æ‹…çš„ä¸€ä¸ªå®¶åº­çš„å‹åŠ›ï¼Œä¾‹å¦‚é‡è¦çš„äººçš„è¡°è€ã€ç–¾ç—…ã€æ­»äº¡ã€‚</li><li>æˆ‘æœ‰æ—¶å€™å¯¹äººç”Ÿå¾ˆéšä¾¿ï¼Œç³Ÿç³•å¢ƒé‡çš„å‘ç”Ÿä¼šè¢«é’æ„Ÿè€Œå¿½ç•¥ï¼Œæˆ–è€…å¾ˆå¿«è§†è‹¥æ— ç¹ï¼Œä¾‹å¦‚ç–«æƒ…å’Œç–«æƒ…åçš„ä¸–ç•Œã€‚åªæ˜¯æ¯ä¸€ä»¶äº‹ï¼Œä¹Ÿä¸è‡³äºå¯¹æˆ‘å…¨æ— å½±å“ï¼Œæˆ‘çš„è’è¯æ„Ÿéšç€å®ƒä»¬ä¸€å±‚ä¸€å±‚åŠ æ·±ã€‚</li><li>æ˜¨å¤©å»å¤–å…¬å¢“ä¸ŠæŒ‚ç¤¾äº†ï¼Œå’Œå¦ˆå¦ˆã€å¤–å©†ä¸€èµ·ã€‚å¤–å©†è·Ÿå¤–å…¬è¯´å¾ˆå¤šè¯ï¼Œé—®ä»–è¿™é‡Œé£æ™¯å¥½ä¸å¥½ï¼Œæœ‰æ²¡æœ‰å»å“ªé‡Œé’“é±¼ã€‚å¦ˆå¦ˆå·å·æŠ¹äº†å‡ æ¬¡çœ¼æ³ªã€‚æˆ‘æœ€æ²¡ç”¨ï¼Œçœ¼æ³ªå¤§é¢—å¤§é¢—æ»´åœ¨çº¸é’±ä¸Šï¼Œéƒ½ä¸å¥½çƒ§äº†ã€‚å¯æ˜¯æˆ‘çœ‹è§å¢“ç¢‘ä¸Šå¤–å…¬çš„åå­—ï¼Œä»–ç¬‘å®¹ç¿çƒ‚çš„å½©è‰²ç…§ç‰‡ï¼Œåªæ˜¯å¾ˆæƒ³å¿µå¾ˆæƒ³å¿µã€‚å¦ˆå¦ˆè®©æˆ‘ä½œæ–çš„æ—¶å€™å¯ä»¥å¿ƒé‡Œè·Ÿå¤–å…¬è¯´ä¸€äº›è¯ï¼Œå‘Šè¯‰ä»–ä¸è¦æ‹…å¿ƒã€è¯·ä»–ä¿ä½‘ã€‚å¯æ˜¯æˆ‘ä¸€è¾¹ä½œæ–ä¸€è¾¹å¿ƒé‡Œåªæœ‰ä¸€ä¸ªå£°éŸ³ï¼šå°•å…¬å•Š å°•å…¬è¯¶[æ³ª]</li></ul>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;æˆ‘æ”¾å¼ƒç†è§£å¾ˆå¤šä¸œè¥¿&lt;/p&gt;
&lt;p&gt;æˆ‘å¼€å§‹æ‹¥æŠ±&lt;/p&gt;
&lt;p&gt;æƒŠäººçš„å¤æ‚æ€§&lt;/p&gt;
&lt;/blockquote&gt;
&lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=&quot;330&quot; height=&quot;450&quot; src=&quot;//music.163.com/outchain/player?type=0&amp;amp;id=7326559292&amp;amp;auto=1&amp;amp;height=430&quot;&gt;
&lt;/iframe&gt;
&lt;p&gt;è¿™ä¸¤å¤©åˆ—äº†ä¸€ä¸ªåå«ã€Œç²¾ç¥çŠ¶å†µã€çš„æ­Œå•ï¼Œé¡¾åæ€ä¹‰ï¼Œé´é€‰äº†å¤§æŠµæ˜¯æœ€èƒ½æœ‰æ•ˆè¡¨è¾¾æˆ‘è¿‘æ¥ç²¾ç¥çŠ¶å†µçš„9é¦–æ­Œï¼ˆä¸å‡ºæ‰€æ–™ä»¥æ‘‡æ»šä¸ºä¸»ï¼‰ã€‚å¥‡å¦™çš„æ˜¯ï¼Œä¸€æ–¹é¢æˆ‘è‡ªè¯©å¬æ­Œæ—¶å¯¹æ­Œè¯ç”šæ˜¯é‡è§†ï¼Œå¦ä¸€æ–¹é¢æœ€çˆ±çš„æ­Œç«Ÿç„¶æ­Œè¯å«é‡ä¸è¶³50%ã€‚æƒ³æƒ³ç°å®ï¼Œæˆ–è®¸æ˜¯æˆ‘æ”¾å¼ƒç†è§£å¾ˆå¤šä¸œè¥¿ï¼ˆç”¨ç†æ€§ï¼‰ï¼Œå¼€å§‹æ‹¥æŠ±å¤æ‚æ€§äº†å§ï¼ˆç”¨æ„Ÿæ€§ï¼Ÿï¼‰ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2022/03/14/W5bxdr9w3egqRGF.jpg&quot; style=&quot;zoom: 33%;&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="thoughts" scheme="https://jyzhu.top/categories/thoughts/"/>
    
    
  </entry>
  
  <entry>
    <title>å¤æ‚æ€§</title>
    <link href="https://jyzhu.top/complexity/"/>
    <id>https://jyzhu.top/complexity/</id>
    <published>2022-03-14T07:22:53.000Z</published>
    <updated>2022-03-14T07:26:15.368Z</updated>
    
    <content type="html"><![CDATA[<p>æˆ‘æ”¾å¼ƒç†è§£å¾ˆå¤šä¸œè¥¿</p><p>æˆ‘å¼€å§‹æ‹¥æŠ±</p><p>æƒŠäººçš„å¤æ‚æ€§</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;æˆ‘æ”¾å¼ƒç†è§£å¾ˆå¤šä¸œè¥¿&lt;/p&gt;
&lt;p&gt;æˆ‘å¼€å§‹æ‹¥æŠ±&lt;/p&gt;
&lt;p&gt;æƒŠäººçš„å¤æ‚æ€§&lt;/p&gt;
</summary>
      
    
    
    
    <category term="poems" scheme="https://jyzhu.top/categories/poems/"/>
    
    
  </entry>
  
  <entry>
    <title>Reading Pixel2Mesh++: Multi-View 3D Mesh Generation via Deformation</title>
    <link href="https://jyzhu.top/Reading-Pixel2meshPP/"/>
    <id>https://jyzhu.top/Reading-Pixel2meshPP/</id>
    <published>2022-02-06T09:59:29.000Z</published>
    <updated>2022-03-14T07:49:35.086Z</updated>
    
    <content type="html"><![CDATA[<p>è®ºæ–‡åœ°å€ï¼šhttps://arxiv.org/abs/1908.01491</p><p>ä½œè€…ï¼šChao Wen, Yinda Zhang, Zhuwen Li, Yanwei Fu</p><p>å‘è¡¨ï¼š ICCV 2019</p><p>é“¾æ¥ï¼š https://arxiv.org/abs/1908.01491</p><hr /><blockquote><p>å¦‚æœä½ å»åšè¿™ä¸ªä»»åŠ¡ï¼Œä¼šæ€ä¹ˆåšï¼Ÿä½œè€…åšçš„æ–¹æ³•å’Œä½ æƒ³çš„æœ‰ä»€ä¹ˆå·®å¼‚ï¼Ÿ</p></blockquote><h2 id="why">Whyï¼š</h2><ol type="1"><li>å•è§†è§’å›¾åƒ3Dé‡å»ºæ¨¡çš„æ•ˆæœä¸å¤Ÿå¥½ï¼Œå°¤å…¶æ˜¯èƒŒé¢ï¼Œè€Œä¸”æ³›åŒ–èƒ½åŠ›ä¹Ÿå·®ã€‚</li><li>æ‰€ä»¥å¢åŠ å¤šä¸ªè§†è§’çš„å›¾åƒï¼šæ›´å¤šè§†è§‰ä¿¡æ¯ï¼Œä¸”æœ‰å·²ç»å®šä¹‰å¾—å¾ˆå¥½çš„ä¼ ç»Ÿæ–¹æ³•ã€‚</li><li>ä½†æ˜¯ä¼ ç»Ÿæ–¹æ³•éœ€è¦æ›´å¤§é‡çš„å›¾åƒï¼›è¿™æ—¶å€™æ·±åº¦å­¦ä¹ æ¨¡å‹å¯ä»¥éšå¼ç¼–ç è§†è§’é—´çš„å…³è”ï¼Œå°±æ´¾ä¸Šäº†ç”¨åœºã€‚</li><li>å¾ˆæœ‰ç”¨ï¼Œä½†æ˜¯æ¬ ç ”ç©¶ã€‚</li></ol><h2 id="what">Whatï¼š</h2><ol type="1"><li>åˆ©ç”¨å¤šè§†è§’å›¾åƒï¼Œå›ºå®šç›¸æœºposeå‚æ•°ï¼Œåˆ©ç”¨GCNï¼Œä»ç²—ç³™é€æ¸ç²¾ç»†åœ°å˜å½¢ï¼Œç”Ÿæˆ3D meshé‡å»ºæ¨¡ã€‚</li><li>é‡‡æ ·meshæ¨¡å‹é¡¶ç‚¹å‘¨å›´çš„åŒºåŸŸï¼Œåˆ©ç”¨perceptual featureæ¨ç†å‡ºå¯¹meshçš„å½¢å˜ã€‚</li><li>å¯¹äºä¸åŒç§ç±»çš„ç‰©ä½“æ³›åŒ–èƒ½åŠ›å¾ˆå¥½ã€‚</li></ol><p>è¯»å‰ç–‘é—®ï¼š</p><ol type="1"><li>ä¼¼ä¹å°±æ˜¯ç»™pixel2meshåŠ ä¸Šä¸€å±‚å£³ï¼Œåº”ç”¨åœ¨å¤šè§†è§’å›¾åƒä¸ŠğŸ¤”é‚£ä¹ˆè¿™é‡Œçš„åˆ›æ–°ç‚¹æœ¬è´¨åœ¨å“ªå„¿å‘¢ï¼Ÿ</li><li>GCNç”¨å¤„å¤§å—ï¼Œä¸ºä»€ä¹ˆç”¨å®ƒï¼Ÿ</li><li>é‡‡æ ·meshé¡¶ç‚¹å‘¨å›´çš„åŒºåŸŸï¼Œæ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ</li><li>å¤šè§†è§’3Dé‡å»ºï¼Œåº”ç”¨çœŸçš„å¹¿æ³›å—ï¼Ÿ</li></ol><h2 id="how">Howï¼š</h2><ol type="1"><li>å¤šè§†è§’å˜å½¢ç½‘ç»œ Multi-View Deformation Network (MDN)</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;è®ºæ–‡åœ°å€ï¼šhttps://arxiv.org/abs/1908.01491&lt;/p&gt;
&lt;p&gt;ä½œè€…ï¼šChao Wen, Yinda Zhang, Zhuwen Li, Yanwei Fu&lt;/p&gt;
&lt;p&gt;å‘è¡¨ï¼š ICCV 2019&lt;/p&gt;
&lt;p&gt;é“¾æ¥ï¼š https://arxiv.org/abs/1908.01491&lt;/p&gt;</summary>
    
    
    
    <category term="Computer Notes" scheme="https://jyzhu.top/categories/Computer-Notes/"/>
    
    
    <category term="Computer Vision" scheme="https://jyzhu.top/tags/Computer-Vision/"/>
    
    <category term="Deep Learning" scheme="https://jyzhu.top/tags/Deep-Learning/"/>
    
    <category term="3D Reconstruction" scheme="https://jyzhu.top/tags/3D-Reconstruction/"/>
    
  </entry>
  
  <entry>
    <title>Reading Self-supervised Single-view 3D Reconstruction via Semantic Consistency</title>
    <link href="https://jyzhu.top/Reading-Self-supervised-Single-view-3D-Reconstruction-via-Semantic-Consistency/"/>
    <id>https://jyzhu.top/Reading-Self-supervised-Single-view-3D-Reconstruction-via-Semantic-Consistency/</id>
    <published>2022-01-22T06:49:01.000Z</published>
    <updated>2022-02-05T10:17:41.929Z</updated>
    
    <content type="html"><![CDATA[<p>è®ºæ–‡åœ°å€ï¼šhttps://arxiv.org/abs/2003.06473</p><p>ä½œè€…ï¼šXueting Li, Sifei Liu, Kihwan Kim, Shalini De Mello, Varun Jampani, Ming-Hsuan Yang, and Jan Kautz</p><p>å‘è¡¨ï¼š ECCV 2020</p><p>é“¾æ¥ï¼š https://github.com/NVlabs/UMR</p><hr /><blockquote><p>å¦‚æœä½ å»åšè¿™ä¸ªä»»åŠ¡ï¼Œä¼šæ€ä¹ˆåšï¼Ÿä½œè€…åšçš„æ–¹æ³•å’Œä½ æƒ³çš„æœ‰ä»€ä¹ˆå·®å¼‚ï¼Ÿ</p></blockquote><h2 id="why">Whyï¼š</h2><ol type="1"><li>åœ¨3dé‡å»ºæ¨¡ä»»åŠ¡ä¸­ï¼ŒåŒæ—¶é¢„æµ‹å½¢çŠ¶ã€ç›¸æœºä½ç½®å’Œæè´¨æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„é—®é¢˜ï¼Œå› ä¸ºå®ƒå†…åœ¨çš„ä¸ç¡®å®šæ€§ã€‚</li><li>ç°æœ‰æ–¹æ³•éƒ½éœ€è¦å€ŸåŠ©å„ç§æ‰‹æ®µï¼š3Då±‚é¢çš„ç›‘ç£ã€2Dè¯­ä¹‰å…³é”®ç‚¹ã€shadingï¼ˆè¿™æ˜¯ä»€ä¹ˆï¼Ÿï¼‰ã€ç‰¹å®šç±»åˆ«çš„3D template ã€å¤šè§†è§’ç­‰ç­‰ã€‚è¿™äº›æ–¹æ³•éœ€è¦å¤§é‡äººåŠ›ï¼Œæ‰€ä»¥å¾ˆéš¾å¹¿æ³›åº”ç”¨ã€‚</li><li>äººç±»ä¼šç›´è§‰æ„ŸçŸ¥åˆ°ä¸€ä¸ªç‰©ä½“åŒ…æ‹¬å„ä¸ªéƒ¨åˆ†ï¼Œæ¯”å¦‚é¸Ÿæœ‰ä¸¤åªè…¿ã€ä¸¤ä¸ªç¿…è†€ã€ä¸€ä¸ªå¤´ï¼Œä»è€Œè¯†åˆ«ç‰©ä½“ã€‚ç±»ä¼¼çš„ï¼Œcvå—æ­¤å¯å‘ï¼Œä¹Ÿå¯ä»¥å°†ä¸€ä¸ªç‰©ä½“å®šä¹‰ä¸ºå¤šä¸ªå¯å˜å½¢çš„éƒ¨åˆ†çš„é›†åˆã€‚</li></ol><h2 id="what">Whatï¼š</h2><ol type="1"><li>ä»…éœ€è¦å•å¼ å›¾ç‰‡+è½®å»“maskï¼Œåˆ©ç”¨è¯­ä¹‰ä¸€è‡´æ€§ï¼Œå®ç°è‡ªç›‘ç£3Dé‡å»ºæ¨¡</li><li>æ€è·¯ï¼š1. æ¯ä¸ªç‰©ä½“å¯ä»¥çœ‹ä½œç”±å¯å˜å½¢çš„éƒ¨åˆ†ç»„æˆï¼›2. å¯¹åŒä¸€ç±»å‹çš„ä¸åŒç‰©ä½“ï¼Œå®ƒä»¬çš„æ¯ä¸€éƒ¨åˆ†åœ¨è¯­ä¹‰ä¸Šéƒ½æ˜¯ä¸€è‡´çš„</li><li>é€šè¿‡è‡ªç›‘ç£å­¦ä¹ å¤§é‡åŒç±»çš„å›¾ç‰‡ï¼Œå¯ä»¥å»ºç«‹é‡å»ºçš„meshæ¨¡å‹ä¸å›¾ç‰‡ä¹‹é—´çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚è¿™æ ·åœ¨åŒæ—¶é¢„æµ‹å½¢çŠ¶ã€ç›¸æœºä½ç½®å’Œæè´¨çš„æ—¶å€™ï¼Œå¯ä»¥é™ä½æ¨¡ç³Šæ€§ã€‚</li><li>ç¬¬ä¸€ä¸ªåšåˆ°ä¸éœ€è¦ç‰¹å®šç±»åˆ«çš„template meshæ¨¡å‹æˆ–è€…è¯­ä¹‰å…³é”®ç‚¹ï¼Œå°±å¯ä»¥ä»å•è§†è§’å›¾åƒä¸­å®ç°3dé‡å»ºæ¨¡ã€‚å› æ­¤ï¼Œè¿™ä¸ªæ–¹æ³•å¯ä»¥æ¨å¹¿åˆ°å„ç§ç‰©ä½“ç±»åˆ«ï¼Œè€Œä¸éœ€è¦ç±»åˆ«çš„æ ‡ç­¾</li></ol><p>è¯»å‰ç–‘é—®ï¼š</p><h2 id="how">Howï¼š</h2><h3 id="æ¨¡å‹">æ¨¡å‹</h3><figure><img src="https://s2.loli.net/2022/01/27/x2BKozeFVpgUPkE.png" alt="image-20220122145159190" /><figcaption>image-20220122145159190</figcaption></figure><ol type="1"><li>ï¼ˆaï¼‰æ˜¯åŸå§‹å›¾ç‰‡ã€‚éœ€è¦åŒä¸€ç±»åˆ«çš„å¤§é‡å›¾ç‰‡ä¸€èµ·ä½œä¸ºè¾“å…¥</li><li>ï¼ˆbï¼‰ç”¨SCOPSæ¨¡å‹ï¼ˆå¦ä¸€ç¯‡å·¥ä½œï¼‰ï¼Œå¯¹å›¾åƒè¿›è¡Œè¯­ä¹‰åˆ†å‰²çš„ç»“æœã€‚è¿™ä¸ªæ¨¡å‹ä¹Ÿæ˜¯è‡ªç›‘ç£çš„</li><li>ï¼ˆcï¼‰æ ‡å‡†è¯­ä¹‰ uv mapï¼ˆCanonical semantic uv mapï¼‰ï¼š<ol type="1"><li>ç†è®ºä¸Šï¼ŒåŒä¸€ç±»ç‰©ä½“çš„meshæ¨¡å‹ï¼Œå°½ç®¡å„è‡ªéƒ½æœ‰ä¸åŒçš„å½¢çŠ¶ï¼Œä½†æ¯ä¸ªç‚¹çš„è¯­ä¹‰å«ä¹‰éƒ½æ˜¯ä¸€è‡´çš„ã€‚</li><li>å› æ­¤ï¼Œæ ¹æ®å‰ä¸€æ­¥ç”Ÿæˆçš„å¤§é‡è¯­ä¹‰åˆ†å‰²ç»“æœï¼Œå¯ä»¥ç”Ÿæˆä¸€å¼ å¯¹åº”è¿™ä¸ªç±»åˆ«çš„Canonicalè¯­ä¹‰uv mapã€‚</li></ol></li><li>ï¼ˆdï¼‰ç”±å‰ä¸€æ­¥ç”Ÿæˆçš„Canonicalè¯­ä¹‰uv mapï¼Œå¯ä»¥å¾—åˆ°é‡å»ºçš„meshæ¨¡å‹è¡¨é¢çš„ç‚¹å¯¹åº”çš„è¯­ä¹‰æ ‡ç­¾</li><li>æ©˜è‰²ç®­å¤´ï¼šè¿™ä¸ªå°±æ˜¯è¯­ä¹‰ä¸€è‡´æ€§äº†ï¼Œå®ƒé¼“åŠ±2Då›¾åƒå’Œ3Dæ¨¡å‹ä¹‹é—´çš„è¯­ä¹‰æ ‡ç­¾ç›¸äº’ä¸€è‡´ã€‚è¿™æ ·ï¼Œå°±å¯ä»¥è§£å†³å‰é¢æåˆ°è¿‡çš„åœ¨3Dé‡å»ºæ¨¡çš„æ—¶å€™çš„â€œç›¸æœº-å½¢çŠ¶ä¸ç¡®å®šæ€§â€è¿™ä¸ªéš¾é¢˜</li></ol><h3 id="å…·ä½“æ–¹æ³•">å…·ä½“æ–¹æ³•</h3><h4 id="cmræ˜¯baseline">CMRæ˜¯baseline</h4><ol type="1"><li>ç”¨ä¸‰ä¸ªdecoder <span class="math inline">\(D_{shape}\ D_{camera}\ D_{texture}\)</span> åŒæ—¶é¢„æµ‹meshæ¨¡å‹çš„å½¢çŠ¶ã€ç›¸æœºå’Œæè´¨<ol type="1"><li>å½¢çŠ¶ <span class="math inline">\(V=\tilde V + \Delta V\)</span>ï¼Œå…¶ä¸­ $V $ æ˜¯æŸç±»ç‰©ä½“çš„template meshæ¨¡å‹ï¼Œ<span class="math inline">\(\Delta V\)</span> æ˜¯é¢„æµ‹å‡ºæ¥çš„ç‚¹çš„åç§»é‡</li><li>ç›¸æœºpose <span class="math inline">\(\theta\)</span> æ˜¯ weak perspective transformation ï¼ˆï¼Ÿï¼‰</li><li>æè´¨ <span class="math inline">\(I_{flow}\)</span> æ˜¯ UV flowï¼Œæ˜¯å°†è¾“å…¥å›¾ç‰‡åˆ°UVç©ºé—´çš„æ˜ å°„ï¼Œç„¶åå®ƒå¯ä»¥è¢«ä¸€ä¸ªå·²ç»å®šä¹‰å¥½çš„å‡½æ•°<span class="math inline">\(\phi\)</span>æ˜ å°„åˆ°meshæ¨¡å‹çš„è¡¨é¢çš„æ¯ä¸€ä¸ªç‚¹</li></ol></li><li>ä½†æ˜¯CMRéœ€è¦äººå·¥æ ‡æ³¨çš„å…³é”®ç‚¹ä½œä¸ºè¾“å…¥ï¼Œè¿™ç¯‡è®ºæ–‡ä¸»è¦å°±æ˜¯æŠŠå®ƒå»æ‰äº†ã€‚å»æ‰ä¹‹åå‘¢ï¼Œä¼šå‡ºç°ç›¸æœº+å½¢çŠ¶åŒæ—¶é¢„æµ‹æ—¶Ambiguityçš„é—®é¢˜ï¼Œæ‰€ä»¥å°±æƒ³æ–¹è®¾æ³•è§£å†³è¿™ä¸ªé—®é¢˜ã€‚</li></ol><figure><img src="https://s2.loli.net/2022/01/27/TkWsiJxMN38tKGu.png" alt="image-20220122160143711" /><figcaption>image-20220122160143711</figcaption></figure><h4 id="è¯­ä¹‰ä¸€è‡´æ€§è§£å†³ç›¸æœºå½¢çŠ¶åŒæ—¶é¢„æµ‹æ—¶çš„ambiguity">è¯­ä¹‰ä¸€è‡´æ€§ï¼šè§£å†³ç›¸æœº+å½¢çŠ¶åŒæ—¶é¢„æµ‹æ—¶çš„Ambiguity</h4><p>ä¹Ÿå°±æ˜¯Fig 3ä¸­çº¢è‰²æ¡†çš„éƒ¨åˆ†ã€‚</p><ol type="1"><li><p><em>è¯­ä¹‰éƒ¨ä»¶ä¸å˜æ€§ semantic part invarianceï¼š</em></p><ol type="1"><li>å¯¹äº2Då›¾åƒï¼Œç”¨SCOPSï¼ˆè‡ªç›‘ç£co-partè¯­ä¹‰åˆ†å‰²ï¼Œå¦ä¸€ç¯‡è®ºæ–‡çš„æ–¹æ³•ï¼‰å¯ä»¥å¾ˆå‡†ç¡®åœ°å¯¹ç‰©ä½“å„ä¸ªéƒ¨åˆ†è¿›è¡Œåˆ†å‰²</li><li>å¯¹äº3D meshï¼Œæ¯ä¸ªç‚¹çš„è¯­ä¹‰å«ä¹‰æ˜¯å›ºå®šä¸å˜çš„ï¼Œå°±ç®—æ¯ä¸ªç‰©ä½“ä¼šæœ‰å„è‡ªçš„å½¢å˜</li></ol></li><li><p><em>è¯­ä¹‰ä¸€è‡´æ€§</em>ï¼š</p><ol type="1"><li><p><img src="https://s2.loli.net/2022/01/27/TzCkKA462gRbOFa.png" alt="image-20220124121618081" style="zoom:50%;" /></p><p>ä»Fig 4 (i) å¯ä»¥çœ‹åˆ°ï¼Œå¦‚æœæ²¡æœ‰è¯­ä¹‰ä¸€è‡´æ€§ï¼Œmeshæ¨¡å‹ä¸­åŸæœ¬å¯¹åº”å¤´çš„é¡¶ç‚¹è¢«å½“ä½œäº†ç¿…è†€å°–ï¼Œè¿™æ ·é”™è¯¯çš„å˜å½¢å¯¹åº”äº†é”™è¯¯çš„ç›¸æœºposeã€‚è¿™å°±æ˜¯ç›¸æœº+å½¢çŠ¶åŒæ—¶é¢„æµ‹æ—¶çš„Ambiguityã€‚</p></li><li><p>å‰é¢å·²ç»æåˆ°è¿‡ï¼Œå¯ä»¥ä¸ºæ¯ä¸ªå…·ä½“ç±»åˆ«ç”Ÿæˆä¸€å¼ æ ‡å‡†è¯­ä¹‰ uv mapï¼ˆCanonical semantic uv mapï¼‰ã€‚è¿™é‡Œï¼Œå°±å¯ä»¥è®© æ¯ä¸ªç‰©ä½“çš„2Dè¯­ä¹‰åˆ†å‰²ç»“æœ ä¸ æ ‡å‡†è¯­ä¹‰ uv map ä¿æŒä¸€è‡´æ€§ï¼Œä»è€Œè®©3Dæ¨¡å‹çš„æ¯ä¸ªè¯­ä¹‰éƒ¨ä»¶è·Ÿ2Då›¾åƒé‡Œç›¸åº”çš„ä½ç½®æœ‰å¯¹åº”å…³ç³»ã€‚è¿™æ ·å¯ä»¥å¾ˆå¥½åœ°è§£å†³ç›¸æœº-å½¢çŠ¶Ambiguityé—®é¢˜ã€‚</p></li></ol></li></ol><h5 id="é€šè¿‡scopså®ç°2då›¾åƒä¸­éƒ¨ä»¶çš„åˆ†å‰²">é€šè¿‡SCOPSå®ç°2Då›¾åƒä¸­éƒ¨ä»¶çš„åˆ†å‰²</h5><p><img src="https://s2.loli.net/2022/01/27/YFNpoKzfxkBRSbI.png" alt="image-20220124114332065" style="zoom:50%;" /></p><p>SCOPS æ˜¯è‡ªç›‘ç£çš„æ–¹æ³•ï¼Œä»ä¸€ç±»ç‰©ä½“çš„å¤§é‡å›¾ç‰‡ä¸­å‘æ˜å…±åŒçš„è¯­ä¹‰éƒ¨ä»¶ã€‚Fig 10ç¬¬äºŒè¡Œå°±æ˜¯å®ƒçš„ç»“æœã€‚åé¢è¿˜ä¼šæåˆ°ï¼Œé€šè¿‡æœ¬æ–‡çš„æ–¹æ³•ï¼Œè¿˜å¯ä»¥åè¿‡æ¥æå‡SCOPSçš„ç»“æœï¼šåˆ©ç”¨ç”Ÿæˆçš„æ ‡å‡†è¯­ä¹‰UV mapä½œä¸ºä¼ªæ ‡æ³¨åè¿‡æ¥è¿›è¡Œç›‘ç£ã€‚</p><h5 id="é€šè¿‡æ ‡å‡†è¯­ä¹‰uv-mapå®ç°3dæ¨¡å‹ä¸­éƒ¨ä»¶çš„åˆ†å‰²">é€šè¿‡æ ‡å‡†è¯­ä¹‰uv mapå®ç°3Dæ¨¡å‹ä¸­éƒ¨ä»¶çš„åˆ†å‰²</h5><ol type="1"><li><p>å·²ç»æœ‰äº†ï¼š</p><ol type="1"><li>æ¨¡å‹å­¦åˆ°çš„texture flow <span class="math inline">\(I_{flow}\)</span>å¯ä»¥å°†è¾“å…¥å›¾ç‰‡æ˜ å°„åˆ°UVç©ºé—´ï¼Œç„¶åå®ƒå¯ä»¥è¢«ä¸€ä¸ªå·²ç»å®šä¹‰å¥½çš„å‡½æ•°<span class="math inline">\(\phi\)</span>æ˜ å°„åˆ°meshæ¨¡å‹çš„è¡¨é¢çš„æ¯ä¸€ä¸ªç‚¹</li><li>é€šè¿‡SCOPSç”Ÿæˆçš„å›¾åƒ <span class="math inline">\(i\)</span> çš„è¯­ä¹‰åˆ†å‰²ç»“æœ <span class="math inline">\(P^i\in R^{H\times W\times N_p}\)</span>ï¼Œ å…¶ä¸­Hå’ŒWæ˜¯é•¿å’Œå®½ï¼Œ <span class="math inline">\(N_p\)</span> æ˜¯è¯­ä¹‰éƒ¨ä»¶æ•°é‡</li></ol></li><li><p>è¿™æ ·çš„è¯ï¼Œé€šè¿‡æ¨¡å‹çš„ <span class="math inline">\(I_{flow}\)</span> å°±å¯ä»¥æŠŠ2Dçš„è¯­ä¹‰åˆ†å‰²ç»“æœ <span class="math inline">\(P^i\)</span> æ˜ å°„åˆ° UV ç©ºé—´ï¼ŒæŠŠè¿™ä¸ªç§°ä¸º è¯­ä¹‰UV map</p></li><li><p>ç†è®ºä¸Šæ¥è¯´ï¼ŒåŒä¸€ç±»åˆ«çš„æ‰€æœ‰ç‰©ä½“éƒ½åº”è¯¥å¾—åˆ°åŒä¸€ä¸ªè¯­ä¹‰UV mapï¼Œå› ä¸º 1. æ ¹æ®è¯­ä¹‰éƒ¨ä»¶ä¸å˜æ€§ï¼Œmeshæ¨¡å‹çš„æ¯ä¸ªé¡¶ç‚¹å¯¹åº”çš„è¯­ä¹‰éƒ¨ä»¶éƒ½æ˜¯å›ºå®šä¸å˜çš„ 2. UV mapå’Œ3d mesh ä¸­çš„ç‚¹åˆæ˜¯é€šè¿‡<span class="math inline">\(\Phi\)</span>æ˜ å°„çš„å…³ç³»ï¼Œæ¯ä¸ªé¡¶ç‚¹å¯¹åº”çš„UV mapä¸Šçš„åæ ‡ä¹Ÿæ˜¯ä¸å˜çš„ã€‚</p></li><li><p>ä½†æ˜¯å› ä¸ºSCOPS + <span class="math inline">\(I_{flow}\)</span> çš„è¯¯å·®ï¼Œå„ä¸ªç‰©ä½“ç”Ÿæˆçš„è¯­ä¹‰UV mapäº‹å®ä¸Šå¾ˆä¸ä¸€æ ·ã€‚æ‰€ä»¥è¿™é‡Œæå‡ºäº†å¯¹ æ ‡å‡†è¯­ä¹‰UV map <span class="math inline">\(\bar P_{uv}\)</span> çš„ä¼°è®¡æ–¹æ³•ï¼š</p><ol type="1"><li><p>é€šè¿‡æŸç§æ–¹æ³•é€‰æ‹©å‡ºè®­ç»ƒé›†ä¸­æ•ˆæœæ¯”è¾ƒå¥½çš„å­é›† <span class="math inline">\(\mathcal{U}\)</span>ï¼Œå¯¹å®ƒä»¬çš„ç»“æœè¿›è¡ŒåŠ å’Œï¼Œ</p><p><strong>é€‰æ‹©æ ·æœ¬çš„æ–¹å¼</strong>ï¼š</p><ol type="1"><li>é¦–å…ˆé€‰æ‹©æœ€å¥½çš„é‚£ä¸€ä¸ªæ ·æœ¬ï¼Œå³ perceptual distanceï¼ˆ3DæŠ•å½±åˆ°2Dçš„å›¾åƒä¸åŸå§‹RGBå›¾åƒçš„çŸ¥è§‰è·ç¦»ï¼Ÿï¼‰æœ€å°çš„</li><li>ç„¶åé€‰æ‹©Kä¸ªè·Ÿè¿™ä¸ªæœ€å¥½çš„æ ·æœ¬æœ€æ¥è¿‘çš„æ ·æœ¬ï¼Œå³å®ƒä»¬çš„è¯­ä¹‰UV mapæœ€æ¥è¿‘</li></ol><p>å…¬å¼å¦‚ä¸‹ï¼š</p></li><li><p><span class="math display">\[\bar P_{uv}=\frac{1}{|\mathcal{U}|}\sum_{i\in \mathcal{U}}I^i_{flow}(P^i)\]</span></p><p>å…¶ä¸­ <span class="math inline">\(I^i_{flow}(P^i)\)</span> å°±æ˜¯é€šè¿‡ <span class="math inline">\(I_{flow}\)</span> æ˜ å°„è¯­ä¹‰åˆ†å‰²ç»“æœ <span class="math inline">\(P^i\)</span> å¾—åˆ°çš„ è¯­ä¹‰UV mapã€‚</p></li></ol></li></ol><h5 id="d-å’Œ-3d-é—´çš„è¯­ä¹‰ä¸€è‡´æ€§">2D å’Œ 3D é—´çš„è¯­ä¹‰ä¸€è‡´æ€§</h5><ol type="1"><li><p><em>åŸºäºæ¦‚ç‡çš„çº¦æŸ Probability-based constraint</em></p><ol type="1"><li><p><span class="math display">\[L_{sp}=||P^i-\mathcal{R}(\Phi (\bar P_{uv});\theta^i)||^2\]</span></p><p>æ ‡å‡†è¯­ä¹‰UV map <span class="math inline">\(\bar P_{uv}\)</span> ç”±é¢„å®šä¹‰å¥½çš„å‡½æ•° <span class="math inline">\(\Phi\)</span> æ˜ å°„åˆ° 3D meshè¡¨é¢ï¼Œç„¶åé‡‡ç”¨é¢„æµ‹å¥½çš„ç›¸æœºpose <span class="math inline">\(\theta^i\)</span> ï¼Œç”¨å¯å¾®åˆ†æ¸²æŸ“ <span class="math inline">\(\mathcal{R}\)</span> å°†3Dæ¨¡å‹æ¸²æŸ“åˆ°2Dï¼Œç„¶åå°†ç»“æœä¸å¯¹åº”çš„ç”±SCOPSç”Ÿæˆçš„éƒ¨ä»¶åˆ†å‰²æ¦‚ç‡å›¾ <span class="math inline">\(P^i\)</span> åšå‡æ–¹è¯¯å·®ã€‚</p></li><li><p>æ³¨ï¼šè¿™ä¸ªç”±SCOPSç”Ÿæˆçš„å›¾åƒåˆ†å‰²ç»“æœ <span class="math inline">\(P^i\)</span> æ˜¯æ¦‚ç‡æ•°å€¼çš„å½¢å¼</p></li><li><p>ç»éªŒæ€§åœ°é€‰æ‹©äº†é‡‡ç”¨å‡æ–¹è¯¯å·®MSEï¼Œæ¯” KullbackLeibler divergence æ•ˆæœå¥½</p></li></ol></li><li><p><em>åŸºäºé¡¶ç‚¹çš„çº¦æŸ Vertex-based constraint</em></p><ol type="1"><li><p>è®©3Dæ¨¡å‹æŠ•å½±å›2Dä¹‹åï¼Œè¢«åˆ†ç±»åˆ°æŸä¸ªè¯­ä¹‰partçš„é¡¶ç‚¹ä»ç„¶å¤„åœ¨å›¾åƒä¸­è¯¥partå¯¹åº”çš„åŒºåŸŸ</p></li><li><p><span class="math display">\[L_{sv}=\sum^{N_p}_{p=1} \frac{1}{|\bar V_p|}Chamfer(\mathcal{R}(\bar V_p;\theta^i),Y_p^i)\]</span></p><p>å…¶ä¸­ï¼Œ<span class="math inline">\(\bar V_p\)</span> æ˜¯å·²ç»å­¦å¥½çš„æŸç±»ç‰©ä½“çš„template meshä¸­å±äºéƒ¨ä»¶pçš„é‚£éƒ¨åˆ†ï¼Œ<span class="math inline">\(Y_p^i\)</span>æ˜¯åŸå§‹2Då›¾åƒä¸­å±äºéƒ¨ä»¶pçš„é‚£éƒ¨åˆ†ï¼Œ<span class="math inline">\(N_p\)</span> æ˜¯è¯­ä¹‰éƒ¨ä»¶æ•°é‡ã€‚</p></li><li><p>ç”¨Chamfer distanceæ˜¯å› ä¸ºæŠ•å½±åçš„é¡¶ç‚¹å’ŒåŸå§‹çš„åƒç´ ç‚¹å¹¶ä¸æ˜¯ä¸¥æ ¼ä¸€å¯¹ä¸€å¯¹åº”çš„å…³ç³»</p></li><li><p>ç”¨æŸç±»ç‰©ä½“çš„template meshï¼Œå°±å¯ä»¥è®©ç½‘ç»œå­¦ç›¸æœºposeï¼›åä¹‹ï¼Œå‡å¦‚ç”¨å•ä¸ªå…·ä½“ç‰©ä½“çš„meshçš„è¯ï¼Œç½‘ç»œå°±ä»…ä»…ä¼šå¯¹3Dç‰©ä½“çš„å½¢çŠ¶è¿›è¡Œæ‰­æ›²ï¼Œä¸ä¼šå­¦åˆ°æ­£ç¡®çš„ç›¸æœºposeäº†ã€æˆ‘æœ‰ç‚¹ä¸ç†è§£ä¸ºå•¥ã€‘</p></li></ol></li></ol><h3 id="æ¸è¿›çš„è®­ç»ƒæ–¹æ³•em">æ¸è¿›çš„è®­ç»ƒæ–¹æ³•EM</h3><ol type="1"><li><p>ä¹‹æ‰€ä»¥è¦ç”¨æ¸è¿›å¼è®­ç»ƒï¼Œæ˜¯å› ä¸º</p><ol type="1"><li>éœ€è¦3Dé‡å»ºæ¨¡ç½‘ç»œé¦–å…ˆå­¦ä¼šä¸€ä¸ªå¤§ä½“ä¸Šå¯ç”¨çš„texture encoder <span class="math inline">\(I_{flow}\)</span>ï¼Œç„¶åæ‰èƒ½ç”Ÿæˆæ ‡å‡†è¯­ä¹‰UV mapï¼Œ</li><li>è¿™æ ·è¿˜èƒ½å…ˆç”Ÿæˆå¯¹åº”å…·ä½“ç±»åˆ«çš„template meshï¼Œä¸€æ–¹é¢åŠ é€Ÿç½‘ç»œçš„æ”¶æ•›ï¼Œä¸€æ–¹é¢å¯ä»¥ç”¨åœ¨å‰é¢æåˆ°çš„<em>åŸºäºé¡¶ç‚¹çš„çº¦æŸ</em>ä¸­ã€‚</li></ol></li><li><p>ä½†æ˜¯ï¼Œå¦‚æœç›´æ¥æŠŠtemplate meshå’Œé‡å»ºæ¨¡æ¨¡å‹å…¨éƒ½ä¸€èµ·å­¦ä¹ çš„è¯ï¼Œæ•ˆæœä¸å¥½ï¼›æ‰€ä»¥å°±æå‡ºäº†ï¼šEMè®­ç»ƒæ­¥éª¤ï¼ˆexpectation-maximizationæœŸæœ›æœ€å¤§åŒ–ï¼Ÿï¼‰ï¼Œå°±æ˜¯å…ˆå›ºå®šä¸€éƒ¨åˆ†å­¦ä¹ å¦ä¸€éƒ¨åˆ†ã€‚</p><ol type="1"><li><p><strong>E</strong>ï¼šå›ºå®šæ ‡å‡†è¯­ä¹‰UV mapå’Œtemplateï¼ˆåˆå§‹æ˜¯çƒä½“ï¼‰ï¼Œ<strong>è®­ç»ƒé‡å»ºæ¨¡ç½‘ç»œ</strong>ã€‚200è½®ã€‚</p><p>lossåŒ…æ‹¬ï¼š</p><ol type="1"><li><p>3DæŠ•å½±åˆ°2Dçš„å›¾åƒä¸gtå‰ªå½±çš„ IoU âœ–ï¸ -1</p></li><li><p>3DæŠ•å½±åˆ°2Dçš„å›¾åƒä¸åŸå§‹RGBå›¾åƒçš„ perceptual distanceï¼ˆçŸ¥è§‰è·ç¦»ï¼Ÿï¼‰</p></li><li><p>å‰é¢æåˆ°çš„åŸºäºæ¦‚ç‡çš„çº¦æŸå’ŒåŸºäºé¡¶ç‚¹çš„çº¦æŸ</p></li><li><p>æè´¨å¾ªç¯ä¸€è‡´æ€§ Texture cycle consistencyï¼š</p><ol type="1"><li><figure><img src="https://s2.loli.net/2022/01/27/SU3aFdKZrOtAiws.png" alt="image-20220124182432533" /><figcaption>image-20220124182432533</figcaption></figure><p>å­¦ä¹ texture flowçš„æ—¶å€™æœ€å¤§çš„é—®é¢˜ï¼šé¢œè‰²ç›¸ä¼¼çš„3D meshçš„é¢ä¼šè¢«å¯¹åº”åˆ°é”™è¯¯çš„2Då›¾åƒçš„åƒç´ ç‚¹ä¸Š</p></li><li><p>è¿™æ˜¯ä¸€ä¸ªcycleï¼šå¼ºåˆ¶é¢„æµ‹å‡ºæ¥çš„texture flowï¼ˆ2D to 3Dï¼‰å’Œç›¸æœºæŠ•å½±ï¼ˆ3D to 2Dï¼‰äºŒè€…ä¸€è‡´ã€‚</p></li><li><p>é¦–å…ˆå®šä¹‰äº†<span class="math inline">\(\mathcal{C}_{in}^j\)</span>ã€ <span class="math inline">\(\mathcal{C}_{out}^j\)</span>åˆ†åˆ«æ˜¯è¾“å…¥å›¾åƒä¸­è¢«æ˜ å°„åˆ°ä¸‰è§’å½¢é¢<span class="math inline">\(j\)</span>çš„ä¸€å®šæ•°é‡åƒç´ ç‚¹çš„å‡ ä½•ä¸­å¿ƒï¼Œå’Œä»ä¸‰è§’å½¢é¢<span class="math inline">\(j\)</span>æ¸²æŸ“å›2Då›¾åƒæ—¶å¯¹åº”çš„ä¸€å®šæ•°é‡åƒç´ ç‚¹çš„å‡ ä½•ä¸­å¿ƒã€‚å…¬å¼å¦‚ä¸‹ï¼š <span class="math display">\[\mathcal{C}_{in}^j = \frac{1}{N_c}\sum^{N_c}_{m=1}\Phi(I_{flow}(\mathcal{G}^m))_j;\\ \mathcal{C}_{out}^j = \frac{\sum^{H\times W}_{m=1}\mathcal{W}_j^m\times \mathcal{G}^m}{\sum^{H\times W}_{m=1}\mathcal{W}_j^m}\]</span> å…¶ä¸­ï¼Œ<span class="math inline">\(\mathcal{G}^m\)</span>æ˜¯æŠ•å½±å›¾åƒçš„æ ‡å‡†åæ ‡ç½‘æ ¼ï¼ˆåŒ…å«äº†åƒç´ çš„åæ ‡<span class="math inline">\((u,v)\)</span>å€¼ï¼‰ï¼Œ<span class="math inline">\(\Phi\)</span>æ˜¯UV mapï¼Œ<span class="math inline">\(I_{flow}\)</span>æŠŠåƒç´ æ˜ å°„åˆ°3D meshçš„é¢<span class="math inline">\(j\)</span>ä¸Šï¼›<span class="math inline">\(N_c\)</span>æ˜¯å¯¹åº”åˆ°é¢<span class="math inline">\(j\)</span>çš„åƒç´ ç‚¹çš„æ•°é‡ï¼›<span class="math inline">\(\mathcal{W}\)</span>æ˜¯å¯å¾®åˆ†æ¸²æŸ“æ—¶ç”Ÿæˆçš„æ¦‚ç‡mapï¼Œæ¯ä¸ª<span class="math inline">\(\mathcal{W}_j^m\)</span>è¡¨ç¤ºé¢ j è¢«æŠ•å½±åˆ°åƒç´  m ä¸Šçš„æ¦‚ç‡ã€‚</p><ul><li>æŠŠé‡å»ºæ¨¡meshæ¨¡å‹æ¸²æŸ“æˆ2Då›¾åƒï¼Œç”¨çš„æ˜¯ Soft Rasterizerï¼Œè€Œä¸æ˜¯CMRä¸­ç”¨çš„ Neural Mesh Rendererï¼Œå› ä¸ºå‰è€…å¯ä»¥æä¾›æ¦‚ç‡mapï¼Œä¾›texture cycle consistencyä½¿ç”¨</li></ul></li><li><p>é‚£ä¹ˆï¼Œæè´¨å¾ªç¯ä¸€è‡´æ€§å°±æ˜¯è®©<span class="math inline">\(\mathcal{C}_{in}^j\)</span>æ¥è¿‘ <span class="math inline">\(\mathcal{C}_{out}^j\)</span>ï¼š <span class="math display">\[L_{tcyc} = \frac{1}{|F|}\sum^{|F|}_{j=1}||\mathcal{C}_{in}^j-\mathcal{C}_{out}^j||^2_F\]</span></p></li></ol></li><li><p>è¿˜æœ‰å†™åœ¨é™„å½•é‡Œçš„ä¸¤ä¸ªlossï¼š</p><ol type="1"><li>graph Laplacian constraint æ¥é¼“åŠ±meshè¡¨é¢å¹³æ»‘ã€ä»pixel-meshä¸­æ¥çš„ã€‘</li><li>edge regularization æ¥æƒ©ç½šå¤§å°ä¸è§„åˆ™çš„é¢ ä»£ç é‡Œä¼¼ä¹æ˜¯flatten loss</li></ol></li><li><p>è¿˜æœ‰å†™åœ¨é™„å½•é‡Œçš„å¯¹æŠ—è®­ç»ƒloss</p></li></ol></li><li><p><strong>M</strong>ï¼šåˆ©ç”¨è®­ç»ƒå¥½çš„é‡å»ºæ¨¡ç½‘ç»œï¼Œæ›´æ–°templateï¼ˆä»çƒä½“å¼€å§‹ï¼‰å’Œæ ‡å‡†è¯­ä¹‰UV mapã€‚</p><ol type="1"><li><p>templateä¸€å¼€å§‹æ˜¯çƒä½“ï¼Œç„¶åæ¯è®­ç»ƒKè½®ï¼Œå¯¹å®ƒè¿›è¡Œä¸€æ¬¡æ›´æ–°ï¼š <span class="math display">\[\bar V_t=\bar V_{t-1} + D_{shape}(\frac{1}{|\mathcal{Q}|}\sum_{i\in \mathcal{Q}}E(I^i))\]</span> <span class="math inline">\(V_{t}\)</span>å’Œ <span class="math inline">\(V_{t-1}\)</span>æ˜¯æ›´æ–°å‰åçš„templateï¼ŒIæ˜¯è¾“å…¥çš„å›¾ç‰‡ï¼Œç»è¿‡Eç”Ÿæˆ3Då±æ€§ï¼ŒDæ˜¯å½¢çŠ¶ encoderã€‚Qæ˜¯ç»è¿‡æŸç§æ–¹å¼é€‰æ‹©å‡ºæ¥çš„éƒ¨åˆ†æ ·æœ¬ã€‚</p><p><strong>é€‰æ‹©æ ·æœ¬çš„æ–¹å¼</strong>ï¼š</p><ol type="1"><li>é¦–å…ˆé€‰æ‹©æœ€å¥½çš„é‚£ä¸€ä¸ªæ ·æœ¬ï¼Œå³ä¸ground truthè½®å»“çš„IoUæœ€å°çš„</li><li>ç„¶åé€‰æ‹©Kä¸ªè·Ÿè¿™ä¸ªæœ€å¥½çš„æ ·æœ¬æœ€æ¥è¿‘çš„æ ·æœ¬ï¼Œå³è¿™äº›æ ·æœ¬çš„gtè½®å»“ä¸æœ€å¥½çš„æ ·æœ¬çš„gtè½®å»“çš„IoUè¶Šå°åˆ™è¶Šæ¥è¿‘</li></ol></li><li><p>è¿™æ ·çš„è¯ï¼Œtemplate <span class="math inline">\(V_t\)</span> å°±æ˜¯é€‰å‡ºæ¥çš„æ ·æœ¬çš„å¹³å‡å½¢çŠ¶</p></li></ol></li><li><p>æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¼šåŒ…æ‹¬ä¸¤è½®ï¼Œæ¯è½®éƒ½åŒ…æ‹¬ä¸€ä¸ªEå’Œä¸€ä¸ªMã€‚ï¼ˆä¸¤è½®åˆ†åˆ«å°±æ˜¯ä»£ç ä¸­çš„<code>train_s1</code> <code>train_s2</code>ã€‚ï¼‰åœ¨Eä¸­ï¼Œè®­ç»ƒ200 epoch é‡å»ºæ¨¡ç½‘ç»œï¼Œç„¶ååœ¨Mä¸­ç”¨è®­ç»ƒå¥½çš„ç½‘ç»œæ›´æ–°templateå’Œæ ‡å‡†è¯­ä¹‰UV mapã€‚æ³¨æ„åœ¨ç¬¬ä¸€è½®ä¸­ï¼ˆä¸€è½®åŒ…æ‹¬ä¸€ä¸ªEå’ŒMï¼‰ï¼Œåªè®­ç»ƒé‡å»ºæ¨¡ç½‘ç»œï¼Œè€Œæ²¡æœ‰è¯­ä¹‰ä¸€è‡´æ€§çº¦æŸã€‚</p></li></ol></li></ol><h3 id="å®éªŒ">å®éªŒ</h3><ol type="1"><li>æ•°æ®é›†ï¼šPASCAL3D+ä¸­çš„è½¦å’Œæ‘©æ‰˜è½¦ã€CUB-200-2011ä¸­çš„é¸Ÿã€ImageNetä¸­çš„é©¬ æ–‘é©¬ ç‰›ã€OpenImagesä¸­çš„ä¼é¹…</li><li>å±€é™æ€§ï¼š<ol type="1"><li>ä¾èµ–äºSCOPSæä¾›è¯­ä¹‰åˆ†å‰²ï¼Œæœ‰æ—¶å€™è¯­ä¹‰åˆ†å‰²ä¸å‡†ç¡®çš„è¯ç»“æœå°±ä¸å¥½</li><li>æ¯”è¾ƒå°‘è§çš„ç›¸æœºposeå¾ˆéš¾</li><li>ç»†èŠ‚æ€§çš„åœ°æ–¹æ•ˆæœä¸å¥½ï¼Œæ¯”å¦‚æ­£åœ¨é£çš„é¸Ÿçš„ä¸¤ä¸ªç¿…è†€ã€æ–‘é©¬çš„è…¿ç­‰</li></ol></li></ol><h1 id="questions">Questions</h1><ol type="1"><li><p>ä¸ºä»€ä¹ˆè¦stage2 ï¼Ÿ</p><ol type="1"><li>è¿™ä¸¤ä¸ª stageçš„ä¸»è¦åŒºåˆ«å°±æ˜¯ï¼šstage1çš„æ—¶å€™æ²¡æœ‰ç”¨è¯­ä¹‰ä¸€è‡´æ€§çº¦æŸï¼Œåœ¨stage2æ‰åŠ ä¸Šã€‚å› ä¸ºä¸€å¼€å§‹texture flow encoderæ•ˆæœå¹¶ä¸å¥½ï¼Œavg_uvä¹Ÿä¸å‡†ç¡®ï¼Œæ‰€ä»¥å¹²è„†å…ˆä¸ç”¨ã€‚æ‰€ä»¥åˆ†æˆs1å’Œs2ï¼Œæœ€ä¸»è¦çš„å°±æ˜¯å› ä¸ºåœ¨s1è®­ç»ƒå®Œä¹‹åï¼Œé‡å»ºæ¨¡ç½‘ç»œå·²ç»å¤§ä½“å¯ä»¥ç”¨äº†ï¼Œè¿™æ—¶å€™å°±å¯ä»¥è°ƒç”¨<code>avg_uv.py</code>æ¥ç”Ÿæˆæ ‡å‡†è¯­ä¹‰UV mapï¼Œä¾›s2çš„æ—¶å€™è¯­ä¹‰ä¸€è‡´æ€§ç”¨ã€‚</li><li>é™„å½•é‡Œè¯´ï¼Œä»æ•ˆæœä¸Šæ¥çœ‹ï¼Œ2ä¸ªstageæ¯”1ä¸ªæ•ˆæœè¦å¥½ï¼Œä¸”å·²ç»è¶³å¤Ÿå¥½äº†ï¼Œæœ‰è¿™å¼ å›¾å¯¹æ¯”äº†ä¸€ä¸‹ï¼š<img src="https://s2.loli.net/2022/01/27/Q26BbRypnrKj7AU.png" alt="image-20220127171646865" /></li></ol></li><li><p>avg_uv å°±æ˜¯å­¦ seg map -&gt; uv mapçš„ä¹ˆï¼Ÿ</p><ol type="1"><li>seg map -&gt; uv mapè¿™ä¸ªè¿‡ç¨‹æ˜¯é‡å»ºæ¨¡ç½‘ç»œä¸­texture flowè¿™ä¸ªéƒ¨åˆ†åšçš„äº‹æƒ…</li><li>avg_uvå°±æ˜¯è®ºæ–‡é‡Œè¯´çš„ æ ‡å‡†è¯­ä¹‰ uv mapï¼ˆCanonical semantic uv mapï¼‰ï¼š<ol type="1"><li>ç†è®ºä¸Šï¼ŒåŒä¸€ç±»ç‰©ä½“çš„meshæ¨¡å‹ï¼Œå°½ç®¡å„è‡ªéƒ½æœ‰ä¸åŒçš„å½¢çŠ¶ï¼Œä½†æ¯ä¸ªç‚¹çš„è¯­ä¹‰å«ä¹‰éƒ½æ˜¯ä¸€è‡´çš„</li><li>å› æ­¤ï¼Œå¯¹äºæŸä¸€ç±»ç‰©ä½“çš„å¤§é‡å›¾åƒæ•°æ®é›†ï¼ˆæ¯”å¦‚é¸Ÿï¼‰ï¼Œå¯ä»¥ç”Ÿæˆä¸€å¼ å¯¹åº”è¿™æ•´ä¸ªç±»åˆ«çš„avg_uv</li><li>åˆ©ç”¨è¿™ä¸ªavg_uvï¼Œç›¸å½“äºæ˜¯ç»™æ•´ä¸ªç±»åˆ«çš„templateæ‰“ä¸Šäº†è¯­ä¹‰æ ‡ç­¾ï¼Œåç»­è®¡ç®—è¯­ä¹‰ä¸€è‡´æ€§çº¦æŸçš„æ—¶å€™å¯ä»¥ç”¨ã€‚</li><li>è¿™ä¸ªavg_uvçš„è®¡ç®—è¿‡ç¨‹ï¼š<ol type="1"><li>é¦–å…ˆç”¨SCOPSï¼ˆå¦ä¸€ç¯‡å·¥ä½œï¼Œæ— ç›‘ç£çš„ï¼‰ç”Ÿæˆæ‰€æœ‰å›¾åƒçš„è¯­ä¹‰åˆ†å‰²ç»“æœseg mapï¼Œç„¶åç”¨é‡å»ºæ¨¡ç½‘ç»œå­¦åˆ°çš„texture flowæ˜ å°„æˆuv map</li><li>é€‰æ‹©æ•ˆæœæœ€å¥½çš„ä¸€éƒ¨åˆ†instancesï¼Œå¯¹å®ƒä»¬çš„uv mapå–å¹³å‡ï¼Œå¾—åˆ°avg_uv</li></ol></li></ol></li></ol></li><li><p>paper é‡Œé¢ æœ‰è¯´å›ºå®šcamera å­¦shapeï¼Ÿ é‚£ä»£ç é‡Œæœ‰fix cameraé¢„æµ‹ä¹ˆï¼Ÿ</p><p>æˆ‘å¥½åƒæ²¡æœ‰è¯»åˆ°paperé‡Œæœ‰å…·ä½“è¯´åˆ°å›ºå®šcameraå­¦shapeè€¶â€¦â€¦</p><p>è®ºæ–‡é‡Œæåˆ°è¦è§£å†³camera-shapeä¸€èµ·å­¦æ—¶çš„ambiguityçš„é—®é¢˜ï¼Œä½†ä¸æ˜¯å›ºå®šä¸€ä¸ªå­¦å¦ä¸€ä¸ªï¼Œè€Œæ˜¯åˆ©ç”¨avg_uvæ¥å®ç°è¯­ä¹‰ä¸€è‡´æ€§ï¼šè®© æ¯ä¸ªç‰©ä½“çš„2D seg uv map ä¸ avg_uv ä¿æŒä¸€è‡´æ€§ï¼Œä»è€Œè®©3Dæ¨¡å‹çš„æ¯ä¸ªè¯­ä¹‰éƒ¨ä»¶è·Ÿ2Då›¾åƒé‡Œç›¸åº”çš„ä½ç½®æœ‰å¯¹åº”å…³ç³»ã€‚</p><p><img src="https://s2.loli.net/2022/01/27/TzCkKA462gRbOFa.png" alt="image-20220124121618081" style="zoom:50%;" /></p><p>ä»è¿™å¼ å›¾é‡Œå¯ä»¥çœ‹åˆ°ï¼Œå¦‚æœæ²¡æœ‰è¯­ä¹‰ä¸€è‡´æ€§ï¼Œmeshæ¨¡å‹ä¸­åŸæœ¬å¯¹åº”å¤´çš„é¡¶ç‚¹è¢«å½“ä½œäº†ç¿…è†€å°–ï¼Œè¿™æ ·çš„cameraå°±æ˜¯é”™è¯¯çš„ï¼Œé”™è¯¯çš„cameraåˆé€ æˆäº†é”™è¯¯çš„shapeã€‚è€Œæœ‰äº†è¯­ä¹‰ä¸€è‡´æ€§ï¼Œå°±èƒ½åˆ©ç”¨è¯­ä¹‰è®©camera æ›´å‡†ç¡®ï¼Œè¿™æ ·å°±èƒ½è·Ÿç€æå‡shape</p></li><li><p>æŒ‰ç…§ä»–çš„è¯´æ³•ï¼Œ å…ˆæ˜¯feature avg ç„¶å decode å‡º average shapeã€‚é‚£ä¹ˆè¿™ä¸ªfeatureå°±è¦å­¦å¥½ä¸€ç‚¹ï¼Œå¦åˆ™å¹³å‡å®¹æ˜“æˆçƒå½¢ã€‚é‚£ä¹ˆè¿™ä¸ªfeature è¿˜æœ‰å…¶ä»–lossåœ¨ä¸Šé¢ä¹ˆï¼Ÿæ¯”å¦‚æˆ‘ä»¬smr ä¸Šè¿˜æœ‰ consistency loss ä½†æ˜¯åŠ åœ¨ delta_verticeä¸Šï¼Ÿä»–æœ‰åŠ åœ¨featureä¸Šä¹ˆï¼Ÿå¦åˆ™ä¸èƒ½ç¡®ä¿è¿™ä¸ª feature avg äº†ä»¥å è¿˜æœ‰æ„ä¹‰</p><p>æˆ‘å¯èƒ½æ²¡æœ‰æ‡‚è¿™ä¸ªé—®é¢˜è€¶â€¦â€¦å­¦é•¿è¯´çš„æ˜¯ä¸æ˜¯è®¡ç®—category level çš„ templateè¿™ä¸ªæ­¥éª¤å‘¢ï¼Ÿæˆ‘è§‰å¾—è¿™ä¸ªæ­¥éª¤é‡Œé¢ä¿è¯æ•ˆæœå¥½çš„æ–¹å¼æœ‰è¿™å‡ ç‚¹æ¯”è¾ƒå…³é”®ï¼š</p><ol type="1"><li>æ›´æ–°category level çš„ templateæ˜¯ä»Mæ­¥éª¤æ‰å¼€å§‹è¿›è¡Œçš„ï¼›åœ¨æ­¤ä¹‹å‰ï¼ŒEæ­¥éª¤ä¸­ä¼šåœ¨å›ºå®štemplateçš„å‰æä¸‹ï¼Œå•ç‹¬è®­ç»ƒé‡å»ºæ¨¡ç½‘ç»œ200è½®ï¼Œè¿™ä¸ªè¿‡ç¨‹ä¸­çš„lossè¿˜æ˜¯æŒºå¤šçš„ï¼Œé™¤äº†è¯­ä¹‰ä¸€è‡´æ€§æ²¡æœ‰ç”¨ä»¥å¤–ï¼Œå…¶ä»–çš„losséƒ½ç”¨äº†ï¼ŒåŒ…æ‹¬è®ºæ–‡é‡Œæå‡ºçš„texture cycle consistencyï¼Œè¿˜æœ‰é™„å½•é‡Œæåˆ°çš„graph Laplacian constraintã€edge constraintç­‰ç­‰</li><li>è®¡ç®—average templateçš„æ—¶å€™ï¼Œå¹¶ä¸æ˜¯ç”¨äº†æ‰€æœ‰æ•°æ®ï¼Œè€Œæ˜¯é€‰æ‹©äº†æœ€å¥½çš„ä¸€éƒ¨åˆ†instancesï¼š<ol type="1"><li>é¦–å…ˆé€‰æ‹©æœ€å¥½çš„é‚£ä¸€ä¸ªinstanceï¼Œå³ä¸ground truth maskçš„IoUæœ€å°çš„</li><li>ç„¶åé€‰æ‹©Kä¸ªè·Ÿè¿™ä¸ªæœ€å¥½çš„æ ·æœ¬æœ€æ¥è¿‘çš„æ ·æœ¬ï¼Œå³è¿™äº›æ ·æœ¬çš„gt maskä¸æœ€å¥½çš„æ ·æœ¬çš„gt maskçš„IoUè¶Šå°åˆ™è¶Šæ¥è¿‘</li></ol></li></ol></li><li><p>ä»£ç é‡Œé¢è¿˜æ”¾äº†ä¸€äº› externalçš„codeï¼Œæœ‰ç”¨åˆ°ä¹ˆï¼Ÿ</p><ol type="1"><li>ä¸€ä¸ªæ˜¯SoftRasï¼Œç”¨æ¥æŠŠé‡å»ºæ¨¡meshæ¨¡å‹æ¸²æŸ“æˆ2Då›¾åƒã€‚è®ºæ–‡é‡Œæåˆ°ç”¨å®ƒè€Œä¸æ˜¯CMRä¸­ç”¨çš„ Neural Mesh Rendererï¼Œæ˜¯å› ä¸ºå®ƒå¯ä»¥æä¾›æ¦‚ç‡mapï¼Œä¾›texture cycle consistencyä½¿ç”¨</li><li>å¦ä¸€ä¸ªæ˜¯Neural Mesh Rendererï¼Œå¤‡é€‰çš„renderer</li><li>å†å°±æ˜¯PerceptualSimilarityï¼Œç”¨æ¥è®¡ç®—äº†perceptual loss</li></ol></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;è®ºæ–‡åœ°å€ï¼šhttps://arxiv.org/abs/2003.06473&lt;/p&gt;
&lt;p&gt;ä½œè€…ï¼šXueting Li, Sifei Liu, Kihwan Kim, Shalini De Mello, Varun Jampani, Ming-Hsuan Yang, and Jan Kautz&lt;/p&gt;
&lt;p&gt;å‘è¡¨ï¼š ECCV 2020&lt;/p&gt;
&lt;p&gt;é“¾æ¥ï¼š https://github.com/NVlabs/UMR&lt;/p&gt;</summary>
    
    
    
    <category term="Computer Notes" scheme="https://jyzhu.top/categories/Computer-Notes/"/>
    
    
    <category term="Computer Vision" scheme="https://jyzhu.top/tags/Computer-Vision/"/>
    
    <category term="3D Reconstruction" scheme="https://jyzhu.top/tags/3D-Reconstruction/"/>
    
    <category term="Self-supervised" scheme="https://jyzhu.top/tags/Self-supervised/"/>
    
  </entry>
  
  <entry>
    <title>rebellious-person</title>
    <link href="https://jyzhu.top/rebellious-person/"/>
    <id>https://jyzhu.top/rebellious-person/</id>
    <published>2022-01-09T20:21:06.000Z</published>
    <updated>2022-01-09T20:21:35.424Z</updated>
    
    <content type="html"><![CDATA[<p>æœ‰çš„æ—¶å€™æˆ‘è§‰å¾—å›é€†å’Œå¬è¯å¹¶ä¸æ˜¯çŸ›ç›¾çš„ç‰¹è´¨ã€‚æœ‰ä¸€ç§æœ¬è´¨çš„å›é€†å…¶å®æ˜¯æƒ³æ¸…æ¥šäº†æƒ³è¦ä»€ä¹ˆï¼Œç„¶åé€‰æ‹©äº†å¬è¯è¿™ä¸€ä¸ªè¡ŒåŠ¨æ¨¡å¼ã€‚ä¸ºä»€ä¹ˆè¯´è¿™æ˜¯å›é€†å‘¢ï¼Œå› ä¸ºè¿™ä¸æ˜¯çœŸçš„å¬è¯ï¼Œæ˜¯æŸç§æœ€æç«¯çš„ä¸å¬è¯ã€‚æˆ‘å·²ç»è§è¿‡äº†å¾ˆå¤šçš„ä¹–ä¹–äººï¼Œè®¸å¤šä¸€çœ¼å°±èƒ½åˆ†è¾¨å‡ºæ¥ï¼Œæ˜¯çœŸä¹–ä¹–å¬è¯ï¼Œè¿˜æ˜¯å›é€†äººæ‰€ä¼ªè£…ã€‚è¿™ç§ä¼ªè£…å¬è¯çš„å›é€†äººå¤§æ¦‚è¿˜æœ‰å¦ä¸€ä¸ªç‰¹è´¨ï¼Œå°±æ˜¯æœ‰å¤šé¢æ€§ã€‚å¾ˆå¤šäººè¯¯æŠŠå…¶ç‰¹å¼‚çš„é‚£äº›é¢å½“ä½œçœŸå®é¢ç›®ï¼Œè§‰å¾—å¬è¯ä¸€é¢æ˜¯ä¼ªè£…ï¼›å…¶å®ä¸ç„¶ï¼Œå…¨éƒ½æ˜¯çœŸå®çš„æ ·è²Œï¼Œæ²¡æœ‰å¿…è¦åˆ†æ˜ã€‚å­¦ä¹ ä¸€ä¸ªäººè¦å­¦ä¼šå®¹å¿ä»–çš„å¤æ‚æ€§ã€‚</p><p>æˆ‘æœ‰æƒ³è¿‡ç”¨ä¸€äº›è‰²å½©æ›´å®¹æ˜“è¾¨æ˜çš„è¯æ¥ä»£æ›¿ã€Œå›é€†ã€ï¼šè‡ªä¸»ï¼Œè‡ªçŸ¥ï¼Œæ¸…é†’ï¼Œæˆç†Ÿï¼Œæ˜ç™½è‡ªå·±æƒ³è¦ä»€ä¹ˆâ€¦â€¦å¯æ˜¯è¿™éƒ½å·®äº†ç‚¹æ„æ€ã€‚è¿˜æ˜¯å›é€†å¥½ï¼Œå› ä¸ºè¿™æ¯•ç«Ÿæœ‰ä¸€ç§å­¤å‹‡æ„Ÿåœ¨é‡Œé¢ï¼›ä¹Ÿä¸è´´åˆ‡ï¼Œå¤§æ¦‚æ˜¯è™«å­è •åŠ¨çš„guyongæ„Ÿã€‚æƒ³è±¡è¿™æ ·ä¸€ä¸ªç”»é¢ï¼šåœ¨è‚ é“ä¸€æ ·çš„ä¸–ç•Œé‡Œï¼Œå¤§å®¶éƒ½ä¹–ä¹–é¡ºæ»‘ç€é€æ¸åŒ–ä¸ºæŸç§æ’æ³„ç‰©ï¼Œä½†æ˜¯å…¶ä¸­æœ‰ä¸€äº›guyongè€…ï¼Œå°±æ˜¯å›é€†äººã€‚</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;æœ‰çš„æ—¶å€™æˆ‘è§‰å¾—å›é€†å’Œå¬è¯å¹¶ä¸æ˜¯çŸ›ç›¾çš„ç‰¹è´¨ã€‚æœ‰ä¸€ç§æœ¬è´¨çš„å›é€†å…¶å®æ˜¯æƒ³æ¸…æ¥šäº†æƒ³è¦ä»€ä¹ˆï¼Œç„¶åé€‰æ‹©äº†å¬è¯è¿™ä¸€ä¸ªè¡ŒåŠ¨æ¨¡å¼ã€‚ä¸ºä»€ä¹ˆè¯´è¿™æ˜¯å›é€†å‘¢ï¼Œå› ä¸ºè¿™ä¸æ˜¯çœŸçš„å¬è¯ï¼Œæ˜¯æŸç§æœ€æç«¯çš„ä¸å¬è¯ã€‚æˆ‘å·²ç»è§è¿‡äº†å¾ˆå¤šçš„ä¹–ä¹–äººï¼Œè®¸å¤šä¸€çœ¼å°±èƒ½åˆ†è¾¨å‡ºæ¥ï¼Œæ˜¯çœŸä¹–ä¹–å¬è¯ï¼Œè¿˜æ˜¯å›é€†äººæ‰€ä¼ªè£…ã€‚è¿™ç§ä¼ªè£…å¬è¯çš„å›é€†äºº</summary>
      
    
    
    
    <category term="thoughts" scheme="https://jyzhu.top/categories/thoughts/"/>
    
    
  </entry>
  
  <entry>
    <title>obj format debugging -- vertices order determines face orientation and faces are invisible from back</title>
    <link href="https://jyzhu.top/obj-format-debugging-vertices-order/"/>
    <id>https://jyzhu.top/obj-format-debugging-vertices-order/</id>
    <published>2022-01-05T11:52:42.000Z</published>
    <updated>2022-01-05T12:10:49.164Z</updated>
    
    <content type="html"><![CDATA[<p>Okayyyyyyyy!!!</p><ol type="1"><li><p><strong>Vertices order determines face orientation</strong>.</p><p>e.g., <code>f 1 2 3</code> and <code>f 1 3 2</code> are 2 opposite faces</p></li><li><p>Another thing is, <strong>faces are invisible from backside by default!!!</strong></p><p>In <strong>Meshlab</strong> here is a setting <code>back-face</code> which by default is <code>single</code>. If set it as <code>double</code>, then the face will be visible from backside.<img src="https://s2.loli.net/2022/01/05/CjwX378IKQYpznb.png" /></p><p>Meanwhile, the <strong>Preview</strong> of MacOS also makes faces transparent from opposite orientation. Like this: <img src="https://s2.loli.net/2022/01/05/vVI5SZk1d8cCqx6.png" alt="Stupid sphere no?" style="zoom:50%;" /></p></li></ol><p>Finally my sphere is correct:</p><p><img src="https://s2.loli.net/2022/01/05/jyMqxdsRCiLDlSf.png" alt="correct sphere" style="zoom:50%;" /></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Okayyyyyyyy!!!&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Vertices order determines face orientation&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;e.g., &lt;code&gt;f 1 2 3&lt;/code&gt; and &lt;code&gt;f 1 3 2&lt;/code&gt; are 2 opposite faces&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Another thing is, &lt;strong&gt;faces are invisible from backside by default!!!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In &lt;strong&gt;Meshlab&lt;/strong&gt; here is a setting &lt;code&gt;back-face&lt;/code&gt; which by default is &lt;code&gt;single&lt;/code&gt;. If set it as &lt;code&gt;double&lt;/code&gt;, then the face will be visible from backside.&lt;img src=&quot;https://s2.loli.net/2022/01/05/CjwX378IKQYpznb.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;Meanwhile, the &lt;strong&gt;Preview&lt;/strong&gt; of MacOS also makes faces transparent from opposite orientation. Like this: &lt;img src=&quot;https://s2.loli.net/2022/01/05/vVI5SZk1d8cCqx6.png&quot; alt=&quot;Stupid sphere no?&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Finally my sphere is correct:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2022/01/05/jyMqxdsRCiLDlSf.png&quot; alt=&quot;correct sphere&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Computer Notes" scheme="https://jyzhu.top/categories/Computer-Notes/"/>
    
    
    <category term="Mesh" scheme="https://jyzhu.top/tags/Mesh/"/>
    
    <category term="3D" scheme="https://jyzhu.top/tags/3D/"/>
    
  </entry>
  
  <entry>
    <title>Last day of 2021</title>
    <link href="https://jyzhu.top/Last-day-of-2021/"/>
    <id>https://jyzhu.top/Last-day-of-2021/</id>
    <published>2021-12-31T09:17:59.000Z</published>
    <updated>2021-12-31T09:20:00.070Z</updated>
    
    <content type="html"><![CDATA[<p>æ²¡æœ‰å¤ªå¤šè¦è¯´çš„ã€‚è¿™é¦–è¯æ­£å¥½è¡¨è¾¾äº†ä¸€åˆ‡æˆ‘æƒ³è¡¨è¾¾çš„ï¼š</p><blockquote><p>ä¸€å‘å¹´å…‰æœ‰é™èº«ï¼Œç­‰é—²ç¦»åˆ«æ˜“é”€é­‚ï¼Œé…’ç­µæ­Œå¸­è«è¾é¢‘ã€‚</p><p>æ»¡ç›®å±±æ²³ç©ºå¿µè¿œï¼Œè½èŠ±é£é›¨æ›´ä¼¤æ˜¥ï¼Œä¸å¦‚æ€œå–çœ¼å‰äººã€‚</p><p>â€”â€”æ™æ®Šã€Šæµ£æºªæ²™ã€‹</p></blockquote><p>å…±å‹‰ã€‚</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;æ²¡æœ‰å¤ªå¤šè¦è¯´çš„ã€‚è¿™é¦–è¯æ­£å¥½è¡¨è¾¾äº†ä¸€åˆ‡æˆ‘æƒ³è¡¨è¾¾çš„ï¼š&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ä¸€å‘å¹´å…‰æœ‰é™èº«ï¼Œç­‰é—²ç¦»åˆ«æ˜“é”€é­‚ï¼Œé…’ç­µæ­Œå¸­è«è¾é¢‘ã€‚&lt;/p&gt;
&lt;p&gt;æ»¡ç›®å±±æ²³ç©ºå¿µè¿œï¼Œè½èŠ±é£é›¨æ›´ä¼¤æ˜¥ï¼Œä¸å¦‚æ€œå–çœ¼å‰äººã€‚&lt;/p&gt;
&lt;p&gt;â€”â€”æ™æ®Šã€Šæµ£æºªæ²™ã€‹&lt;/p&gt;
&lt;/blockquote&gt;
</summary>
      
    
    
    
    <category term="thoughts" scheme="https://jyzhu.top/categories/thoughts/"/>
    
    
    <category term="Literature" scheme="https://jyzhu.top/tags/Literature/"/>
    
  </entry>
  
  <entry>
    <title>å…äºæœªæ¥</title>
    <link href="https://jyzhu.top/release-future/"/>
    <id>https://jyzhu.top/release-future/</id>
    <published>2021-12-22T17:04:57.000Z</published>
    <updated>2021-12-22T17:09:10.767Z</updated>
    
    <content type="html"><![CDATA[<p>æ˜å¤©ï¼Œå¤ªé˜³ç…§å¸¸å‡èµ·<br />ä¸–ä¸Šæ‰€æœ‰çš„é¢œè‰²å°†é€æ¸æ©åŸ‹æˆ‘çœ¼ä¸­çš„æ‚²ä¼¤<br />æ¶ˆå¤±çš„å›½åº¦ æ¶ˆå¤±çš„äºº<br />æˆ‘æ€ä¹ˆç›¸ä¿¡å•Š<br />äººæ€ä¹ˆå¯èƒ½ä¼šæ¶ˆå¤±å‘¢<br />åŒ–ä½œä¸€æŠ”é»„åœŸ<br />å»åˆ°å¦ä¸€ä¸ªä¸–ç•Œ<br />æ²¡æœ‰äººä¼¤å¿ƒçš„æ—¶å€™ä¼šä¸ä¿¡å½¼å²¸å§ï¼Ÿ<br />ä½•æ—¶ä¹Ÿéƒ½èƒ½è·³èˆ<br />åªæ˜¯èˆåœ¨æœ‰äº›äº‹é¢å‰éƒ½å…¨æ— æ„ä¹‰<br />é™¤äº†ç”Ÿæ­»<br />å“ªä¸€æ¡©ä¸æ˜¯é—²äº‹<br />æ¯ä¸ªäººä¸€ç”Ÿä¸­éƒ½æ²‰æººåœ¨æ— å…³ç´§è¦çš„çäº‹ä¸­<br />ä»¥å…è¢«ç”Ÿå‘½çš„æ‚²ä¼¤ä¾µæ‰°<br />ä»¥å…³é—­æ„Ÿå®˜<br />ç„¶è€Œé…’æµ‡è¿›å¤§æµ·çš„æ„é‡Œ<br />å°±å¥½åƒæŠŠæˆ‘æ©åŸ‹åœ¨è¿™ä¸ªä¸–ç•Œä¸­<br />æˆ–è€…ç”¨è¿™ä¸ªä¸–ç•Œçš„é¢œè‰²æ©åŸ‹æˆ‘<br />æˆ–è€…ç”¨çç¢æ©åŸ‹æ‰€æœ‰ç”Ÿè€…<br />å¯æ˜¯æ©åŸ‹ä¸€åˆ‡å§<br />ä¸è¦æ©åŸ‹æˆ‘çš„äº²äºº<br />é‡è¦çš„äº²äººå•Š<br />å¤šå¸Œæœ›ä¸–ç•Œå› ä½ ä»æ­¤åœæ‘†<br />å°±åœä¸‹æ¥å§<br />è®©æˆ‘å…äºæœªæ¥<br />ä¸ºä»€ä¹ˆæ˜å¤©<br />å¤ªé˜³è¿˜è¦ç…§å¸¸å‡èµ·å•Š</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;æ˜å¤©ï¼Œå¤ªé˜³ç…§å¸¸å‡èµ·&lt;br /&gt;
ä¸–ä¸Šæ‰€æœ‰çš„é¢œè‰²å°†é€æ¸æ©åŸ‹æˆ‘çœ¼ä¸­çš„æ‚²ä¼¤&lt;br /&gt;
æ¶ˆå¤±çš„å›½åº¦ æ¶ˆå¤±çš„äºº&lt;br /&gt;
æˆ‘æ€ä¹ˆç›¸ä¿¡å•Š&lt;br /&gt;
äººæ€ä¹ˆå¯èƒ½ä¼šæ¶ˆå¤±å‘¢&lt;br /&gt;
åŒ–ä½œä¸€æŠ”é»„åœŸ&lt;br /&gt;
å»åˆ°å¦ä¸€ä¸ªä¸–ç•Œ&lt;br /&gt;
æ²¡æœ‰äººä¼¤å¿ƒçš„æ—¶å€™ä¼šä¸ä¿¡å½¼å²¸å§ï¼Ÿ&lt;br /&gt;
ä½•</summary>
      
    
    
    
    <category term="poems" scheme="https://jyzhu.top/categories/poems/"/>
    
    
    <category term="grandpa" scheme="https://jyzhu.top/tags/grandpa/"/>
    
  </entry>
  
  <entry>
    <title>My Grandfather</title>
    <link href="https://jyzhu.top/My-Grandfather/"/>
    <id>https://jyzhu.top/My-Grandfather/</id>
    <published>2021-12-22T16:57:42.000Z</published>
    <updated>2021-12-22T17:30:30.803Z</updated>
    
    <content type="html"><![CDATA[<p>æˆ‘çš„å¤–å…¬å»ä¸–äº†ï¼Œè½¬çœ¼å°±å¿«åŠä¸ªæœˆäº†ã€‚è¿™ä»¶äº‹æƒ…åœ¨æˆ‘å¿ƒä¸­ï¼Œä»ä¸æ•¢ç›¸ä¿¡çš„è¯´æ³•ï¼Œå˜æˆäº†æ¨¡ç³Šçš„ã€ä¸çœŸå®çš„è¯´æ³•ã€‚æˆ‘å®é™…ä¸Šæ—¶æ—¶æèµ·ï¼Œå®ƒåœ¨ä»»ä½•æ—¶å€™éƒ½è¦ç»•åœ¨æˆ‘è„‘ä¸­ï¼Œä»¥è‡³äºéƒ½å¾ˆéš¾ç›¸ä¿¡å·²ç»è¿‡å»åŠä¸ªæœˆäº†ï¼›å¯æ˜¯å…¶å®åˆå¾ˆéš¾æèµ·ï¼Œæèµ·æ€»æ˜¾å¾—è½»é£˜é£˜çš„ï¼Œè¿™æ˜¯å‹åœ¨æˆ‘å¿ƒä¸­æœ€æ²‰é‡çš„ä¸€ä»¶äº‹ã€‚</p><span id="more"></span><p>æˆ‘å½“ç„¶å¾ˆçˆ±æˆ‘çš„å¤–å…¬ï¼Œä»–æ˜¯ä¸€ä½æ­£ç›´ã€å–„è‰¯ã€åšå¼ºçš„äººã€‚æˆ‘çš„è„‘ä¸­ç§¯æ”’äº†å¾ˆå¤šå¾ˆå¤šå…³äºä»–çš„äº‹è¿¹ï¼Œéƒ½æ˜¯ä»å¤–å©†ã€å¦ˆå¦ˆå£ä¸­å¬æ¥çš„ã€‚</p><p>å¤–å…¬è‡ªå·±å…¶å®è·Ÿæˆ‘äº¤æµå¾—å¾ˆå°‘ï¼Œæ—¶è‡³ä»Šæ—¥å°è±¡æœ€æ·±åˆ»çš„ï¼Œç«Ÿç„¶æ˜¯å°å­¦çš„æ—¶å€™å¤–å…¬ç»™æˆ‘ç…®é¢åƒï¼Œå¾ˆä¸¥å‰åœ°æ‰¹è¯„æˆ‘ï¼šé¢æ±¤ä¹Ÿå¿…é¡»å–å®Œï¼Œä¸èƒ½æµªè´¹ï¼å°æ—¶å€™çš„æˆ‘æŒ‘é£Ÿã€é£Ÿé‡å°ï¼Œè¿™ä¸ªè®­è¯«è®©æˆ‘å¾ˆç•æƒ§ã€‚å¯æ˜¯æˆ‘ä»æ¥æ²¡æƒ³è¿‡é¢æ±¤ä¹Ÿæ˜¯éœ€è¦çæƒœçš„äº‹ç‰©ï¼Œå› æ­¤è¢«å¤–å…¬ç‚¹é†’ï¼Œä¹Ÿé¢‡æ„Ÿæƒ­æ„§ã€‚ä»¥è‡³äºè®°åˆ°ä»Šæ—¥ï¼Œå¹¶ä¸”å°†åˆ»è¿›éª¨å­é‡Œã€‚</p><p>æˆ‘é«˜ä¸­çš„æ—¶å€™å…¶å®ä»¥ååˆ†é¥±æ»¡çš„æ„Ÿæƒ…ï¼Œåœ¨ä¸€ç¯‡å‘¨è®°ä¸­è®¤çœŸåœ°å†™è¿‡å¤–å…¬çš„äº‹è¿¹ä¸å½¢è±¡ã€‚å¦ˆå¦ˆè§‰å¾—å¾ˆæ„ŸåŠ¨ã€‚æˆ‘ç›®å‰å€’æ˜¯ä¸æ•¢ç¿»å‡ºæ¥çœ‹ã€‚å¤šå°‘å¹´åæ‰ä¼šæ— æ„ä¸­çœ‹åˆ°ï¼Œç„¶åå“­æ‰å‘¢ï¼Ÿæˆ‘ä¸æ•¢æƒ³ã€‚</p><p>æˆ‘çš„å¤–å…¬å•Šï¼Œä»–çš„äººç”Ÿè¿‡å¾—åº”è¯¥å¾ˆä¸å®¹æ˜“çš„ã€‚ä»å°å¤±å»åŒäº²ï¼Œäººç”Ÿä¸­æœ‰è¿‡ä¸€æ®µç©·å›°æ½¦å€’çš„æ—¥å­ï¼Œæ‰å…»æˆæåº¦èŠ‚çº¦çš„ä¹ æƒ¯ã€‚ä»–å›ºæ‰§åˆ°åæ‰§çš„ç¨‹åº¦ï¼Œæ‰æˆä¸ºè¿™æ ·ä¸€ä½å¨ä¸¥çš„é•¿è¾ˆï¼Œå¯æ˜¯ä¹Ÿæ­£å› ä¸ºè¿™æ€§æ ¼ï¼Œå¹´è½»æ—¶å·¥ä½œä¸­å—åˆ°è¿‡å¾ˆå¤§çš„æŒ«æŠ˜ã€‚ä»–çš„å¤´è„‘ä¸æ‰èƒ½ä¸€å®šæ˜¯å€¼å¾—å°Šæ•¬çš„ï¼Œç´æ£‹ä¹¦ç”»éƒ½ä¼šä¸€äº›ä¸è¯´ï¼Œè¿˜ä¼šä¿®å„ç§ç”µè·¯ï¼Œæ‹¥æœ‰ä¸€ä¸ªé¢‡ä¸ºç¥ç§˜ã€åŒ…ç½—ä¸‡è±¡çš„å·¥å…·æŸœã€‚</p><p>å¤–å…¬è¿·ä¿¡ç®—å‘½ï¼Œæˆ‘çš„åå­—å°±æ˜¯ä»–èµ·çš„ï¼Œç»è¿‡å¾ˆä»”ç»†çš„æ¨ç®—ã€‚å¼Ÿå¼Ÿå‡ºç”Ÿçš„æ—¶å€™ï¼Œå¤–å…¬è™½ç„¶ä»åœ¨ä¸–ï¼Œä½†å·²ç»ç—…é‡ï¼Œé—æ†¾æ²¡èƒ½ç»™ä»–èµ·åäº†ã€‚å¦ˆå¦ˆè¯´ï¼Œä¸€å®šæ˜¯å¤–å…¬ç®—äº†å¤ªå¤šå‘½ï¼Œè§¦çŠ¯äº†ä»€ä¹ˆè§„åˆ™è€Œå—åˆ°æƒ©ç½šï¼Œæ‰€ä»¥æ™šå¹´è‡ªå·±å‘½è‹¦ï¼Œäº‘äº‘ã€‚æœ€åçœŸçš„å¥½è‹¦å•Šï¼Œé‚£æ ·ä¸€ä½æ€ç»´æ•æ·çš„æ™ºè€…ï¼Œç»ˆæ—¥å£ä¸èƒ½è¿°ã€æ‰‹ä¸èƒ½ä¹¦ï¼Œå¿å—ç€èº«ä½“å„å¤„çš„ç–¼ç—›ï¼Œä¸€å¤©å¤©å› ä¸ºè¥å…»ä¸è‰¯è€Œæ¶ˆç˜¦ä¸‹å»ï¼Œç”Ÿå‘½çš„æ´»åŠ›ä¸å¯é€†åœ°æš—æ·¡ä¸‹å»ã€‚</p><p>è¿™äº›ç”Ÿå‘½ä¸å¯é€†çš„è¿åŠ¨ä¸€åº¦è®©æˆ‘é™·å…¥æœ€æ·±çš„ææƒ§ã€‚æˆ‘èƒ½æƒ³è±¡ï¼Œä½†æˆ‘èƒ½æƒ³è±¡å‡ ä½•å‘¢ã€‚æœ€åä¸€æ¬¡è§åˆ°å¤–å…¬å·²æ˜¯åŠå¹´å‰äº†ï¼Œåæ¥çš„å¤–å…¬æ˜¯ä»€ä¹ˆæ ·å­å‘¢ã€‚ä»–åœ¨æˆ‘å¿ƒä¸­çš„å½¢è±¡ï¼Œä¸€åˆ‡çš„äº‹è¿¹ï¼Œç›¸å…³çš„å›å¿†ï¼Œéƒ½å·²ç»åœ¨æ—¶é—´ä¸­å®šæ ¼äº†ã€‚</p><p>è¿™æ˜¯æˆ‘æœ€ä¼¤æ„Ÿçš„äº‹æƒ…ã€‚</p><p>ä¸€ä¸ªäººè¿˜æ´»ç€ï¼Œé‚£æ„å‘³ç€éšç€æ—¶é—´ï¼Œä»–ä¹Ÿæ˜¯åœ¨æµåŠ¨çš„ã€‚å¯æ˜¯ä¸€ä¸ªäººæ­»å»ï¼Œä»–å°±å‡å›ºäº†ï¼Œè¿™æ˜¯æˆ‘è¿˜ä¸èƒ½æ¥å—çš„äº‹æƒ…ã€‚è·Ÿæ°¸æ’ç›¸æ¯”ï¼Œäººçš„ä¸€ç”ŸçŸ­æš‚å¾—è¦å‘½ã€‚è·Ÿæµ©ç€šç›¸æ¯”ï¼Œäººçš„å‘½è½»å¾—ä¸å€¼ä¸€æã€‚ä½†åœ¨æˆ‘å¿ƒä¸­ï¼Œé‡è¦çš„äººï¼Œå…¶é‡é‡å°±æ˜¯æ— æ³•è¡¡é‡çš„ï¼Œå…¶ç¦»å»å°±æ˜¯åˆ‡åˆ‡å®å®åœ°ï¼Œå°†æˆ‘çš„ç”Ÿå‘½ä¹Ÿéšä¹‹å‰²å»äº†ä¸€éƒ¨åˆ†ã€‚ç„¶è€Œï¼Œå…³äºæˆ‘çš„ç”Ÿå‘½è¢«å‰²èµ°è¿™ä»¶äº‹ï¼Œæˆ‘æ„Ÿåˆ°æ„Ÿæ¿€ï¼Œä¹Ÿæ„Ÿåˆ°è¸å®ã€‚</p><p>æˆ‘çš„æ„Ÿæƒ³åœ¨äººä¹‹é€ä¸–è¿™ä»¶äº‹é¢å‰ï¼Œå¤šå°‘å¾®ä¸è¶³é“ã€‚ä½†æˆ‘ä»ç„¶ä¼šä¸€ééåœ°å›å¿†è¿™ä»¶äº‹ï¼Œæˆ‘ä¼šå†ä¸€ééåœ°æèµ·è¿™ä»¶äº‹ã€‚è¿™æ˜¯æˆ‘å¯¹å¤–å…¬æ€å¿µçš„æ–¹å¼ã€‚</p><blockquote><p>æˆ‘çŸ¥é“è¿™ä¸–ç•Œæœ¬å¦‚éœ²æ°´èˆ¬çŸ­æš‚ã€‚ç„¶è€Œç„¶è€Œã€‚</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;æˆ‘çš„å¤–å…¬å»ä¸–äº†ï¼Œè½¬çœ¼å°±å¿«åŠä¸ªæœˆäº†ã€‚è¿™ä»¶äº‹æƒ…åœ¨æˆ‘å¿ƒä¸­ï¼Œä»ä¸æ•¢ç›¸ä¿¡çš„è¯´æ³•ï¼Œå˜æˆäº†æ¨¡ç³Šçš„ã€ä¸çœŸå®çš„è¯´æ³•ã€‚æˆ‘å®é™…ä¸Šæ—¶æ—¶æèµ·ï¼Œå®ƒåœ¨ä»»ä½•æ—¶å€™éƒ½è¦ç»•åœ¨æˆ‘è„‘ä¸­ï¼Œä»¥è‡³äºéƒ½å¾ˆéš¾ç›¸ä¿¡å·²ç»è¿‡å»åŠä¸ªæœˆäº†ï¼›å¯æ˜¯å…¶å®åˆå¾ˆéš¾æèµ·ï¼Œæèµ·æ€»æ˜¾å¾—è½»é£˜é£˜çš„ï¼Œè¿™æ˜¯å‹åœ¨æˆ‘å¿ƒä¸­æœ€æ²‰é‡çš„ä¸€ä»¶äº‹ã€‚&lt;/p&gt;</summary>
    
    
    
    <category term="thoughts" scheme="https://jyzhu.top/categories/thoughts/"/>
    
    
    <category term="grandpa" scheme="https://jyzhu.top/tags/grandpa/"/>
    
  </entry>
  
  <entry>
    <title>è¯» DeepHuman: 3D Human Reconstruction from a Single Image</title>
    <link href="https://jyzhu.top/DeepHuman-3D-Human-Reconstruction-from-a-Single-Image/"/>
    <id>https://jyzhu.top/DeepHuman-3D-Human-Reconstruction-from-a-Single-Image/</id>
    <published>2021-12-15T06:46:11.000Z</published>
    <updated>2022-02-05T09:45:06.464Z</updated>
    
    <content type="html"><![CDATA[<p>è®ºæ–‡åœ°å€ï¼š<a href="https://openaccess.thecvf.com/content_ICCV_2019/html/Zheng_DeepHuman_3D_Human_Reconstruction_From_a_Single_Image_ICCV_2019_paper.html" class="uri">https://openaccess.thecvf.com/content_ICCV_2019/html/Zheng_DeepHuman_3D_Human_Reconstruction_From_a_Single_Image_ICCV_2019_paper.html</a></p><p>ä½œè€…ï¼šZerong Zheng, Tao Yu, Yixuan Wei, Qionghai Dai, Yebin Liu</p><p>å‘è¡¨ï¼š ICCV2019</p><p>Codeï¼š <a href="https://github.com/ZhengZerong/DeepHuman" class="uri">https://github.com/ZhengZerong/DeepHuman</a></p><hr /><blockquote><p>å¦‚æœä½ å»åšè¿™ä¸ªä»»åŠ¡ï¼Œä¼šæ€ä¹ˆåšï¼Ÿä½œè€…åšçš„æ–¹æ³•å’Œä½ æƒ³çš„æœ‰ä»€ä¹ˆå·®å¼‚ï¼Ÿ</p></blockquote><h2 id="why">Whyï¼š</h2><ol type="1"><li>ç°åœ¨çš„äººä½“é‡å»ºæ¨¡å·¥ä½œå¤§å¤šéœ€è¦å¤šè§†è§’å›¾åƒæˆ–è€…å¤štemporalå›¾åƒï¼Œä»å•å¼ å›¾åƒé‡å»ºäººä½“ä»ç„¶æ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„å·¥ä½œã€‚</li><li>å•å¼ å›¾åƒé‡å»ºæ¨¡çš„å·¥ä½œï¼Œå°±ç®—æ˜¯åˆ©ç”¨äººä½“templateï¼ˆSMPLï¼‰çš„ï¼Œæœ€å¥½çš„æ•ˆæœä¹Ÿåªæ˜¯é‡ç°å½¢çŠ¶å’Œå§¿åŠ¿ï¼Œä½†æ˜¯åœ¨æœè£…å±‚é¢ä¸Šçš„å‘ˆç°æ•ˆæœå¾ˆå·®ã€‚BodyNetå·²ç»å°è¯•äº†ï¼Œä½†æ˜¯æ•ˆæœä¹Ÿå¾ˆå·®ã€‚</li><li>ç°åœ¨çš„å…¬å¼€æ•°æ®é›†éƒ½æ²¡æœ‰å¤§åˆ†è¾¨ç‡çš„ã€åŒ…å«æ™®é€šæœé¥°çš„è¡¨é¢ç‰¹å¾çš„3Däººä½“æ•°æ®é›†ã€‚æ‰€ä»¥åªå¥½è‡ªå·±æäº†ä¸€ä¸ªã€‚</li></ol><h2 id="what">Whatï¼š</h2><ol type="1"><li>æå‡ºäº†DeepHumanï¼Œä½“åˆ°ä½“ï¼ˆvolume to volumeï¼‰çš„3Däººä½“é‡å»ºæ¨¡</li><li>å°†ä»SMPLæ¨¡å‹ç”Ÿæˆçš„ ç¨ å¯†è¯­ä¹‰è¡¨ç¤º ä½œä¸ºé¢å¤–çš„è¾“å…¥ï¼Œæ¥è®©é‡å»ºçš„ç‰©ä½“è¡¨é¢æ›´æ¸…æ™°ï¼Œç”šè‡³è¿˜èƒ½é‡å»ºä¸å¯è§çš„éƒ¨åˆ†</li><li>é€šè¿‡ä½“ç§¯ç‰¹å¾å˜æ¢ï¼ˆvolumetric feature transformationï¼‰ï¼ŒæŠŠä¸åŒå°ºåº¦çš„å›¾åƒç‰¹å¾èåˆèµ·æ¥ï¼Œå¾—ä»¥æ¢å¤ç²¾ç¡®çš„è¡¨é¢ï¼›ç„¶åé€šè¿‡æ­£åˆ™æç‚¼ç½‘ç»œï¼ˆnormal refinement network)è¿›ä¸€æ­¥ç»†åŒ–è¡¨é¢</li><li>é¡ºä¾¿æå‡ºäº†THumanæ•°æ®é›†</li></ol><p>è¯»å‰ç–‘é—®ï¼š</p><ol type="1"><li>SMPLæ¨¡å‹æ˜¯å“ªæ¥çš„ï¼Ÿéœ‡æƒŠï¼Œæ˜¯éœ€è¦åˆ©ç”¨HMRä¹‹ç±»çš„æ–¹æ³•å…ˆç”Ÿæˆä¸€ä¸ªSMPLäººä½“æ¨¡å‹ï¼Œç„¶åå†å’Œå›¾åƒä¸€èµ·ä½œä¸ºè¾“å…¥ï¼Œæ‰€ä»¥è¿™ç¯‡è®ºæ–‡æ˜¯è·Ÿå‰åŠéƒ¨åˆ†å·¥ä½œâ€”â€”ç”ŸæˆSMPLæ¨¡å‹â€”â€”ä¸€ç‚¹å…³ç³»æ²¡æœ‰çš„ğŸ¤”</li><li>ä¸æ˜¯è‡ªç›‘ç£å§ï¼Ÿä¸æ˜¯çš„ï¼Œæ˜¯æœ‰3D mesh ground truthçš„</li><li>çœ‹èµ·æ¥æ•ˆæœå¾ˆå¥½ï¼Œæ¨¡å‹ä¸­åº”è¯¥åˆ©ç”¨äº†ä¸€äº›bottom-upçš„äººä½“ç»“æ„å…ˆéªŒçŸ¥è¯†å§ï¼Ÿæˆ‘çŒœæ˜¯ä¸æ˜¯å…ˆç”¨çš„SMPLæ„å»ºäººä½“ï¼Œç„¶åå†é¢å¤–å¢åŠ ä¸€éƒ¨åˆ†ç½‘ç»œç»“æ„ï¼ŒæŠŠäººä½“è¡¨é¢é‡å»ºå¾—æ›´å¥½å‘¢ï¼Ÿæ²¡é”™ã€‚</li><li>normal refinement networkæ˜¯å•¥å‘¢ï¼Ÿnormalæ˜¯æ³•çº¿å•¦ï¼Œæˆ‘ç†è§£è¿™ä¸ªå…¶å®å°±æ˜¯ä¸€ä¸ªç®€å•çš„UNetç½‘ç»œï¼ŒæŠŠæ³•çº¿è´´å›¾upsampleæˆä¸¤å€å¤§å°</li><li>ä¸åŒscaleçš„å›¾åƒç‰¹å¾æ˜¯æ€ä¹ˆåˆ©ç”¨çš„ï¼Ÿè¿™é‡Œæå‡ºäº†ä¸€ä¸ªVFTæ¥æŠŠå›¾åƒç‰¹å¾èåˆè¿›volumeç‰¹å¾é‡Œã€‚å›¾åƒç‰¹å¾æ€ä¹ˆæ¥çš„ï¼Œç®€å•çš„conv+reluã€‚volumeç‰¹å¾æ€ä¹ˆæ¥çš„ï¼Œä¸€ä¸ªç«‹ä½“æ”¹è‰¯ç‰ˆUNetã€‚æ‰€ä»¥å…·ä½“åšæ³•å°±æ˜¯ï¼Œåœ¨UNetçš„downsampleè¿‡ç¨‹ä¸­çš„æ¯ä¸€å±‚ï¼Œéƒ½è¿›è¡Œä¸€æ¬¡VFTï¼ŒæŠŠå›¾åƒç‰¹å¾èåˆè¿›volumeç‰¹å¾é‡Œé¢ã€‚</li><li>THumanæ•°æ®é›†å¥½ç”¨å—ï¼Ÿæˆ‘çœ‹è¿™ç¯‡è®ºæ–‡æœ‰ä¸€ç™¾å¤šçš„å¼•ç”¨ï¼Œæ˜¯å› ä¸ºå¤§å®¶éƒ½ç”¨ä¸Šäº†è¿™ä¸ªæ•°æ®é›†å—ï¼Ÿä¸çŸ¥é“è¯¶â€¦â€¦</li></ol><h2 id="how">Howï¼š</h2><ol type="1"><li>æœè£…å±‚é¢çš„é‡å»ºæ¨¡è¦åšå¥½ï¼Œéœ€è¦åˆ†è§£æˆä¸¤æ–¹é¢ï¼š<ol type="1"><li><em>å¯è§†åŒºåŸŸçš„å˜å½¢è‡ªç”±åº¦è¦è¢«é™åˆ¶ï¼Œä¸ç„¶äººä½“ç»“æ„ä¼šè¢«ç ´åã€‚</em> ä¸ºæ­¤ï¼Œè¿™ç¯‡æ–‡ç« æå‡ºé™¤äº†åŸå§‹å›¾åƒä»¥å¤–ï¼Œè¿˜é¢å¤–åŠ ä¸Šä¸¤ç§å‚æ•°åŒ–çš„äººä½“æ¨¡å‹ï¼ŒåŒ…æ‹¬3Dè¯­ä¹‰ä½“+å¯¹åº”çš„2Dè¯­ä¹‰map</li><li><em>æ¨¡å‹è¦èƒ½æå–å‡ºå‡ ä½•ä¿¡æ¯ï¼Œæ¯”å¦‚æœè£…é£æ ¼å’Œçš±çº¹ã€‚</em> ä¸ºæ­¤ï¼Œæå‡ºäº†å¤šå°ºåº¦ä½“ç§¯ç‰¹å¾è½¬æ¢ã€‚ æœ€åå†é€šè¿‡æ³•çº¿æŠ•å½±å±‚ï¼Œè¿æ¥ç”Ÿæˆç½‘ç»œå’Œç²¾ç‚¼ç½‘ç»œ</li></ol></li><li>æ€»çš„æ¥è¯´ï¼Œåˆ†æˆ3ä¸ªå­ä»»åŠ¡ï¼š<ol type="1"><li>è¾“å…¥å›¾åƒ -&gt; å‚æ•°åŒ–äººä½“æ¨¡å‹</li><li>å›¾åƒ+äººä½“æ¨¡å‹ -&gt; è¡¨é¢é‡å»º</li><li>å›¾åƒ -&gt; å¯è§†è¡¨é¢å†åº¦ç²¾ç»†åŒ–</li></ol></li><li>THumanæ•°æ®é›†ï¼ŒåŒ…æ‹¬7000ä¸ªç©¿ç€230ç§æœè£…çš„éšæœºå§¿åŠ¿çš„äººä½“mesh</li></ol><h3 id="æ¨¡å‹">æ¨¡å‹ï¼š</h3><figure><img src="https://s2.loli.net/2021/12/19/GX1IB39Yb5OwAoe.png" alt="image-20211217121247234" /><figcaption>image-20211217121247234</figcaption></figure><ol type="1"><li>å¯¹äºæ¯ä¸ªä¸‰ç»´æ¨¡å‹é¡¶ç‚¹ï¼Œç”Ÿæˆä¸€ä¸ªåŒ…å«3ä¸ªç»´åº¦çš„è¯­ä¹‰ç ï¼ŒåŒ…å«å…¶ç©ºé—´åæ ‡+å§¿åŠ¿ä¿¡æ¯ï¼Œæ˜ å°„åˆ°äºŒç»´å›¾åƒIä¸Šï¼Œå¾—åˆ°è¯­ä¹‰map Ms</li><li>ä½“ç´ åŒ–smplæ¨¡å‹ï¼Œç„¶åæŠŠè¯­ä¹‰ç ä¼ æ’­åˆ°å¯¹åº”ä½“ç´ ä¸­ï¼Œå¾—åˆ°è¯­ä¹‰ä½“Vs</li><li>å®šä¹‰ä¸€ä¸ª128*192*128çš„3då æ®ç©ºé—´(occupancy volume) Voï¼Œå…¶ä¸­è¡¨é¢ä»¥å†…çš„æ‰€æœ‰ä½“ç´ å€¼è®¾ä¸º1ï¼Œä»¥å¤–çš„ä¸º0ã€‚é€šè¿‡ä¸€ä¸ªå›¾åƒå¯¼å‘çš„ä½“åˆ°ä½“ç¿»è¯‘ç½‘ç»œï¼Œé Iå’ŒMsçš„ååŠ©ï¼ŒæŠŠVsé‡å»ºæ¨¡ä¸ºVo</li><li>å› ä¸ºä½“ç´ ä½“çš„åƒç´ æœ‰é™ï¼Œæ‰€ä»¥æœ€åå†ç”¨ä¸€ä¸ªUNetï¼Œç›´æ¥æŠŠVoæŠ•å½±æˆä¸€ä¸ª2D<a href="https://zh.wikipedia.org/wiki/%E6%B3%95%E7%BA%BF%E8%B4%B4%E5%9B%BE">æ³•çº¿è´´å›¾(Normal map)</a> Nï¼Œä¹Ÿå°±ç›¸å½“äºæ˜¯å¯è§†çš„è¡¨é¢</li><li>æ€»çš„æ¥è¯´ï¼Œæ¨¡å‹ç”±ä¸‰éƒ¨åˆ†ç»„æˆ<ol type="1"><li>å›¾åƒç¼–ç G</li><li>ä½“åˆ°ä½“è½¬æ¢ç½‘ç»œvol2vol</li><li>æ³•çº¿ç²¾ç‚¼ç½‘ç»œR</li></ol></li></ol><h4 id="å›¾åƒç¼–ç -g">å›¾åƒç¼–ç  G</h4><p>ç»“åˆIå’ŒMsï¼Œå¾—åˆ°å¤šå°ºåº¦çš„2Dç‰¹å¾maps <span class="math inline">\(M_f^{(k)}(k=1,...,K)\)</span></p><h4 id="ä½“ç‰¹å¾è½¬æ¢-volumetric-feature-transformation-vft">ä½“ç‰¹å¾è½¬æ¢ volumetric feature transformation VFT</h4><figure><img src="https://s2.loli.net/2021/12/19/EBjbG4PztH6cNVO.png" alt="image-20211217121317806" /><figcaption>image-20211217121317806</figcaption></figure><p>VFTè¿™ä¸ªä¸œè¥¿æŠŠå‰é¢é€šè¿‡å›¾åƒç¼–ç å¾—åˆ°çš„å¤šå°ºåº¦çš„2Dç‰¹å¾maps <span class="math inline">\(M_f^{(k)}(k=1,...,K)\)</span>èåˆåˆ°vol2volç½‘ç»œä¸­</p><ol type="1"><li>é€šè¿‡ä¸€ä¸ªå·ç§¯+æ¿€æ´»ï¼ŒæŠŠç‰¹å¾map <span class="math inline">\(M_F^{(k)}\)</span>æ˜ å°„åˆ°æ¨¡å—åŒ–å‚æ•°<span class="math inline">\((\alpha_k, \beta_k)\)</span>ä¸­</li><li>å› ä¸ºæ­¤æ—¶<span class="math inline">\((\alpha_k, \beta_k)\)</span>æ˜¯äºŒç»´çš„ï¼Œè€Œè¯­ä¹‰ä½“<span class="math inline">\(V_f^{(k)}\)</span>æ˜¯ä¸‰ç»´çš„ï¼Œæ‰€ä»¥è¿™é‡Œæ˜¯æŠŠ<span class="math inline">\(V_f^{(k)}\)</span>åœ¨zè½´ä¸Šåˆ†æˆé«˜åº¦ä¸º1çš„ä¸€å±‚ä¸€å±‚çš„åˆ‡ç‰‡ï¼Œç„¶ååˆ†åˆ«è·Ÿ<span class="math inline">\((\alpha_k, \beta_k)\)</span>åšä»¿å°„å˜æ¢ï¼ˆç†è§£æˆçº¿æ€§å˜æ¢+å¹³ç§»ï¼‰</li><li>ä»¿å°„å˜æ¢ï¼š<span class="math inline">\(VFT(V_f^{(k)}(z_i))=\alpha_k\bigodot V_f^{(k)}(z_i) + \beta_k\)</span>ã€‚æœ€åå°±èƒ½å¾—åˆ°è½¬æ¢åçš„Vfäº†</li></ol><p>ç›¸æ¯”äºç›´æ¥æŠŠç‰¹å¾è¿æ¥èµ·æ¥ï¼ŒVFTçš„å¥½å¤„å°±æ˜¯è¯´å®ƒå¯ä»¥æ›´å¥½åœ°ä¿å­˜å½¢çŠ¶ç‰¹å¾ï¼Œè€Œä¸”æ›´å¿«æ›´çµæ´»ã€‚</p><h4 id="vol2vol">vol2vol</h4><ol type="1"><li>æ˜¯ä¸€ä¸ª3Dçš„Unetï¼Œä»¥Vså’Œ<span class="math inline">\(M_f^{(k)}(k=1,...,K)\)</span>ä¸ºè¾“å…¥ï¼ŒVoä¸ºè¾“å‡º</li><li>åœ¨encoderé˜¶æ®µç”¨VFTæŠŠMfä¿¡æ¯èåˆè¿›Vfæ¥ï¼›ç„¶ååˆ©ç”¨skip- connectionï¼Œè¿™ä¸ªVFTçš„å˜æ¢ä¿¡æ¯ä¹Ÿæ˜¯å¯ä»¥ç›´æ¥ä¼ é€’åˆ°decoderé˜¶æ®µçš„</li></ol><h4 id="ä½“åˆ°æ³•çº¿è´´å›¾çš„æŠ•å½±å±‚-r">ä½“åˆ°æ³•çº¿è´´å›¾çš„æŠ•å½±å±‚ R</h4><p>è¿™æ˜¯ä¸€ä¸ªå¯å¾®åˆ†çš„ä½“ç§¯åˆ°æ³•çº¿çš„æŠ•å½±å±‚ï¼Œå¯ä»¥æ ¹æ®å æ®ç©ºé—´ç›´æ¥è®¡ç®—å‡ºæ³•çº¿è´´å›¾ï¼Œå®ç°äººä½“è¡¨é¢ç»†èŠ‚çš„å‘ˆç°ã€‚</p><figure><img src="https://s2.loli.net/2021/12/19/TL5dxOVwvJGiq9Q.png" alt="image-20211217121336401" /><figcaption>image-20211217121336401</figcaption></figure><ol type="1"><li>æ ¹æ®å æ®ç©ºé—´ç”Ÿæˆä¸€ä¸ªæ·±åº¦å›¾depth mapï¼Œä¸Šå›¾4æ˜¯ç”Ÿæˆdepth mapçš„æ­¥éª¤ï¼š<ol type="1"><li>4ï¼ˆaï¼‰ä¸­ï¼Œè“è‰²åœ†æ˜¯è¾“å…¥çš„æ¨¡å‹ï¼Œä» <span class="math inline">\(p=(x_p,y_p)\)</span> ç‚¹å¼€å§‹ï¼Œæ²¿ç€zè½´æ‰«ææ¯ä¸€ä¸ªä½“ç´ ç‚¹çš„å æ®æƒ…å†µï¼Œå°±èƒ½å¾—åˆ°å›¾4ï¼ˆbï¼‰</li><li>æ‰¾åˆ°æœ€è¿‘çš„è¢«å æ®çš„ä½“ç´ ç‚¹ï¼Œå³æ˜¯æ·±åº¦å€¼<span class="math inline">\(D(p)\)</span>ï¼Œå¦‚å›¾4ï¼ˆcï¼‰</li><li>è¿™ä¸ªæ–¹æ³•è™½ç„¶å¾ˆç›´è§‚ï¼Œä½†æ˜¯ç›´æ¥æ¥ç®—å¹¶ä¸å¥½ç®—ï¼Œæ‰€ä»¥å®é™…ä¸Šæ˜¯é‡‡ç”¨ä¸€ç§å¯¹ä½“ç´ æ¨¡å‹è¿›è¡Œå˜æ¢ç„¶åå†æ±‚å€¼çš„æ•°å­¦æ–¹æ³•ç®—çš„</li></ol></li><li>å°†depth mapè½¬åŒ–æˆé¡¶ç‚¹å›¾vertex mapï¼Œç„¶åç”¨æ•°å­¦æ–¹æ³•è®¡ç®—å‡ºæ³•çº¿å›¾normal map<ol type="1"><li>æ ¹æ®å›¾åƒä¸­çš„ä½ç½®ï¼ŒæŠŠxå’Œyåæ ‡èµ‹å€¼ç»™æ·±åº¦åƒç´ </li><li>ç„¶åç”¨ Sobel ç®—å­æ¥è®¡ç®—é¡¶ç‚¹mapæ²¿xå’Œyæ–¹å‘çš„æ–¹å‘å¯¼æ•°ï¼š<span class="math inline">\(G_x=S_x*M_v,G_y=S_y*M_v,\)</span></li><li>åƒç´ ç‚¹ <span class="math inline">\(p=(x_p,y_p)\)</span>çš„æ³•çº¿å°±å¯ä»¥ç›´æ¥è®¡ç®—å‡ºæ¥ï¼š<span class="math inline">\(N^{(x_py_p)}=G_x(p)\times G_y(p)\)</span></li></ol></li><li>æœ€åç”¨ä¸€ä¸ª Unet æŠŠ normal map Upsampleåˆ°ä¸¤å€å¤§å°</li></ol><h3 id="loss-functions">Loss functions</h3><ol type="1"><li><p>3Då æ®ç©ºé—´çš„é‡å»ºæ¨¡è¯¯å·®ï¼Œç”¨Binary Cross-Entropy (BCE)è¡¨ç¤ºï¼š <span class="math display">\[L_V = -\frac{1}{|\hat V_o|}\sum_{x,y,z} \gamma \hat V_o^{(xyz)} logV_o^{(xyz)}+(1-\gamma)(1-\hat V_o^{(xyz)})log(1-V_o^{(xyz)})\]</span> <span class="math inline">\(\hat V_o\)</span>æ˜¯å æ®ç©ºé—´çœŸå®å€¼ï¼Œ<span class="math inline">\(V_o^{(xyz)}\)</span> <span class="math inline">\(\hat V_o^{(xyz)}\)</span>éƒ½æ˜¯åœ¨åæ ‡<span class="math inline">\((x,y,z)\)</span>çš„ä½“ç´ ç‚¹ï¼Œ<span class="math inline">\(\gamma\)</span> æ˜¯ä¸€ä¸ªæƒé‡</p></li><li><p>2Då‰ªå½±ï¼ˆsilhouetteï¼‰çš„é‡å»ºæ¨¡è¯¯å·®ï¼Œæ˜¯ä¸€ä¸ªå¤šè§†è§’é‡æŠ•å½±lossï¼š <span class="math display">\[L_{FS} = -\frac{1}{|\hat S_{fv}|}\sum_{x,y} \hat S_{fv}^{(xy)}log S_{fv}^{(xy)}+(1-\hat S_{fv}^{(xy)})log(1-S_{fv}^{(xy)})\]</span> <span class="math inline">\(L_{FS}\)</span>æ˜¯å‰è§†è§’ï¼ˆfront-viewï¼‰çš„å‰ªå½±é‡æŠ•å½±lossï¼Œ<span class="math inline">\(S_{fv}\)</span>æ˜¯<span class="math inline">\(V_o\)</span>çš„å‰ªå½±é‡æŠ•å½±ï¼Œ<span class="math inline">\(\hat S_{fv}\)</span>æ˜¯ç›¸åº”çš„çœŸå®æŠ•å½±ï¼Œ$ S_{fv}^{(xy)}$ <span class="math inline">\(\hat S_{fv}^{(xy)}\)</span>æ˜¯åœ¨åæ ‡<span class="math inline">\((x,y)\)</span>çš„ç›¸åº”åƒç´ å€¼ã€‚</p><p>ä¾§é¢è§†è§’çš„loss <span class="math inline">\(L_{SS}\)</span>çš„å®šä¹‰å¦‚å‡ºä¸€è¾™ã€‚</p></li><li><p>æ³•çº¿å›¾çš„ç²¾ç‚¼è¯¯å·®ï¼Œç”¨ä½™å¼¦è·ç¦»ï¼š <span class="math display">\[L_N = \frac{1}{|\hat N|}\sum_{x,y} 1-\frac{&lt;N^{(xy)},\hat N^{(xy)}&gt;}{|N^{(xy)}|\cdot |\hat N^{(xy)}|}\]</span></p></li><li><p>æ€»lossï¼š <span class="math display">\[L = L_V +\lambda_{FS}L_{FS} +\lambda_{SS}L_{SS}+\lambda_{N}L_{N}\]</span></p></li></ol><h3 id="thumanæ•°æ®é›†">THumanæ•°æ®é›†</h3><ol type="1"><li>ç”¨DoubleFusionæ–¹æ³•æ•æ‰3Däººä½“meshæ¨¡å‹</li><li>æ•°æ®é›†ä¸­åŒ…æ‹¬7000ä¸ªæ•°æ®é¡¹ï¼Œæ¯ä¸€é¡¹æœ‰ï¼šè¡¨é¢åŒ…å«äº†æè´¨çš„meshæ¨¡å‹ + RGBDå›¾åƒ + å¯¹åº”çš„SMPLæ¨¡å‹</li></ol><h3 id="å®éªŒ">å®éªŒ</h3><figure><img src="https://s2.loli.net/2021/12/19/acYy6ftBGLN7FRV.png" alt="image-20211217121419341" /><figcaption>image-20211217121419341</figcaption></figure><p>è·Ÿè¿™å‡ ä¸ªæ¯”ï¼šHMR BodyNet SiCloPe</p><p>æ•ˆæœå¥½æäº†</p><h3 id="è®¨è®º">è®¨è®º</h3><p>limitationï¼š</p><ol type="1"><li>å¿…é¡»ä¾èµ–HMRå’ŒSMPLifyæ¥ä¸ºè¾“å…¥å›¾åƒä¼°è®¡ä¸€ä¸ªSMPLæ¨¡å‹</li><li>ä¸å¯è§çš„åœ°æ–¹è¢«è¿‡åº¦å¹³æ»‘äº†</li><li>æ‰‹åªèƒ½è¡¨ç¤ºæˆä¸€å›¢ï¼Œé¢éƒ¨è¡¨æƒ…ä¹Ÿä¸èƒ½åˆ»ç”»</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;è®ºæ–‡åœ°å€ï¼š&lt;a href=&quot;https://openaccess.thecvf.com/content_ICCV_2019/html/Zheng_DeepHuman_3D_Human_Reconstruction_From_a_Single_Image_ICCV_2019_paper.html&quot; class=&quot;uri&quot;&gt;https://openaccess.thecvf.com/content_ICCV_2019/html/Zheng_DeepHuman_3D_Human_Reconstruction_From_a_Single_Image_ICCV_2019_paper.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ä½œè€…ï¼šZerong Zheng, Tao Yu, Yixuan Wei, Qionghai Dai, Yebin Liu&lt;/p&gt;
&lt;p&gt;å‘è¡¨ï¼š ICCV2019&lt;/p&gt;
&lt;p&gt;Codeï¼š &lt;a href=&quot;https://github.com/ZhengZerong/DeepHuman&quot; class=&quot;uri&quot;&gt;https://github.com/ZhengZerong/DeepHuman&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Computer Notes" scheme="https://jyzhu.top/categories/Computer-Notes/"/>
    
    
    <category term="Computer Vision" scheme="https://jyzhu.top/tags/Computer-Vision/"/>
    
    <category term="Deep Learning" scheme="https://jyzhu.top/tags/Deep-Learning/"/>
    
    <category term="3D Reconstruction" scheme="https://jyzhu.top/tags/3D-Reconstruction/"/>
    
    <category term="Paper Reading" scheme="https://jyzhu.top/tags/Paper-Reading/"/>
    
  </entry>
  
  <entry>
    <title>è¯»ï¼šè®ºè§†è§‰çŸ¥è¯†</title>
    <link href="https://jyzhu.top/%E8%AF%BB%EF%BC%9A%E8%AE%BA%E8%A7%86%E8%A7%89%E7%9F%A5%E8%AF%86/"/>
    <id>https://jyzhu.top/%E8%AF%BB%EF%BC%9A%E8%AE%BA%E8%A7%86%E8%A7%89%E7%9F%A5%E8%AF%86/</id>
    <published>2021-12-15T06:25:17.000Z</published>
    <updated>2021-12-15T06:29:43.189Z</updated>
    
    <content type="html"><![CDATA[<p>è®ºæ–‡åœ°å€ï¼šhttps://link.springer.com/article/10.1631%2FFITEE.1910001</p><p>ä½œè€…ï¼šæ½˜äº‘é¹¤</p><p>å‘è¡¨ï¼š Frontiers of Information Technology &amp; Electronic Engineering</p><p>é“¾æ¥ï¼š https://link.springer.com/article/10.1631%2FFITEE.1910001</p><hr /><blockquote><p>è¿™ç¯‡æ˜¯æ½˜é™¢å£«çš„å‰ç»æ€§æ€è€ƒï¼Œè™½ç„¶æ¯”è¾ƒçŸ­ï¼Œä½†è¿˜æ˜¯è®¤çœŸè¯»ä¸€è¯»ã€‚å­¦é•¿åˆ†äº«ç»™æˆ‘ï¼Œå¤§æ¦‚æ˜¯å¯ä»¥å¯¹æˆ‘ä»¬çš„ç ”ç©¶èµ·åˆ°ä¸€äº›æŒ‡å¯¼æ€§å¯è¿ªå§ã€‚</p></blockquote><h2 id="why">Whyï¼š</h2><h2 id="what">Whatï¼š</h2><ol type="1"><li>æå‡ºâ€œè§†è§‰çŸ¥è¯†â€æ¦‚å¿µ</li><li>è§†è§‰æ¦‚å¿µ-&gt;è§†è§‰å‘½é¢˜-&gt;è§†è§‰å™äº‹</li></ol><p>è¯»å‰ç–‘é—®ï¼š</p><h2 id="how">Howï¼š</h2>]]></content>
    
    
    <summary type="html">&lt;p&gt;è®ºæ–‡åœ°å€ï¼šhttps://link.springer.com/article/10.1631%2FFITEE.1910001&lt;/p&gt;
&lt;p&gt;ä½œè€…ï¼šæ½˜äº‘é¹¤&lt;/p&gt;
&lt;p&gt;å‘è¡¨ï¼š Frontiers of Information Technology &amp;amp; Electronic Engineering&lt;/p&gt;
&lt;p&gt;é“¾æ¥ï¼š https://link.springer.com/article/10.1631%2FFITEE.1910001&lt;/p&gt;</summary>
    
    
    
    <category term="Computer Notes" scheme="https://jyzhu.top/categories/Computer-Notes/"/>
    
    
    <category term="Computer Vision" scheme="https://jyzhu.top/tags/Computer-Vision/"/>
    
    <category term="Paper Reading" scheme="https://jyzhu.top/tags/Paper-Reading/"/>
    
  </entry>
  
</feed>
